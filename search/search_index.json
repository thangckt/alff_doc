{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"<code>alff</code> Documentation","text":""},{"location":"#alff","title":"<code>alff</code>","text":"<p>ALFF: Active Learning Framework for generating Machine Learning Forcefields.</p> <p>This package is developed and maintained by C.Thang Nguyen</p>"},{"location":"alff_active_learning/","title":"ALFF: Active Learning","text":"<p>Run the main ALFF active learning process.</p> <pre><code>alff_al PARAM.yaml MACHINE.yaml\n</code></pre> <ul> <li><code>PARAM.yaml</code>: The parameters of the generator.</li> <li><code>MACHINE.yaml</code>: The settings of the machines running the generator's subprocesses.</li> </ul> <p>An example run:</p> <pre><code>-------------------------------- ALFF --------------------------------\n    Version:  0.1.dev409+g177de1d\n       Path:  C:/conda/envs/py13/Lib/site-packages/alff\n---------------------------- Dependencies ----------------------------\n       numpy  1.26.4       C:/conda/envs/py11/Lib/site-packages/numpy\n       scipy  1.13.0       C:/conda/envs/py11/Lib/site-packages/scipy\n         ase  3.23.1b1     C:/conda/envs/py11/Lib/site-packages/ase\n      polars  1.11.0       C:/conda/envs/py11/Lib/site-packages/polars\n      thutil  0.1.dev122   C:/conda/envs/py11/Lib/site-packages/thutil\n      sevenn  0.10.1       C:/conda/envs/py11/Lib/site-packages/sevenn\n     phonopy  2.29.1       C:/conda/envs/py11/Lib/site-packages/phonopy\n----------------------- Author: C.Thang Nguyen -----------------------\n--------------- Contact: https://thang.eu.org/contact ----------------\n\n                             ___    __    ____________\n                            /   |  / /   / ____/ ____/\n                           / /| | / /   / /_  / /_\n                          / ___ |/ /___/ __/ / __/\n                         /_/  |_/_____/_/   /_/\n\nalff-INFO: START ACTIVE LEARNING\nalff-INFO: ======================= iter_000000 ========================\nalff-INFO: ------------- iter_000000 stage_00: pre_train --------------\nalff-INFO: ------------- iter_000000 stage_01: run_train --------------\nalff-INFO: Trainning ML models... be patient\n               Remote host: some_IP_address\n               Remote path: /uwork/user01/work/w24_alff_job\n               Log file: logs/20241020_220540_dispatcher.log\n</code></pre>"},{"location":"alff_api/","title":"API","text":""},{"location":"alff_api/#alff","title":"<code>alff</code>","text":"<p>ALFF: Active Learning Framework for generating Machine Learning Forcefields.</p> <p>This package is developed and maintained by C.Thang Nguyen</p> <p>Modules:</p> <ul> <li> <code>al</code>           \u2013            </li> <li> <code>cli</code>           \u2013            </li> <li> <code>constant</code>           \u2013            </li> <li> <code>data</code>           \u2013            </li> <li> <code>elastic</code>           \u2013            </li> <li> <code>lib</code>           \u2013            </li> <li> <code>phonon</code>           \u2013            </li> </ul> <p>Attributes:</p> <ul> <li> <code>ROOT_PATH</code>           \u2013            </li> <li> <code>__author__</code>           \u2013            </li> <li> <code>__contact__</code>           \u2013            </li> </ul>"},{"location":"alff_api/#alff.ROOT_PATH","title":"<code>ROOT_PATH = Path(__file__).parent</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.__author__","title":"<code>__author__ = 'C.Thang Nguyen'</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.__contact__","title":"<code>__contact__ = 'https://thang.eu.org/contact'</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.al","title":"<code>al</code>","text":"<p>Modules:</p> <ul> <li> <code>active_learning</code>           \u2013            <p>iter:</p> </li> <li> <code>finetune</code>           \u2013            </li> <li> <code>lib_gpaw_al</code>           \u2013            <p>Move all the GPAW related functions to here.</p> </li> <li> <code>lib_lammps_al</code>           \u2013            </li> </ul>"},{"location":"alff_api/#alff.al.active_learning","title":"<code>active_learning</code>","text":"iter <p>0_train 1_model_devi 2_dft 3_data</p> <p>Functions:</p> <ul> <li> <code>get_job_names</code>             \u2013              </li> <li> <code>pre_dft_task_name</code>             \u2013              </li> <li> <code>get_sys_index</code>             \u2013              </li> <li> <code>pre_train</code>             \u2013              </li> <li> <code>run_train</code>             \u2013              </li> <li> <code>post_train</code>             \u2013              </li> <li> <code>expand_matrix_values</code>             \u2013              </li> <li> <code>pre_md</code>             \u2013              </li> <li> <code>pre_md_lammps_7net</code>             \u2013              </li> <li> <code>run_md</code>             \u2013              </li> <li> <code>run_md_lammps_7net</code>             \u2013              </li> <li> <code>run_md_model_devi</code>             \u2013              </li> <li> <code>post_md</code>             \u2013              </li> <li> <code>check_cluster</code>             \u2013              </li> <li> <code>check_bad_box</code>             \u2013              </li> <li> <code>pre_fp_vasp</code>             \u2013              </li> <li> <code>pre_fp_amber_diff</code>             \u2013              <p>Run amber twice to calculate high-level and low-level potential,</p> </li> <li> <code>pre_fp_custom</code>             \u2013              <p>Make input file for customized FP style.</p> </li> <li> <code>pre_fp</code>             \u2013              <p>Select the candidate strutures and make the input file of FP calculation.</p> </li> <li> <code>pre_fp_calculation</code>             \u2013              <p>Make the input file of FP calculation.</p> </li> <li> <code>run_fp_inner</code>             \u2013              </li> <li> <code>run_fp</code>             \u2013              </li> <li> <code>post_fp_check_fail</code>             \u2013              </li> <li> <code>post_fp_vasp</code>             \u2013              </li> <li> <code>post_fp_pwscf</code>             \u2013              </li> <li> <code>post_fp_abacus_scf</code>             \u2013              </li> <li> <code>post_fp_siesta</code>             \u2013              </li> <li> <code>post_fp_amber_diff</code>             \u2013              </li> <li> <code>post_fp_custom</code>             \u2013              <p>Post fp for custom fp. Collect data from user-defined <code>output_fn</code>.</p> </li> <li> <code>post_fp</code>             \u2013              </li> <li> <code>al_iteration</code>             \u2013              <p>Run main loop of active learning.</p> </li> </ul>"},{"location":"alff_api/#alff.al.active_learning._get_model_suffix","title":"<code>_get_model_suffix(pdict) -&gt; str</code>","text":"<p>Return the model suffix based on the backend.</p>"},{"location":"alff_api/#alff.al.active_learning.get_job_names","title":"<code>get_job_names(pdict)</code>","text":""},{"location":"alff_api/#alff.al.active_learning.pre_dft_task_name","title":"<code>pre_dft_task_name(struct_idx, counter)</code>","text":""},{"location":"alff_api/#alff.al.active_learning.get_sys_index","title":"<code>get_sys_index(task)</code>","text":""},{"location":"alff_api/#alff.al.active_learning._get_mlp_engine","title":"<code>_get_mlp_engine(pdict)</code>","text":""},{"location":"alff_api/#alff.al.active_learning.pre_train","title":"<code>pre_train(iter_idx, pdict, mdict)</code>","text":""},{"location":"alff_api/#alff.al.active_learning.run_train","title":"<code>run_train(iter_idx, pdict, mdict)</code>","text":""},{"location":"alff_api/#alff.al.active_learning.post_train","title":"<code>post_train(iter_idx, pdict, mdict)</code>","text":""},{"location":"alff_api/#alff.al.active_learning.expand_matrix_values","title":"<code>expand_matrix_values(target_list, cur_idx=0)</code>","text":""},{"location":"alff_api/#alff.al.active_learning.pre_md","title":"<code>pre_md(iter_idx, pdict, mdict)</code>","text":""},{"location":"alff_api/#alff.al.active_learning._get_lammps_default_args","title":"<code>_get_lammps_default_args(iter_idx, pdict)</code>","text":""},{"location":"alff_api/#alff.al.active_learning.pre_md_lammps_7net","title":"<code>pre_md_lammps_7net(iter_idx, pdict, mdict)</code>","text":""},{"location":"alff_api/#alff.al.active_learning.run_md","title":"<code>run_md(iter_idx, pdict, mdict)</code>","text":""},{"location":"alff_api/#alff.al.active_learning.run_md_lammps_7net","title":"<code>run_md_lammps_7net(iter_idx, pdict, mdict)</code>","text":""},{"location":"alff_api/#alff.al.active_learning.run_md_model_devi","title":"<code>run_md_model_devi(iter_idx, pdict, mdict)</code>","text":""},{"location":"alff_api/#alff.al.active_learning.post_md","title":"<code>post_md(iter_idx, pdict, mdict)</code>","text":""},{"location":"alff_api/#alff.al.active_learning.check_cluster","title":"<code>check_cluster(conf_name, fp_cluster_vacuum, fmt='lammps/dump')</code>","text":""},{"location":"alff_api/#alff.al.active_learning.check_bad_box","title":"<code>check_bad_box(conf_name, criteria, fmt='lammps/dump')</code>","text":""},{"location":"alff_api/#alff.al.active_learning._read_model_devi_file","title":"<code>_read_model_devi_file(task_path: str, model_devi_f_avg_relative: bool = False, model_devi_merge_traj: bool = False)</code>","text":""},{"location":"alff_api/#alff.al.active_learning._select_by_model_devi_standard","title":"<code>_select_by_model_devi_standard(modd_system_task: list[str], f_trust_lo: float, f_trust_hi: float, v_trust_lo: float, v_trust_hi: float, cluster_cutoff: float, model_devi_engine: str, model_devi_skip: int = 0, model_devi_f_avg_relative: bool = False, model_devi_merge_traj: bool = False, detailed_report_pre_fp: bool = True)</code>","text":""},{"location":"alff_api/#alff.al.active_learning._select_by_model_devi_adaptive_trust_low","title":"<code>_select_by_model_devi_adaptive_trust_low(modd_system_task: list[str], f_trust_hi: float, numb_candi_f: int, perc_candi_f: float, v_trust_hi: float, numb_candi_v: int, perc_candi_v: float, model_devi_skip: int = 0, model_devi_f_avg_relative: bool = False, model_devi_merge_traj: bool = False)</code>","text":"<p>modd_system_task    model deviation tasks belonging to one system f_trust_hi numb_candi_f        number of candidate due to the f model deviation perc_candi_f        percentage of candidate due to the f model deviation v_trust_hi numb_candi_v        number of candidate due to the v model deviation perc_candi_v        percentage of candidate due to the v model deviation model_devi_skip.</p>"},{"location":"alff_api/#alff.al.active_learning._select_by_model_devi_adaptive_trust_low--returns","title":"Returns","text":"<p>accur               the accurate set candi               the candidate set failed              the failed set counter             counters, number of elements in the sets f_trust_lo          adapted trust level of f v_trust_lo          adapted trust level of v</p>"},{"location":"alff_api/#alff.al.active_learning._pre_fp_vasp_inner","title":"<code>_pre_fp_vasp_inner(iter_idx, modd_path, work_path, model_devi_skip, v_trust_lo, v_trust_hi, f_trust_lo, f_trust_hi, fp_task_min, fp_task_max, fp_link_files, type_map, pdict)</code>","text":"<p>iter_idx          int             iter index modd_path           string          path of model devi work_path           string          path of fp fp_task_max         int             max number of tasks fp_link_files       [string]        linked files for fp, POTCAR for example fp_param           map             parameters for fp.</p>"},{"location":"alff_api/#alff.al.active_learning.pre_fp_vasp","title":"<code>pre_fp_vasp(iter_idx, pdict)</code>","text":""},{"location":"alff_api/#alff.al.active_learning.pre_fp_amber_diff","title":"<code>pre_fp_amber_diff(iter_idx: int, pdict: dict)</code>","text":"<p>Run amber twice to calculate high-level and low-level potential, and then generate difference between them.</p> <p>Besides AMBER, one needs to install <code>dpamber</code> package, which is avaiable at https://github.com/njzjz/dpamber</p> <p>Currently, it should be used with the AMBER model_devi driver.</p>"},{"location":"alff_api/#alff.al.active_learning.pre_fp_amber_diff--parameters","title":"Parameters","text":"<p>iter_idx : int     iter index pdict : dict     Run parameters. The following parameters are used in this method:         mdin_prefix : str             The path prefix to AMBER mdin files         qm_region : list[str]             AMBER mask of the QM region. Each mask maps to a system.         qm_charge : list[int]             Charge of the QM region. Each charge maps to a system.         high_level : str             high level method         low_level : str             low level method         fp_param : dict             This parameters includes:                 high_level_mdin : str                     High-level AMBER mdin file. %qm_theory%, %qm_region%,                     and %qm_charge% will be replace.                 low_level_mdin : str                     Low-level AMBER mdin file. %qm_theory%, %qm_region%,                     and %qm_charge% will be replace.         parm7_prefix : str             The path prefix to AMBER PARM7 files         parm7 : list[str]             List of paths to AMBER PARM7 files. Each file maps to a system.</p>"},{"location":"alff_api/#alff.al.active_learning.pre_fp_amber_diff--references","title":"References","text":"<p>.. [1] Development of Range-Corrected Deep Learning Potentials for Fast, Accurate Quantum    Mechanical/Molecular Mechanical Simulations of Chemical Reactions in Solution,    Jinzhe Zeng, Timothy J. Giese, \u015e\u00f6len Ekesan, and Darrin M. York, Journal of Chemical    Theory and Computation 2021 17 (11), 6993-7009</p>"},{"location":"alff_api/#alff.al.active_learning.pre_fp_custom","title":"<code>pre_fp_custom(iter_idx, pdict)</code>","text":"<p>Make input file for customized FP style.</p> <p>Convert the POSCAR file to custom format.</p>"},{"location":"alff_api/#alff.al.active_learning.pre_fp_custom--parameters","title":"Parameters","text":"<p>iter_idx : int     iter index pdict : dict     Run parameters.</p>"},{"location":"alff_api/#alff.al.active_learning.pre_fp","title":"<code>pre_fp(iter_idx, pdict, mdict)</code>","text":"<p>Select the candidate strutures and make the input file of FP calculation.</p>"},{"location":"alff_api/#alff.al.active_learning.pre_fp--parameters","title":"Parameters","text":"<p>iter_idx : int     iter index pdict : dict     Run parameters. mdict : dict     Machine parameters.</p>"},{"location":"alff_api/#alff.al.active_learning.pre_fp_calculation","title":"<code>pre_fp_calculation(iter_idx, pdict, mdict)</code>","text":"<p>Make the input file of FP calculation.</p>"},{"location":"alff_api/#alff.al.active_learning.pre_fp_calculation--parameters","title":"Parameters","text":"<p>iter_idx : int     iter index pdict : dict     Run parameters. mdict : dict     Machine parameters.</p>"},{"location":"alff_api/#alff.al.active_learning._vasp_check_fin","title":"<code>_vasp_check_fin(ii)</code>","text":""},{"location":"alff_api/#alff.al.active_learning._qe_check_fin","title":"<code>_qe_check_fin(ii)</code>","text":""},{"location":"alff_api/#alff.al.active_learning.run_fp_inner","title":"<code>run_fp_inner(iter_idx, pdict, mdict, forward_files, backward_files, check_fin, log_file='fp.log', forward_common_files=[])</code>","text":""},{"location":"alff_api/#alff.al.active_learning.run_fp","title":"<code>run_fp(iter_idx, pdict, mdict)</code>","text":""},{"location":"alff_api/#alff.al.active_learning.post_fp_check_fail","title":"<code>post_fp_check_fail(iter_idx, pdict, rfailed=None)</code>","text":""},{"location":"alff_api/#alff.al.active_learning.post_fp_vasp","title":"<code>post_fp_vasp(iter_idx, pdict, rfailed=None)</code>","text":""},{"location":"alff_api/#alff.al.active_learning.post_fp_pwscf","title":"<code>post_fp_pwscf(iter_idx, pdict)</code>","text":""},{"location":"alff_api/#alff.al.active_learning.post_fp_abacus_scf","title":"<code>post_fp_abacus_scf(iter_idx, pdict)</code>","text":""},{"location":"alff_api/#alff.al.active_learning.post_fp_siesta","title":"<code>post_fp_siesta(iter_idx, pdict)</code>","text":""},{"location":"alff_api/#alff.al.active_learning.post_fp_amber_diff","title":"<code>post_fp_amber_diff(iter_idx, pdict)</code>","text":""},{"location":"alff_api/#alff.al.active_learning.post_fp_custom","title":"<code>post_fp_custom(iter_idx, pdict)</code>","text":"<p>Post fp for custom fp. Collect data from user-defined <code>output_fn</code>.</p>"},{"location":"alff_api/#alff.al.active_learning.post_fp_custom--parameters","title":"Parameters","text":"<p>iter_idx : int     The index of the current iteration. pdict : dict     The parameter data.</p>"},{"location":"alff_api/#alff.al.active_learning.post_fp","title":"<code>post_fp(iter_idx, pdict)</code>","text":""},{"location":"alff_api/#alff.al.active_learning.al_iteration","title":"<code>al_iteration(configfile_param, configfile_machine)</code>","text":"<p>Run main loop of active learning.</p>"},{"location":"alff_api/#alff.al.finetune","title":"<code>finetune</code>","text":""},{"location":"alff_api/#alff.al.lib_gpaw_al","title":"<code>lib_gpaw_al</code>","text":"<p>Move all the GPAW related functions to here. - functions for <code>arginfo.py</code> - functions for <code>run.py</code>.</p> <p>Functions:</p> <ul> <li> <code>pre_dft_gpaw</code>             \u2013              <p>Make input file for customized FP style.</p> </li> <li> <code>post_dft_gpaw</code>             \u2013              <p>Post fp for custom fp. Collect data from user-defined <code>output_fn</code>.</p> </li> </ul> <p>Attributes:</p> <ul> <li> <code>LIB_GPAW_PATH</code>           \u2013            </li> <li> <code>fp_name</code>           \u2013            </li> </ul>"},{"location":"alff_api/#alff.al.lib_gpaw_al.LIB_GPAW_PATH","title":"<code>LIB_GPAW_PATH = Path(f'{ROOT_PATH})/al/gpaw')</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.al.lib_gpaw_al.fp_name","title":"<code>fp_name = '02.fp'</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.al.lib_gpaw_al.pre_dft_gpaw","title":"<code>pre_dft_gpaw(iter_index, jdata)</code>","text":"<p>Make input file for customized FP style.</p>"},{"location":"alff_api/#alff.al.lib_gpaw_al.pre_dft_gpaw--parameters","title":"Parameters","text":"<p>iter_index : int     iter index jdata : dict     Run parameters.</p>"},{"location":"alff_api/#alff.al.lib_gpaw_al.post_dft_gpaw","title":"<code>post_dft_gpaw(iter_index, jdata)</code>","text":"<p>Post fp for custom fp. Collect data from user-defined <code>output_fn</code>.</p>"},{"location":"alff_api/#alff.al.lib_gpaw_al.post_dft_gpaw--parameters","title":"Parameters","text":"<p>iter_index : int     The index of the current iteration. jdata : dict     The parameter data.</p>"},{"location":"alff_api/#alff.al.lib_lammps_al","title":"<code>lib_lammps_al</code>","text":""},{"location":"alff_api/#alff.cli","title":"<code>cli</code>","text":"<p>Functions:</p> <ul> <li> <code>alff_al</code>             \u2013              <p>CLI for active learning</p> </li> <li> <code>alff_gen</code>             \u2013              <p>CLI for data generation</p> </li> <li> <code>alff_finetune</code>             \u2013              <p>CLI for fine-tuning</p> </li> <li> <code>alff_phonon</code>             \u2013              <p>CLI for phonon calculation</p> </li> <li> <code>convert_chgnet_to_xyz</code>             \u2013              <p>CLI for converting the MPCHGNet dataset to XYZ format</p> </li> <li> <code>get_args</code>             \u2013              <p>Get the arguments from the command line</p> </li> </ul>"},{"location":"alff_api/#alff.cli.alff_al","title":"<code>alff_al()</code>","text":"<p>CLI for active learning</p>"},{"location":"alff_api/#alff.cli.alff_gen","title":"<code>alff_gen()</code>","text":"<p>CLI for data generation</p>"},{"location":"alff_api/#alff.cli.alff_finetune","title":"<code>alff_finetune()</code>","text":"<p>CLI for fine-tuning</p>"},{"location":"alff_api/#alff.cli.alff_phonon","title":"<code>alff_phonon()</code>","text":"<p>CLI for phonon calculation</p>"},{"location":"alff_api/#alff.cli.convert_chgnet_to_xyz","title":"<code>convert_chgnet_to_xyz()</code>","text":"<p>CLI for converting the MPCHGNet dataset to XYZ format</p>"},{"location":"alff_api/#alff.cli.get_args","title":"<code>get_args()</code>","text":"<p>Get the arguments from the command line</p>"},{"location":"alff_api/#alff.constant","title":"<code>constant</code>","text":"<p>Attributes:</p> <ul> <li> <code>time_str</code>           \u2013            </li> <li> <code>DIR_LOG</code>           \u2013            </li> <li> <code>FILE_LOG_ALFF</code>           \u2013            </li> <li> <code>FILE_LOG_DISPATCHER</code>           \u2013            </li> <li> <code>LOGGER</code>           \u2013            </li> <li> <code>DIR_TRAIN</code>           \u2013            </li> <li> <code>DIR_MD</code>           \u2013            </li> <li> <code>DIR_DFT</code>           \u2013            </li> <li> <code>DIR_DATA</code>           \u2013            </li> <li> <code>DIR_TEMPLATE</code>           \u2013            </li> <li> <code>DIR_TMP_DATA</code>           \u2013            </li> <li> <code>DIR_TMP_MODEL</code>           \u2013            </li> <li> <code>FILE_ITER_LOG</code>           \u2013            </li> <li> <code>FILE_DATAPATH</code>           \u2013            </li> <li> <code>FILE_MODELPATH</code>           \u2013            </li> <li> <code>FILE_TRAIN_PARAM</code>           \u2013            </li> <li> <code>FILE_LAMMPS_INPUT</code>           \u2013            </li> <li> <code>FILE_LAMMPS_ARG</code>           \u2013            </li> <li> <code>train_tmpl_path</code>           \u2013            </li> <li> <code>FMT_ITER</code>           \u2013            </li> <li> <code>FMT_STAGE</code>           \u2013            </li> <li> <code>FMT_MODEL</code>           \u2013            </li> <li> <code>FMT_CONF</code>           \u2013            </li> <li> <code>FMT_TASK_MD</code>           \u2013            </li> <li> <code>FMT_TASK_DFT</code>           \u2013            </li> <li> <code>DIR_BUILD</code>           \u2013            </li> <li> <code>DIR_SCALE</code>           \u2013            </li> <li> <code>DIR_GENDATA</code>           \u2013            </li> <li> <code>FILE_FRAME_unLABELED</code>           \u2013            </li> <li> <code>FILE_FRAME_LABELED</code>           \u2013            </li> <li> <code>FILE_TRAJ_LABELED</code>           \u2013            </li> <li> <code>FILE_GPAW_DFT</code>           \u2013            </li> <li> <code>DIR_SUPERCELL</code>           \u2013            </li> <li> <code>DIR_PHONON</code>           \u2013            </li> </ul>"},{"location":"alff_api/#alff.constant.time_str","title":"<code>time_str = time.strftime('%Y%m%d_%H%M%S')</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.constant.DIR_LOG","title":"<code>DIR_LOG = 'log'</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.constant.FILE_LOG_ALFF","title":"<code>FILE_LOG_ALFF = f'{DIR_LOG}/{time_str}_alff.log'</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.constant.FILE_LOG_DISPATCHER","title":"<code>FILE_LOG_DISPATCHER = FILE_LOG_ALFF.replace('alff', 'dispatcher')</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.constant.LOGGER","title":"<code>LOGGER = create_logger('alff', level='INFO', log_file=FILE_LOG_ALFF)</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.constant.DIR_TRAIN","title":"<code>DIR_TRAIN = '00_train'</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.constant.DIR_MD","title":"<code>DIR_MD = '01_md'</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.constant.DIR_DFT","title":"<code>DIR_DFT = '02_dft'</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.constant.DIR_DATA","title":"<code>DIR_DATA = '03_data'</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.constant.DIR_TEMPLATE","title":"<code>DIR_TEMPLATE = 'template'</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.constant.DIR_TMP_DATA","title":"<code>DIR_TMP_DATA = 'copied_data'</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.constant.DIR_TMP_MODEL","title":"<code>DIR_TMP_MODEL = 'copied_model'</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.constant.FILE_ITER_LOG","title":"<code>FILE_ITER_LOG = 'alff_iter.record'</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.constant.FILE_DATAPATH","title":"<code>FILE_DATAPATH = 'data_paths.yaml'</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.constant.FILE_MODELPATH","title":"<code>FILE_MODELPATH = 'model_paths.yaml'</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.constant.FILE_TRAIN_PARAM","title":"<code>FILE_TRAIN_PARAM = 'train_param.yaml'</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.constant.FILE_LAMMPS_INPUT","title":"<code>FILE_LAMMPS_INPUT = 'lammps_input.in'</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.constant.FILE_LAMMPS_ARG","title":"<code>FILE_LAMMPS_ARG = 'lammps_param.yaml'</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.constant.train_tmpl_path","title":"<code>train_tmpl_path = os.path.join(DIR_TEMPLATE, DIR_TRAIN)</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.constant.FMT_ITER","title":"<code>FMT_ITER = '06d'</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.constant.FMT_STAGE","title":"<code>FMT_STAGE = '02d'</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.constant.FMT_MODEL","title":"<code>FMT_MODEL = '03d'</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.constant.FMT_CONF","title":"<code>FMT_CONF = '04d'</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.constant.FMT_TASK_MD","title":"<code>FMT_TASK_MD = '06d'</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.constant.FMT_TASK_DFT","title":"<code>FMT_TASK_DFT = '06d'</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.constant.DIR_BUILD","title":"<code>DIR_BUILD = '00_build_structure'</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.constant.DIR_SCALE","title":"<code>DIR_SCALE = '01_scale_perturb'</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.constant.DIR_GENDATA","title":"<code>DIR_GENDATA = '02_gendata'</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.constant.FILE_FRAME_unLABELED","title":"<code>FILE_FRAME_unLABELED = 'conf.extxyz'</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.constant.FILE_FRAME_LABELED","title":"<code>FILE_FRAME_LABELED = 'conf_labeled.extxyz'</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.constant.FILE_TRAJ_LABELED","title":"<code>FILE_TRAJ_LABELED = 'traj_labeled.extxyz'</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.constant.FILE_GPAW_DFT","title":"<code>FILE_GPAW_DFT = 'gpaw_dft.yaml'</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.constant.DIR_SUPERCELL","title":"<code>DIR_SUPERCELL = '01_supercell'</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.constant.DIR_PHONON","title":"<code>DIR_PHONON = '02_phonon'</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.data","title":"<code>data</code>","text":"<p>Modules:</p> <ul> <li> <code>convert_mpchgnet_to_xyz</code>           \u2013            </li> <li> <code>gendata</code>           \u2013            </li> <li> <code>lib_gpaw_gendata</code>           \u2013            <p>NOTE:</p> </li> </ul>"},{"location":"alff_api/#alff.data.convert_mpchgnet_to_xyz","title":"<code>convert_mpchgnet_to_xyz</code>","text":"<p>Functions:</p> <ul> <li> <code>chgnet_to_ase_atoms</code>             \u2013              </li> <li> <code>run_convert</code>             \u2013              </li> </ul> <p>Attributes:</p> <ul> <li> <code>info_keys</code>           \u2013            </li> </ul>"},{"location":"alff_api/#alff.data.convert_mpchgnet_to_xyz.info_keys","title":"<code>info_keys = ['uncorrected_total_energy', 'corrected_total_energy', 'energy_per_atom', 'ef_per_atom', 'e_per_atom_relaxed', 'ef_per_atom_relaxed', 'magmom', 'bandgap', 'mp_id']</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.data.convert_mpchgnet_to_xyz.chgnet_to_ase_atoms","title":"<code>chgnet_to_ase_atoms(datum: dict[str, dict[str, Any]]) -&gt; list[Atoms]</code>","text":""},{"location":"alff_api/#alff.data.convert_mpchgnet_to_xyz.run_convert","title":"<code>run_convert()</code>","text":""},{"location":"alff_api/#alff.data.gendata","title":"<code>gendata</code>","text":"<p>Functions:</p> <ul> <li> <code>build_structure</code>             \u2013              <p>Build structures based on input parameters</p> </li> <li> <code>optimize_structure</code>             \u2013              <p>Optimize the structures</p> </li> <li> <code>scale_perturb_structure</code>             \u2013              <p>Scale and perturb the structures</p> </li> <li> <code>copy_structure_files</code>             \u2013              <p>Copy structure files (both labeled or unlabeled) from source directory to destination directory, and rename to FILE_FRAME_unLABELED</p> </li> <li> <code>symlink_structure_files</code>             \u2013              <p>Symlink structure files (both labeled or unlabeled) from source directory to destination directory</p> </li> <li> <code>scale_x_dim</code>             \u2013              <p>Scale the x dimension of the structures</p> </li> <li> <code>scale_y_dim</code>             \u2013              <p>Scale the y dimension of the structures</p> </li> <li> <code>scale_z_dim</code>             \u2013              <p>Scale the z dimension of the structures</p> </li> <li> <code>perturb_structure</code>             \u2013              <p>Perturb the structures</p> </li> <li> <code>run_dft</code>             \u2013              <p>Run DFT calculations</p> </li> <li> <code>collect_data</code>             \u2013              <p>Collect data from DFT simulations</p> </li> <li> <code>data_generator</code>             \u2013              <p>Generate initial data for training ML models</p> </li> </ul>"},{"location":"alff_api/#alff.data.gendata.build_structure","title":"<code>build_structure(pdict, mdict)</code>","text":"<p>Build structures based on input parameters</p>"},{"location":"alff_api/#alff.data.gendata.optimize_structure","title":"<code>optimize_structure(pdict, mdict)</code>","text":"<p>Optimize the structures</p>"},{"location":"alff_api/#alff.data.gendata.scale_perturb_structure","title":"<code>scale_perturb_structure(pdict, mdict)</code>","text":"<p>Scale and perturb the structures</p>"},{"location":"alff_api/#alff.data.gendata.copy_structure_files","title":"<code>copy_structure_files(src_dir: str, dest_dir: str)</code>","text":"<p>Copy structure files (both labeled or unlabeled) from source directory to destination directory, and rename to FILE_FRAME_unLABELED</p>"},{"location":"alff_api/#alff.data.gendata.symlink_structure_files","title":"<code>symlink_structure_files(src_dir: str, dest_dir: str)</code>","text":"<p>Symlink structure files (both labeled or unlabeled) from source directory to destination directory</p>"},{"location":"alff_api/#alff.data.gendata.scale_x_dim","title":"<code>scale_x_dim(struct_files: list, scale_x_list: list)</code>","text":"<p>Scale the x dimension of the structures</p>"},{"location":"alff_api/#alff.data.gendata.scale_y_dim","title":"<code>scale_y_dim(struct_files: list, scale_y_list: list)</code>","text":"<p>Scale the y dimension of the structures</p>"},{"location":"alff_api/#alff.data.gendata.scale_z_dim","title":"<code>scale_z_dim(struct_files: list, scale_z_list: list)</code>","text":"<p>Scale the z dimension of the structures</p>"},{"location":"alff_api/#alff.data.gendata.perturb_structure","title":"<code>perturb_structure(struct_files: list, perturb_num: int, perturb_disp: float)</code>","text":"<p>Perturb the structures</p>"},{"location":"alff_api/#alff.data.gendata._total_conf_num","title":"<code>_total_conf_num(pdict: dict)</code>","text":""},{"location":"alff_api/#alff.data.gendata.run_dft","title":"<code>run_dft(pdict, mdict)</code>","text":"<p>Run DFT calculations</p>"},{"location":"alff_api/#alff.data.gendata.collect_data","title":"<code>collect_data(pdict, mdict)</code>","text":"<p>Collect data from DFT simulations</p>"},{"location":"alff_api/#alff.data.gendata.data_generator","title":"<code>data_generator(configfile_param: str, configfile_machine: str)</code>","text":"<p>Generate initial data for training ML models</p>"},{"location":"alff_api/#alff.data.lib_gpaw_gendata","title":"<code>lib_gpaw_gendata</code>","text":"<p>NOTE: - do not use <code>return</code> in the functions that run <code>dpdispatcher.submission()</code>. - work_path is a folder relative to the run_path - task_paths is folders relative to the work_path</p> <p>Functions:</p> <ul> <li> <code>pregen_gpaw_optimize</code>             \u2013              <p>This function does:</p> </li> <li> <code>rungen_gpaw_optimize</code>             \u2013              <p>This function does:</p> </li> <li> <code>postgen_gpaw_optimize</code>             \u2013              <p>This function does:</p> </li> <li> <code>pregen_gpaw_singlepoint</code>             \u2013              <p>Refer to the <code>pregen_gpaw_optimize()</code> function.</p> </li> <li> <code>rungen_gpaw_singlepoint</code>             \u2013              <p>Refer to the <code>rungen_gpaw_optimize()</code> function.</p> </li> <li> <code>postgen_gpaw_singlepoint</code>             \u2013              <p>Refer to the <code>postgen_gpaw_optimize()</code> function.</p> </li> <li> <code>pregen_gpaw_aimd</code>             \u2013              <p>Refer to the <code>pregen_gpaw_optimize()</code> function.</p> </li> <li> <code>rungen_gpaw_aimd</code>             \u2013              <p>Refer to the <code>rungen_gpaw_optimize()</code> function.</p> </li> <li> <code>postgen_gpaw_aimd</code>             \u2013              <p>Refer to the <code>postgen_gpaw_optimize()</code> function.</p> </li> <li> <code>check_gpaw_input</code>             \u2013              <p>Check the input files for the GPAW calculation, to ensure some necessary fields are set.</p> </li> <li> <code>sort_dft_task_paths</code>             \u2013              <p>Sort the structure paths by its supercell size.</p> </li> </ul> <p>Attributes:</p> <ul> <li> <code>LIB_GPAW_PATH</code>           \u2013            </li> </ul>"},{"location":"alff_api/#alff.data.lib_gpaw_gendata.LIB_GPAW_PATH","title":"<code>LIB_GPAW_PATH = Path(f'{ROOT_PATH}/lib/gpaw')</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.data.lib_gpaw_gendata.pregen_gpaw_optimize","title":"<code>pregen_gpaw_optimize(work_path, pdict)</code>","text":"<p>This function does: - Prepare task_paths: select only unlabeled structures to compute at clusters. - Prepare gpaw_dft and gpaw_run_file</p>"},{"location":"alff_api/#alff.data.lib_gpaw_gendata.rungen_gpaw_optimize","title":"<code>rungen_gpaw_optimize(work_path, pdict, mdict)</code>","text":"<p>This function does: - Prepare command_list - Read task_paths from .yaml file - Prepare fordward &amp; backward files - Submit jobs to the cluster - Download the results when finished</p>"},{"location":"alff_api/#alff.data.lib_gpaw_gendata.postgen_gpaw_optimize","title":"<code>postgen_gpaw_optimize(work_path, pdict)</code>","text":"<p>This function does: - Remove unlabeled .extxyz files, just keep the labeled ones.</p>"},{"location":"alff_api/#alff.data.lib_gpaw_gendata.pregen_gpaw_singlepoint","title":"<code>pregen_gpaw_singlepoint(work_path, pdict)</code>","text":"<p>Refer to the <code>pregen_gpaw_optimize()</code> function.</p>"},{"location":"alff_api/#alff.data.lib_gpaw_gendata.rungen_gpaw_singlepoint","title":"<code>rungen_gpaw_singlepoint(work_path, pdict, mdict)</code>","text":"<p>Refer to the <code>rungen_gpaw_optimize()</code> function.</p>"},{"location":"alff_api/#alff.data.lib_gpaw_gendata.postgen_gpaw_singlepoint","title":"<code>postgen_gpaw_singlepoint(work_path, pdict)</code>","text":"<p>Refer to the <code>postgen_gpaw_optimize()</code> function.</p>"},{"location":"alff_api/#alff.data.lib_gpaw_gendata.pregen_gpaw_aimd","title":"<code>pregen_gpaw_aimd(work_path, pdict)</code>","text":"<p>Refer to the <code>pregen_gpaw_optimize()</code> function.</p>"},{"location":"alff_api/#alff.data.lib_gpaw_gendata.rungen_gpaw_aimd","title":"<code>rungen_gpaw_aimd(work_path, pdict, mdict)</code>","text":"<p>Refer to the <code>rungen_gpaw_optimize()</code> function.</p>"},{"location":"alff_api/#alff.data.lib_gpaw_gendata.postgen_gpaw_aimd","title":"<code>postgen_gpaw_aimd(work_path, pdict)</code>","text":"<p>Refer to the <code>postgen_gpaw_optimize()</code> function.</p>"},{"location":"alff_api/#alff.data.lib_gpaw_gendata.check_gpaw_input","title":"<code>check_gpaw_input(input_file: str) -&gt; None</code>","text":"<p>Check the input files for the GPAW calculation, to ensure some necessary fields are set.</p>"},{"location":"alff_api/#alff.data.lib_gpaw_gendata.sort_dft_task_paths","title":"<code>sort_dft_task_paths(task_paths: list, work_path: str) -&gt; list</code>","text":"<p>Sort the structure paths by its supercell size. This helps to chunk the tasks with similar supercell size together (similar supercell size means similar k-point number), which then lead to running DFT calculations in similar time, avoiding the situation that some tasks are finished while others are still running.</p>"},{"location":"alff_api/#alff.elastic","title":"<code>elastic</code>","text":"<p>Modules:</p> <ul> <li> <code>elastic</code>           \u2013            </li> </ul>"},{"location":"alff_api/#alff.elastic.elastic","title":"<code>elastic</code>","text":""},{"location":"alff_api/#alff.lib","title":"<code>lib</code>","text":"<p>Modules:</p> <ul> <li> <code>argument_docs</code>           \u2013            <p><code>alff</code> accepts a configuration file in YAML/JSON/JSONC format.</p> </li> <li> <code>deepmdkit_model_devi</code>           \u2013            </li> <li> <code>gpaw</code>           \u2013            </li> <li> <code>lib_dispatcher</code>           \u2013            </li> <li> <code>tool_conf</code>           \u2013            </li> <li> <code>util</code>           \u2013            <p>some common utilities for generator, auto_test and data</p> </li> </ul>"},{"location":"alff_api/#alff.lib.argument_docs","title":"<code>argument_docs</code>","text":"<p><code>alff</code> accepts a configuration file in YAML/JSON/JSONC format.</p> <p>Functions:</p> <ul> <li> <code>param</code>             \u2013              <p>ALFF parameters.</p> </li> <li> <code>not_use_param_seveen</code>             \u2013              <p>SevenNet parameters that are not applicable.</p> </li> <li> <code>machine</code>             \u2013              <p>ALFF parameters for running on a clusters.</p> </li> </ul>"},{"location":"alff_api/#alff.lib.argument_docs.param","title":"<code>param()</code>","text":"<p>ALFF parameters.</p>"},{"location":"alff_api/#alff.lib.argument_docs.param--parameters","title":"Parameters","text":"<pre><code>mlp_engine: str\n    The engine to use for training the MLP model. Choices: 'sevenn', 'mace'\nnumb_models: int\n    Number of models to train.\ninit_data_paths: list[str]\n    List of paths to the initial data.\ndistributed: bool\n    Whether to use distributed training.\ndistributed_backend: str\n    The Pytorch backend to use for distributed training. Choices: 'nccl', 'mpi'\nsevenn_args: dict\n    SevenNet's parameters.\nmace_args: dict\n    Mace's parameters.\n</code></pre>"},{"location":"alff_api/#alff.lib.argument_docs.not_use_param_seveen","title":"<code>not_use_param_seveen()</code>","text":"<p>SevenNet parameters that are not applicable.</p> <p>These parameters are either generated by the ALFF or are not required for running the ALFF.</p>"},{"location":"alff_api/#alff.lib.argument_docs.not_use_param_seveen--parameters","title":"Parameters","text":"<pre><code>train.random_seed: int\n    Random seed for reproducibility.\ndata.load_dataset_path: list[str]\n    List of paths to the dataset.\n</code></pre>"},{"location":"alff_api/#alff.lib.argument_docs.machine","title":"<code>machine()</code>","text":"<p>ALFF parameters for running on a clusters.</p>"},{"location":"alff_api/#alff.lib.deepmdkit_model_devi","title":"<code>deepmdkit_model_devi</code>","text":"<p>Functions:</p> <ul> <li> <code>calc_model_devi_f</code>             \u2013              <p>Calculate model deviation of force.</p> </li> <li> <code>calc_model_devi_e</code>             \u2013              <p>Calculate model deviation of total energy per atom.</p> </li> <li> <code>calc_model_devi_v</code>             \u2013              <p>Calculate model deviation of virial.</p> </li> <li> <code>write_model_devi_out</code>             \u2013              <p>Write output of model deviation.</p> </li> <li> <code>calc_model_devi</code>             \u2013              <p>Python interface to calculate model deviation.</p> </li> <li> <code>make_model_devi</code>             \u2013              <p>Make model deviation calculation.</p> </li> </ul>"},{"location":"alff_api/#alff.lib.deepmdkit_model_devi.calc_model_devi_f","title":"<code>calc_model_devi_f(fs: np.ndarray, real_f: Optional[np.ndarray] = None, relative: Optional[float] = None, atomic: bool = False) -&gt; Tuple[np.ndarray, ...]</code>","text":"<pre><code>calc_model_devi_f(fs: np.ndarray, real_f: Optional[np.ndarray] = None, relative: Optional[float] = None, atomic: Literal[False] = False) -&gt; Tuple[np.ndarray, np.ndarray, np.ndarray]\n</code></pre><pre><code>calc_model_devi_f(fs: np.ndarray, real_f: Optional[np.ndarray] = None, relative: Optional[float] = None, *, atomic: Literal[True]) -&gt; Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray]\n</code></pre> <p>Calculate model deviation of force.</p>"},{"location":"alff_api/#alff.lib.deepmdkit_model_devi.calc_model_devi_f--parameters","title":"Parameters","text":"<p>fs : numpy.ndarray     size of <code>n_models x n_frames x n_atoms x 3</code> real_f : numpy.ndarray or None     real force, size of <code>n_frames x n_atoms x 3</code>. If given,     the RMS real error is calculated instead. relative : float, default: None     If given, calculate the relative model deviation of force. The     value is the level parameter for computing the relative model     deviation of the force. atomic : bool, default: False     Whether return deviation of force in all atoms</p>"},{"location":"alff_api/#alff.lib.deepmdkit_model_devi.calc_model_devi_f--returns","title":"Returns","text":"<p>max_devi_f : numpy.ndarray     maximum deviation of force in all atoms min_devi_f : numpy.ndarray     minimum deviation of force in all atoms avg_devi_f : numpy.ndarray     average deviation of force in all atoms fs_devi : numpy.ndarray     deviation of force in all atoms, returned if atomic=True</p>"},{"location":"alff_api/#alff.lib.deepmdkit_model_devi.calc_model_devi_e","title":"<code>calc_model_devi_e(es: np.ndarray, real_e: Optional[np.ndarray] = None) -&gt; np.ndarray</code>","text":"<p>Calculate model deviation of total energy per atom.</p> <p>Here we don't use the atomic energy, as the decomposition of energy is arbitrary and not unique. There is no fitting target for atomic energy.</p>"},{"location":"alff_api/#alff.lib.deepmdkit_model_devi.calc_model_devi_e--parameters","title":"Parameters","text":"<p>es : numpy.ndarray     size of <code>n_models x n_frames x 1 real_e : numpy.ndarray     real energy, size of</code>n_frames x 1`. If given,     the RMS real error is calculated instead.</p>"},{"location":"alff_api/#alff.lib.deepmdkit_model_devi.calc_model_devi_e--returns","title":"Returns","text":"<p>max_devi_e : numpy.ndarray     maximum deviation of energy</p>"},{"location":"alff_api/#alff.lib.deepmdkit_model_devi.calc_model_devi_v","title":"<code>calc_model_devi_v(vs: np.ndarray, real_v: Optional[np.ndarray] = None, relative: Optional[float] = None) -&gt; Tuple[np.ndarray, np.ndarray, np.ndarray]</code>","text":"<p>Calculate model deviation of virial.</p>"},{"location":"alff_api/#alff.lib.deepmdkit_model_devi.calc_model_devi_v--parameters","title":"Parameters","text":"<p>vs : numpy.ndarray     size of <code>n_models x n_frames x 9</code> real_v : numpy.ndarray     real virial, size of <code>n_frames x 9</code>. If given,     the RMS real error is calculated instead. relative : float, default: None     If given, calculate the relative model deviation of virial. The     value is the level parameter for computing the relative model     deviation of the virial.</p>"},{"location":"alff_api/#alff.lib.deepmdkit_model_devi.calc_model_devi_v--returns","title":"Returns","text":"<p>max_devi_v : numpy.ndarray     maximum deviation of virial in 9 elements min_devi_v : numpy.ndarray     minimum deviation of virial in 9 elements avg_devi_v : numpy.ndarray     average deviation of virial in 9 elements</p>"},{"location":"alff_api/#alff.lib.deepmdkit_model_devi.write_model_devi_out","title":"<code>write_model_devi_out(devi: np.ndarray, fname: str, header: str = '', atomic: bool = False)</code>","text":"<p>Write output of model deviation.</p>"},{"location":"alff_api/#alff.lib.deepmdkit_model_devi.write_model_devi_out--parameters","title":"Parameters","text":"<p>devi : numpy.ndarray     the first column is the steps index fname : str     the file name to dump header : str, default=\"\"     the header to dump atomic : bool, default: False     whether atomic model deviation is printed</p>"},{"location":"alff_api/#alff.lib.deepmdkit_model_devi._check_tmaps","title":"<code>_check_tmaps(tmaps, ref_tmap=None)</code>","text":"<p>Check whether type maps are identical.</p>"},{"location":"alff_api/#alff.lib.deepmdkit_model_devi.calc_model_devi","title":"<code>calc_model_devi(coord, box, atype, models, fname=None, frequency=1, mixed_type=False, fparam: Optional[np.ndarray] = None, aparam: Optional[np.ndarray] = None, real_data: Optional[dict] = None, atomic: bool = False, relative: Optional[float] = None, relative_v: Optional[float] = None)</code>","text":"<p>Python interface to calculate model deviation.</p>"},{"location":"alff_api/#alff.lib.deepmdkit_model_devi.calc_model_devi--parameters","title":"Parameters","text":"<p>coord : numpy.ndarray, <code>n_frames x n_atoms x 3</code>     Coordinates of system to calculate box : numpy.ndarray or None, <code>n_frames x 3 x 3</code>     Box to specify periodic boundary condition. If None, no pbc will be used atype : numpy.ndarray, <code>n_atoms x 1</code>     Atom types models : list of DeepPot models     Models used to evaluate deviation fname : str or None     File to dump results, default None frequency : int     Steps between frames (if the system is given by molecular dynamics engine), default 1 mixed_type : bool     Whether the input atype is in mixed_type format or not fparam : numpy.ndarray     frame specific parameters aparam : numpy.ndarray     atomic specific parameters real_data : dict, optional     real data to calculate RMS real error atomic : bool, default: False     If True, calculate the force model deviation of each atom. relative : float, default: None     If given, calculate the relative model deviation of force. The     value is the level parameter for computing the relative model     deviation of the force. relative_v : float, default: None     If given, calculate the relative model deviation of virial. The     value is the level parameter for computing the relative model     deviation of the virial.</p>"},{"location":"alff_api/#alff.lib.deepmdkit_model_devi.calc_model_devi--returns","title":"Returns","text":"<p>model_devi : numpy.ndarray, <code>n_frames x 8</code>     Model deviation results. The first column is index of steps, the other 7 columns are     max_devi_v, min_devi_v, avg_devi_v, max_devi_f, min_devi_f, avg_devi_f, devi_e.</p>"},{"location":"alff_api/#alff.lib.deepmdkit_model_devi.calc_model_devi--examples","title":"Examples","text":"<p>from deepmd.infer import calc_model_devi from deepmd.infer import DeepPot as DP import numpy as np coord = np.array([[1,0,0], [0,0,1.5], [1,0,3]]).reshape([1, -1]) cell = np.diag(10 * np.ones(3)).reshape([1, -1]) atype = [1,0,1] graphs = [DP(\"graph.000.pb\"), DP(\"graph.001.pb\")] model_devi = calc_model_devi(coord, cell, atype, graphs)</p>"},{"location":"alff_api/#alff.lib.deepmdkit_model_devi.make_model_devi","title":"<code>make_model_devi(*, models: list, system: str, set_prefix: str, output: str, frequency: int, real_error: bool = False, atomic: bool = False, relative: Optional[float] = None, relative_v: Optional[float] = None, **kwargs)</code>","text":"<p>Make model deviation calculation.</p>"},{"location":"alff_api/#alff.lib.deepmdkit_model_devi.make_model_devi--parameters","title":"Parameters","text":"<p>models : list     A list of paths of models to use for making model deviation system : str     The path of system to make model deviation calculation set_prefix : str     The set prefix of the system output : str     The output file for model deviation results frequency : int     The number of steps that elapse between writing coordinates     in a trajectory by a MD engine (such as Gromacs / Lammps).     This paramter is used to determine the index in the output file. real_error : bool, default: False     If True, calculate the RMS real error instead of model deviation. atomic : bool, default: False     If True, calculate the force model deviation of each atom. relative : float, default: None     If given, calculate the relative model deviation of force. The     value is the level parameter for computing the relative model     deviation of the force. relative_v : float, default: None     If given, calculate the relative model deviation of virial. The     value is the level parameter for computing the relative model     deviation of the virial. **kwargs     Arbitrary keyword arguments.</p>"},{"location":"alff_api/#alff.lib.gpaw","title":"<code>gpaw</code>","text":"<p>Modules:</p> <ul> <li> <code>cli_gpaw_aimd</code>           \u2013            <p>Some notes:</p> </li> <li> <code>cli_gpaw_optimize</code>           \u2013            <p>Some notes</p> </li> <li> <code>cli_gpaw_singlepoint</code>           \u2013            <p>Some notes</p> </li> </ul>"},{"location":"alff_api/#alff.lib.gpaw.cli_gpaw_aimd","title":"<code>cli_gpaw_aimd</code>","text":"<p>Some notes: - Run MD in ase following this tutorial: https://wiki.fysik.dtu.dk/ase/tutorials/md/md.html - Must set txt='calc.txt' in GPAW calculator for backward files. - param_yaml must contain     - a dict <code>gpaw</code> with GPAW parameters.     - a dict <code>aimd</code> with ASE MD parameters. - For MD run, control symmetry to avoid error: <code>broken symmetry</code>.</p> <p>Functions:</p> <ul> <li> <code>print_properties</code>             \u2013              <p>Function to print the potential, kinetic and total energy.</p> </li> <li> <code>write_xyz</code>             \u2013              </li> </ul> <p>Attributes:</p> <ul> <li> <code>parser</code>           \u2013            </li> <li> <code>args</code>           \u2013            </li> <li> <code>configfile</code>           \u2013            </li> <li> <code>pdict</code>           \u2013            </li> <li> <code>extxyz_file</code>           \u2013            </li> <li> <code>atoms</code>           \u2013            </li> <li> <code>params</code>           \u2013            </li> <li> <code>gpaw_arg</code>           \u2013            </li> <li> <code>calc</code>           \u2013            </li> <li> <code>aimd</code>           \u2013            </li> <li> <code>dt</code>           \u2013            </li> <li> <code>temperature</code>           \u2013            </li> <li> <code>ensemble</code>           \u2013            </li> <li> <code>collect_frames</code>           \u2013            </li> <li> <code>dump_freq</code>           \u2013            </li> <li> <code>nsteps</code>           \u2013            </li> <li> <code>dyn</code>           \u2013            </li> </ul>"},{"location":"alff_api/#alff.lib.gpaw.cli_gpaw_aimd.parser","title":"<code>parser = argparse.ArgumentParser(description='Optimize structure using GPAW')</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.lib.gpaw.cli_gpaw_aimd.args","title":"<code>args = parser.parse_args()</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.lib.gpaw.cli_gpaw_aimd.configfile","title":"<code>configfile = args.param</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.lib.gpaw.cli_gpaw_aimd.pdict","title":"<code>pdict = load_setting_file(configfile)</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.lib.gpaw.cli_gpaw_aimd.extxyz_file","title":"<code>extxyz_file = pdict['input_extxyz_path']</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.lib.gpaw.cli_gpaw_aimd.atoms","title":"<code>atoms = read(extxyz_file, format='extxyz', index='-1')</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.lib.gpaw.cli_gpaw_aimd.params","title":"<code>params = {'mode': {'name': 'pw', 'ecut': 500}, 'xc': 'PBE', 'convergence': {'energy': 1e-06, 'density': 0.0001, 'eigenstates': 1e-08}, 'occupations': {'name': 'fermi-dirac', 'width': 0.01}, 'txt': 'calc_aimd.txt', 'symmetry': 'off'}</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.lib.gpaw.cli_gpaw_aimd.gpaw_arg","title":"<code>gpaw_arg = pdict.get('gpaw_arg', {})</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.lib.gpaw.cli_gpaw_aimd.calc","title":"<code>calc = GPAW(**params)</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.lib.gpaw.cli_gpaw_aimd.aimd","title":"<code>aimd = pdict.get('aimd', {})</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.lib.gpaw.cli_gpaw_aimd.dt","title":"<code>dt = aimd.get('dt', 1)</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.lib.gpaw.cli_gpaw_aimd.temperature","title":"<code>temperature = aimd.get('temperature', 300)</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.lib.gpaw.cli_gpaw_aimd.ensemble","title":"<code>ensemble = aimd.get('ensemble', 'NVE')</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.lib.gpaw.cli_gpaw_aimd.collect_frames","title":"<code>collect_frames = aimd.get('collect_frames', 5)</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.lib.gpaw.cli_gpaw_aimd.dump_freq","title":"<code>dump_freq = aimd.get('dump_freq', 1)</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.lib.gpaw.cli_gpaw_aimd.nsteps","title":"<code>nsteps = collect_frames * dump_freq</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.lib.gpaw.cli_gpaw_aimd.dyn","title":"<code>dyn = VelocityVerlet(atoms, timestep=dt * units.fs)</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.lib.gpaw.cli_gpaw_aimd.print_properties","title":"<code>print_properties(atoms=atoms, filename='calc_properties.txt')</code>","text":"<p>Function to print the potential, kinetic and total energy.</p>"},{"location":"alff_api/#alff.lib.gpaw.cli_gpaw_aimd.write_xyz","title":"<code>write_xyz(atoms=atoms, filename='traj_labeled.extxyz')</code>","text":""},{"location":"alff_api/#alff.lib.gpaw.cli_gpaw_optimize","title":"<code>cli_gpaw_optimize</code>","text":"<p>Some notes - Must set txt='calc.txt' in GPAW calculator for backward files. - param_yaml must contain     - a dict <code>gpaw</code> with GPAW parameters.     - a dict <code>optimize</code> with ASE optimization parameters.</p> <p>Attributes:</p> <ul> <li> <code>parser</code>           \u2013            </li> <li> <code>args</code>           \u2013            </li> <li> <code>configfile</code>           \u2013            </li> <li> <code>pdict</code>           \u2013            </li> <li> <code>extxyz_file</code>           \u2013            </li> <li> <code>atoms</code>           \u2013            </li> <li> <code>params</code>           \u2013            </li> <li> <code>gpaw_arg</code>           \u2013            </li> <li> <code>calc</code>           \u2013            </li> <li> <code>opt_args</code>           \u2013            </li> <li> <code>relax_dim</code>           \u2013            </li> <li> <code>pbc</code>           \u2013            </li> <li> <code>fmax</code>           \u2013            </li> <li> <code>max_steps</code>           \u2013            </li> <li> <code>atoms_filter</code>           \u2013            </li> <li> <code>opt</code>           \u2013            </li> <li> <code>pot_energy</code>           \u2013            </li> <li> <code>forces</code>           \u2013            </li> <li> <code>stress</code>           \u2013            </li> <li> <code>atoms_fake</code>           \u2013            </li> <li> <code>output_file</code>           \u2013            </li> </ul>"},{"location":"alff_api/#alff.lib.gpaw.cli_gpaw_optimize.parser","title":"<code>parser = argparse.ArgumentParser(description='Optimize structure using GPAW')</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.lib.gpaw.cli_gpaw_optimize.args","title":"<code>args = parser.parse_args()</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.lib.gpaw.cli_gpaw_optimize.configfile","title":"<code>configfile = args.param</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.lib.gpaw.cli_gpaw_optimize.pdict","title":"<code>pdict = load_setting_file(configfile)</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.lib.gpaw.cli_gpaw_optimize.extxyz_file","title":"<code>extxyz_file = pdict['input_extxyz_path']</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.lib.gpaw.cli_gpaw_optimize.atoms","title":"<code>atoms = read(extxyz_file, format='extxyz', index='-1')</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.lib.gpaw.cli_gpaw_optimize.params","title":"<code>params = {'mode': {'name': 'pw', 'ecut': 500}, 'xc': 'PBE', 'convergence': {'energy': 1e-06, 'density': 0.0001, 'eigenstates': 1e-08}, 'occupations': {'name': 'fermi-dirac', 'width': 0.01}, 'txt': 'calc_optimize.txt'}</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.lib.gpaw.cli_gpaw_optimize.gpaw_arg","title":"<code>gpaw_arg = pdict.get('gpaw_arg', {})</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.lib.gpaw.cli_gpaw_optimize.calc","title":"<code>calc = GPAW(**params)</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.lib.gpaw.cli_gpaw_optimize.opt_args","title":"<code>opt_args = pdict.get('optimize', {})</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.lib.gpaw.cli_gpaw_optimize.relax_dim","title":"<code>relax_dim = opt_args.get('relax_dim', None)</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.lib.gpaw.cli_gpaw_optimize.pbc","title":"<code>pbc = atoms.get_pbc()</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.lib.gpaw.cli_gpaw_optimize.fmax","title":"<code>fmax = opt_args.get('fmax', 0.05)</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.lib.gpaw.cli_gpaw_optimize.max_steps","title":"<code>max_steps = opt_args.get('max_steps', 10000)</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.lib.gpaw.cli_gpaw_optimize.atoms_filter","title":"<code>atoms_filter = FrechetCellFilter(atoms, mask=relax_dim)</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.lib.gpaw.cli_gpaw_optimize.opt","title":"<code>opt = BFGS(atoms_filter)</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.lib.gpaw.cli_gpaw_optimize.pot_energy","title":"<code>pot_energy = atoms.get_potential_energy()</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.lib.gpaw.cli_gpaw_optimize.forces","title":"<code>forces = atoms.get_forces()</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.lib.gpaw.cli_gpaw_optimize.stress","title":"<code>stress = atoms.get_stress(voigt=True)</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.lib.gpaw.cli_gpaw_optimize.atoms_fake","title":"<code>atoms_fake = atoms.copy()</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.lib.gpaw.cli_gpaw_optimize.output_file","title":"<code>output_file = extxyz_file.replace('.extxyz', '_labeled.extxyz')</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.lib.gpaw.cli_gpaw_singlepoint","title":"<code>cli_gpaw_singlepoint</code>","text":"<p>Some notes - Must set txt='calc.txt' in GPAW calculator for backward files. - param_yaml must contain     - a dict <code>gpaw</code> with GPAW parameters.</p> <p>Attributes:</p> <ul> <li> <code>parser</code>           \u2013            </li> <li> <code>args</code>           \u2013            </li> <li> <code>configfile</code>           \u2013            </li> <li> <code>pdict</code>           \u2013            </li> <li> <code>extxyz_file</code>           \u2013            </li> <li> <code>atoms</code>           \u2013            </li> <li> <code>params</code>           \u2013            </li> <li> <code>gpaw_arg</code>           \u2013            </li> <li> <code>calc</code>           \u2013            </li> <li> <code>pot_energy</code>           \u2013            </li> <li> <code>forces</code>           \u2013            </li> <li> <code>stress</code>           \u2013            </li> <li> <code>atoms_fake</code>           \u2013            </li> <li> <code>output_file</code>           \u2013            </li> </ul>"},{"location":"alff_api/#alff.lib.gpaw.cli_gpaw_singlepoint.parser","title":"<code>parser = argparse.ArgumentParser(description='Optimize structure using GPAW')</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.lib.gpaw.cli_gpaw_singlepoint.args","title":"<code>args = parser.parse_args()</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.lib.gpaw.cli_gpaw_singlepoint.configfile","title":"<code>configfile = args.param</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.lib.gpaw.cli_gpaw_singlepoint.pdict","title":"<code>pdict = load_setting_file(configfile)</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.lib.gpaw.cli_gpaw_singlepoint.extxyz_file","title":"<code>extxyz_file = pdict['input_extxyz_path']</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.lib.gpaw.cli_gpaw_singlepoint.atoms","title":"<code>atoms = read(extxyz_file, format='extxyz', index='-1')</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.lib.gpaw.cli_gpaw_singlepoint.params","title":"<code>params = {'mode': {'name': 'pw', 'ecut': 500}, 'xc': 'PBE', 'convergence': {'energy': 1e-06, 'density': 0.0001, 'eigenstates': 1e-08}, 'occupations': {'name': 'fermi-dirac', 'width': 0.01}, 'txt': 'calc_singlepoint.txt'}</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.lib.gpaw.cli_gpaw_singlepoint.gpaw_arg","title":"<code>gpaw_arg = pdict.get('gpaw_arg', {})</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.lib.gpaw.cli_gpaw_singlepoint.calc","title":"<code>calc = GPAW(**params)</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.lib.gpaw.cli_gpaw_singlepoint.pot_energy","title":"<code>pot_energy = atoms.get_potential_energy()</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.lib.gpaw.cli_gpaw_singlepoint.forces","title":"<code>forces = atoms.get_forces()</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.lib.gpaw.cli_gpaw_singlepoint.stress","title":"<code>stress = atoms.get_stress(voigt=True)</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.lib.gpaw.cli_gpaw_singlepoint.atoms_fake","title":"<code>atoms_fake = atoms.copy()</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.lib.gpaw.cli_gpaw_singlepoint.output_file","title":"<code>output_file = extxyz_file.replace('.extxyz', '_labeled.extxyz')</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.lib.lib_dispatcher","title":"<code>lib_dispatcher</code>","text":"<p>Functions:</p> <ul> <li> <code>submit_job</code>             \u2013              <p>Function to submit a job to the cluster:</p> </li> <li> <code>submit_junk_job</code>             \u2013              <p>Improved version of <code>submit_job</code> to split the task_paths into chunks and submit them.</p> </li> </ul> <p>Attributes:</p> <ul> <li> <code>fh</code>           \u2013            </li> <li> <code>fmt</code>           \u2013            </li> </ul>"},{"location":"alff_api/#alff.lib.lib_dispatcher.fh","title":"<code>fh = logging.FileHandler(FILE_LOG_DISPATCHER)</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.lib.lib_dispatcher.fmt","title":"<code>fmt = logging.Formatter('%(asctime)s | %(name)s-%(levelname)s: %(message)s', '%Y-%b-%d %H:%M:%S')</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.lib.lib_dispatcher.submit_job","title":"<code>submit_job(mdict_machine: dict, mdict_resources: dict, command_list: list[str], work_path: str, task_paths: list[str], forward_files: list[str], backward_files: list[str], forward_common_files: list[str], outlog: str, errlog: str)</code>","text":"<p>Function to submit a job to the cluster: - Prepare the task list - Make the submission and wait for the job to finish - Download the results</p>"},{"location":"alff_api/#alff.lib.lib_dispatcher.submit_junk_job","title":"<code>submit_junk_job(mdict_machine: dict, mdict_resources: dict, command_list: list[str], work_path: str, task_paths: list[str], forward_files: list[str], backward_files: list[str], forward_common_files: list[str], outlog: str, errlog: str, jobs_per_dispatch: int)</code>","text":"<p>Improved version of <code>submit_job</code> to split the task_paths into chunks and submit them.</p>"},{"location":"alff_api/#alff.lib.tool_conf","title":"<code>tool_conf</code>","text":"<p>Functions:</p> <ul> <li> <code>build_conf</code>             \u2013              <p>Build atomic configuration, using <code>ase.build</code> library. See https://wiki.fysik.dtu.dk/ase/ase/build/build.html#</p> </li> <li> <code>scale_atoms</code>             \u2013              <p>Scale the atoms by the given factors along the three directions.</p> </li> <li> <code>perturb_atoms</code>             \u2013              <p>Perturb the atoms by random displacements. This method adds random displacements to the atomic positions. See more</p> </li> <li> <code>poscar2lmpdata</code>             \u2013              <p>Convert POSCAR file to LAMMPS data file.</p> </li> <li> <code>extxyz2lmpdata</code>             \u2013              <p>Convert extxyz file to LAMMPS data file.</p> </li> <li> <code>write_extxyz</code>             \u2013              <p>Write a list of Atoms object to an extxyz file. The exited <code>ase.io.write</code> function does not support writing file if the parent directory does not exist. This function will overcome this problem.</p> </li> <li> <code>read_extxyz</code>             \u2013              <p>Read extxyz file. The exited <code>ase.io.read</code> returns a single Atoms object if file contains only one frame. This function will return a list of Atoms object.</p> </li> <li> <code>select_extxyz_frames</code>             \u2013              <p>Choose frames from a extxyz trajectory file, based on some criteria.</p> </li> </ul>"},{"location":"alff_api/#alff.lib.tool_conf.build_conf","title":"<code>build_conf(pdict: dict)</code>","text":"<p>Build atomic configuration, using <code>ase.build</code> library. See https://wiki.fysik.dtu.dk/ase/ase/build/build.html#</p> <p>Supported structure types: - bulk: sc, fcc, bcc, tetragonal, bct, hcp, rhombohedral, orthorhombic, mcl, diamond, zincblende, rocksalt, cesiumchloride, fluorite or wurtzite. - molecule: molecule - mx2: MX2</p> <p>Parameters:</p> <ul> <li> <code>pdict</code>               (<code>dict</code>)           \u2013            <p>Parameters dictionary</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>outfile</code>          \u2013            <p>Save atomic configuration with format specified by ext of <code>outfile</code>. All ASE supported formats are allowed.</p> </li> </ul>"},{"location":"alff_api/#alff.lib.tool_conf.scale_atoms","title":"<code>scale_atoms(atoms: Atoms, factors: list = [1, 1, 1]) -&gt; Atoms</code>","text":"<p>Scale the atoms by the given factors along the three directions.</p>"},{"location":"alff_api/#alff.lib.tool_conf.perturb_atoms","title":"<code>perturb_atoms(atoms: Atoms, std_disp: float) -&gt; Atoms</code>","text":"<p>Perturb the atoms by random displacements. This method adds random displacements to the atomic positions. See more</p>"},{"location":"alff_api/#alff.lib.tool_conf.poscar2lmpdata","title":"<code>poscar2lmpdata(poscar_file: str, lmpdata_file: str, atom_style: str = 'atomic') -&gt; list[str]</code>","text":"<p>Convert POSCAR file to LAMMPS data file.</p>"},{"location":"alff_api/#alff.lib.tool_conf.extxyz2lmpdata","title":"<code>extxyz2lmpdata(extxyz_file: str, lmpdata_file: str, atom_style: str = 'atomic') -&gt; list[str]</code>","text":"<p>Convert extxyz file to LAMMPS data file.</p>"},{"location":"alff_api/#alff.lib.tool_conf.write_extxyz","title":"<code>write_extxyz(outfile: str, atoms: list)</code>","text":"<p>Write a list of Atoms object to an extxyz file. The exited <code>ase.io.write</code> function does not support writing file if the parent directory does not exist. This function will overcome this problem.</p> <p>Parameters:</p> <ul> <li> <code>atoms</code>               (<code>list</code>)           \u2013            <p>List of Atoms object.</p> </li> <li> <code>outfile</code>               (<code>str</code>)           \u2013            <p>Path to the output file.</p> </li> </ul>"},{"location":"alff_api/#alff.lib.tool_conf.read_extxyz","title":"<code>read_extxyz(extxyz_file: str, index=':') -&gt; list[Atoms]</code>","text":"<p>Read extxyz file. The exited <code>ase.io.read</code> returns a single Atoms object if file contains only one frame. This function will return a list of Atoms object.</p> <p>Parameters:</p> <ul> <li> <code>extxyz_file</code>               (<code>str</code>)           \u2013            <p>Path to the output file.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>list</code> (              <code>list[Atoms]</code> )          \u2013            <p>List of Atoms object.</p> </li> </ul> Note <ul> <li><code>ase.io.read</code> returns a single Atoms object or a list of Atoms object, depending on the <code>index</code> argument. <code>index=\":\"</code> will always return a list.</li> </ul>"},{"location":"alff_api/#alff.lib.tool_conf.select_extxyz_frames","title":"<code>select_extxyz_frames(extxyz_file: str, has_symbols: list = None, only_symbols: list = None, exact_symbols: list = None, has_properties: list = None, only_properties: list = None, has_columns: list = None, only_columns: list = None, output_file: str = 'selected_frames.extxyz') -&gt; list[Atoms]</code>","text":"<p>Choose frames from a extxyz trajectory file, based on some criteria.</p> <p>Parameters:</p> <ul> <li> <code>extxyz_file</code>               (<code>str</code>)           \u2013            <p>Path to the extxyz file.</p> </li> <li> <code>has_symbols</code>               (<code>list</code>, default:                   <code>None</code> )           \u2013            <p>List of symbols that each frame must have at least one of them.</p> </li> <li> <code>only_symbols</code>               (<code>list</code>, default:                   <code>None</code> )           \u2013            <p>List of symbols that each frame must have only these symbols.</p> </li> <li> <code>exact_symbols</code>               (<code>list</code>, default:                   <code>None</code> )           \u2013            <p>List of symbols that each frame must have exactly these symbols.</p> </li> <li> <code>has_properties</code>               (<code>list</code>, default:                   <code>None</code> )           \u2013            <p>List of properties that each frame must have at least one of them.</p> </li> <li> <code>only_properties</code>               (<code>list</code>, default:                   <code>None</code> )           \u2013            <p>List of properties that each frame must have only these properties.</p> </li> <li> <code>has_columns</code>               (<code>list</code>, default:                   <code>None</code> )           \u2013            <p>List of columns that each frame must have at least one of them.</p> </li> <li> <code>only_columns</code>               (<code>list</code>, default:                   <code>None</code> )           \u2013            <p>List of columns that each frame must have only these columns.</p> </li> <li> <code>output_file</code>               (<code>str</code>, default:                   <code>'selected_frames.extxyz'</code> )           \u2013            <p>Path to the output file.</p> </li> </ul>"},{"location":"alff_api/#alff.lib.util","title":"<code>util</code>","text":"<p>some common utilities for generator, auto_test and data</p> <p>Functions:</p> <ul> <li> <code>text_pkg_info</code>             \u2013              </li> <li> <code>text_logo</code>             \u2013              </li> <li> <code>record_iter</code>             \u2013              </li> <li> <code>mkname_iter</code>             \u2013              </li> <li> <code>replace</code>             \u2013              </li> <li> <code>copy_file_list</code>             \u2013              </li> <li> <code>cmd_append_log</code>             \u2013              </li> <li> <code>repeat_to_length</code>             \u2013              </li> <li> <code>expand_idx</code>             \u2013              <p>Expand the input list of indices to a list of integers.</p> </li> <li> <code>mkname_structure</code>             \u2013              <p>Create the directory name for the structure</p> </li> <li> <code>ask_for_backup_dir</code>             \u2013              </li> <li> <code>ask_yes_no</code>             \u2013              <p>Asks a yes/no question and returns True for 'yes' and False for 'no'.</p> </li> <li> <code>remote_info</code>             \u2013              <p>Return the remote machine information. Job_type: 'train', 'dft', 'md'.</p> </li> <li> <code>info_current_dispatch</code>             \u2013              <p>Return the information of the current chunk of tasks.</p> </li> </ul>"},{"location":"alff_api/#alff.lib.util.text_pkg_info","title":"<code>text_pkg_info(modules=['numpy', 'scipy', 'ase', 'polars', 'thutil', 'sevenn', 'phonopy'])</code>","text":""},{"location":"alff_api/#alff.lib.util.text_logo","title":"<code>text_logo()</code>","text":""},{"location":"alff_api/#alff.lib.util.record_iter","title":"<code>record_iter(filename, iter_idx, stage_idx)</code>","text":""},{"location":"alff_api/#alff.lib.util.mkname_iter","title":"<code>mkname_iter(iter_idx: int) -&gt; str</code>","text":""},{"location":"alff_api/#alff.lib.util.replace","title":"<code>replace(file_name, pattern, subst)</code>","text":""},{"location":"alff_api/#alff.lib.util.copy_file_list","title":"<code>copy_file_list(file_list, from_path, to_path)</code>","text":""},{"location":"alff_api/#alff.lib.util.cmd_append_log","title":"<code>cmd_append_log(cmd, log_file)</code>","text":""},{"location":"alff_api/#alff.lib.util.repeat_to_length","title":"<code>repeat_to_length(input_str: str, length) -&gt; str</code>","text":""},{"location":"alff_api/#alff.lib.util.expand_idx","title":"<code>expand_idx(in_list: list[int, str]) -&gt; list[int]</code>","text":"<p>Expand the input list of indices to a list of integers. Eg: in_list = [1, 2, \"3-5:2\", \"6-10\"]</p>"},{"location":"alff_api/#alff.lib.util.mkname_structure","title":"<code>mkname_structure(pdict)</code>","text":"<p>Create the directory name for the structure</p>"},{"location":"alff_api/#alff.lib.util.ask_for_backup_dir","title":"<code>ask_for_backup_dir(dir_path: str)</code>","text":""},{"location":"alff_api/#alff.lib.util.ask_yes_no","title":"<code>ask_yes_no(question: str) -&gt; str</code>","text":"<p>Asks a yes/no question and returns True for 'yes' and False for 'no'.</p>"},{"location":"alff_api/#alff.lib.util.remote_info","title":"<code>remote_info(mdict, job_type: str = 'dft') -&gt; str</code>","text":"<p>Return the remote machine information. Job_type: 'train', 'dft', 'md'.</p>"},{"location":"alff_api/#alff.lib.util.info_current_dispatch","title":"<code>info_current_dispatch(task_paths, jobs_per_dispatch, chunk_count, paths_in_chunk, last_time=None, current_time=None) -&gt; str</code>","text":"<p>Return the information of the current chunk of tasks.</p>"},{"location":"alff_api/#alff.phonon","title":"<code>phonon</code>","text":"<p>Modules:</p> <ul> <li> <code>lib_gpaw_phonon</code>           \u2013            </li> <li> <code>lib_lammps_phonon</code>           \u2013            </li> <li> <code>lib_phonopy</code>           \u2013            </li> <li> <code>phonon</code>           \u2013            </li> </ul>"},{"location":"alff_api/#alff.phonon.lib_gpaw_phonon","title":"<code>lib_gpaw_phonon</code>","text":"<p>Functions:</p> <ul> <li> <code>prepho_gpaw_optimize_fixbox</code>             \u2013              <p>Refer to the <code>pregen_gpaw_optimize()</code> function.</p> </li> <li> <code>postpho_gpaw_singlepoint_suppercell_force</code>             \u2013              <p>This function does:</p> </li> </ul> <p>Attributes:</p> <ul> <li> <code>LIB_GPAW_PATH</code>           \u2013            <p>Reuse functions from <code>lib_gpaw_gendata.py</code></p> </li> </ul>"},{"location":"alff_api/#alff.phonon.lib_gpaw_phonon.LIB_GPAW_PATH","title":"<code>LIB_GPAW_PATH = Path(f'{ROOT_PATH}/lib/gpaw')</code>  <code>module-attribute</code>","text":"<p>Reuse functions from <code>lib_gpaw_gendata.py</code> - pregen_gpaw_optimize - rungen_gpaw_optimize - postgen_gpaw_optimize</p> <p>NOTE: must ensure \"gpaw_arg\" is defined in pdict[\"dft\"] as: pdict\"dft\"</p>"},{"location":"alff_api/#alff.phonon.lib_gpaw_phonon.prepho_gpaw_optimize_fixbox","title":"<code>prepho_gpaw_optimize_fixbox(work_path, pdict)</code>","text":"<p>Refer to the <code>pregen_gpaw_optimize()</code> function. Only change <code>gpaw_dft</code> for fixed cell optimization.</p>"},{"location":"alff_api/#alff.phonon.lib_gpaw_phonon.postpho_gpaw_singlepoint_suppercell_force","title":"<code>postpho_gpaw_singlepoint_suppercell_force(work_path, pdict)</code>","text":"<p>This function does: - Clean up unlabelled extxyz files - Collect forces from the output files</p>"},{"location":"alff_api/#alff.phonon.lib_lammps_phonon","title":"<code>lib_lammps_phonon</code>","text":"<p>Functions:</p> <ul> <li> <code>prepho_lammps_optimize</code>             \u2013              <p>This function does:</p> </li> <li> <code>runpho_lammps_optimize</code>             \u2013              <p>This function does:</p> </li> <li> <code>postpho_lammps_optimize</code>             \u2013              <p>This function does:</p> </li> </ul> <p>Attributes:</p> <ul> <li> <code>LIB_GPAW_PATH</code>           \u2013            </li> </ul>"},{"location":"alff_api/#alff.phonon.lib_lammps_phonon.LIB_GPAW_PATH","title":"<code>LIB_GPAW_PATH = Path(f'{ROOT_PATH}/lib/gpaw')</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.phonon.lib_lammps_phonon.prepho_lammps_optimize","title":"<code>prepho_lammps_optimize(work_path, pdict)</code>","text":"<p>This function does: - Prepare task_paths: select only unlabeled structures to compute at clusters. - Prepare lammps_optimize and lammps_input files.</p>"},{"location":"alff_api/#alff.phonon.lib_lammps_phonon.runpho_lammps_optimize","title":"<code>runpho_lammps_optimize(work_path, pdict, mdict)</code>","text":"<p>This function does: - Prepare command_list - Read task_paths from .yaml file - Prepare fordward &amp; backward files - Submit jobs to the cluster - Download the results when finished</p>"},{"location":"alff_api/#alff.phonon.lib_lammps_phonon.postpho_lammps_optimize","title":"<code>postpho_lammps_optimize(work_path, pdict)</code>","text":"<p>This function does: - Remove unlabeled .extxyz files, just keep the labeled ones.</p>"},{"location":"alff_api/#alff.phonon.lib_phonopy","title":"<code>lib_phonopy</code>","text":"<p>Functions:</p> <ul> <li> <code>plot_phonon</code>             \u2013              </li> <li> <code>get_band_path</code>             \u2013              </li> <li> <code>convert_phonopy2ase</code>             \u2013              </li> <li> <code>convert_ase2phonopy</code>             \u2013              </li> <li> <code>get_band_structure</code>             \u2013              </li> </ul>"},{"location":"alff_api/#alff.phonon.lib_phonopy._ref_phonon_calc","title":"<code>_ref_phonon_calc(atoms: Atoms, calc: object, supercell_matrix=[[2, 0, 0], [0, 2, 0], [0, 0, 2]], displacement=0.01, NAC: bool = False) -&gt; object</code>","text":"<p>NOTE: this function is note be used. just for reference.</p> <p>Parameters:</p> <ul> <li> <code>atoms</code>               (<code>Atoms</code>)           \u2013            <p>ASE's structure object which is already optimized/relaxed as the ground state.</p> </li> <li> <code>calc</code>               (<code>object</code>)           \u2013            <p>ASE calculator object.</p> </li> <li> <code>supercell_matrix</code>               (<code>list</code>, default:                   <code>[[2, 0, 0], [0, 2, 0], [0, 0, 2]]</code> )           \u2013            <p>The supercell matrix for the phonon calculation.</p> </li> <li> <code>displacement</code>               (<code>float</code>, default:                   <code>0.01</code> )           \u2013            <p>The atomic displacement distance in Angstrom.</p> </li> <li> <code>NAC</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>Whether to use non-analytical corrections (NAC) for the phonon calculation.</p> </li> </ul> <p>NOTE: not yet finished</p>"},{"location":"alff_api/#alff.phonon.lib_phonopy.plot_phonon","title":"<code>plot_phonon(phonon: object, filename: str)</code>","text":""},{"location":"alff_api/#alff.phonon.lib_phonopy.get_band_path","title":"<code>get_band_path(atoms: PhonopyAtoms, path_str: str = None, npoints: int = 61, path_frac=None, labels=None)</code>","text":""},{"location":"alff_api/#alff.phonon.lib_phonopy.convert_phonopy2ase","title":"<code>convert_phonopy2ase(atoms: PhonopyAtoms) -&gt; Atoms</code>","text":""},{"location":"alff_api/#alff.phonon.lib_phonopy.convert_ase2phonopy","title":"<code>convert_ase2phonopy(atoms: Atoms) -&gt; PhonopyAtoms</code>","text":""},{"location":"alff_api/#alff.phonon.lib_phonopy.get_band_structure","title":"<code>get_band_structure(phonon: object, path_str: str = None, npoints: int = None)</code>","text":""},{"location":"alff_api/#alff.phonon.phonon","title":"<code>phonon</code>","text":"<p>Functions:</p> <ul> <li> <code>relax_initial_structure</code>             \u2013              <p>Relax the structure by DFT/MD</p> </li> <li> <code>scale_and_relax</code>             \u2013              <p>Scale and relax the structures while fixing box size. Use when want to compute phonon at different volumes.</p> </li> <li> <code>compute_force</code>             \u2013              <p>Compute forces for each relaxed-structure by DFT/MD.</p> </li> <li> <code>compute_force_single_structure</code>             \u2013              <p>Run DFT/MD single-point calculation to compute forces for a list of supercells of a single structure. The function does the following:</p> </li> <li> <code>compute_phonon</code>             \u2013              <p>Compute phonon properties by <code>phonopy</code> functions.</p> </li> <li> <code>phonon_calc</code>             \u2013              <p>Generate initial data for training ML models</p> </li> </ul>"},{"location":"alff_api/#alff.phonon.phonon.relax_initial_structure","title":"<code>relax_initial_structure(pdict, mdict)</code>","text":"<p>Relax the structure by DFT/MD</p>"},{"location":"alff_api/#alff.phonon.phonon.scale_and_relax","title":"<code>scale_and_relax(pdict, mdict)</code>","text":"<p>Scale and relax the structures while fixing box size. Use when want to compute phonon at different volumes.</p>"},{"location":"alff_api/#alff.phonon.phonon.compute_force","title":"<code>compute_force(pdict, mdict)</code>","text":"<p>Compute forces for each relaxed-structure by DFT/MD.</p>"},{"location":"alff_api/#alff.phonon.phonon.compute_force_single_structure","title":"<code>compute_force_single_structure(work_path, pdict, mdict)</code>","text":"<p>Run DFT/MD single-point calculation to compute forces for a list of supercells of a single structure. The function does the following: - Initialize the <code>phonopy</code> object - generate supercells with displacements in each subdir - run DFT/MD single-point calculation to compute forces for each supercell - assign forces back to phonopy object - save the phonopy object to a file for latter post-processing</p>"},{"location":"alff_api/#alff.phonon.phonon.compute_phonon","title":"<code>compute_phonon(pdict, mdict)</code>","text":"<p>Compute phonon properties by <code>phonopy</code> functions.</p>"},{"location":"alff_api/#alff.phonon.phonon.phonon_calc","title":"<code>phonon_calc(configfile_param: str, configfile_machine: str)</code>","text":"<p>Generate initial data for training ML models</p>"},{"location":"alff_arg_docs/","title":"alff parameters","text":""},{"location":"alff_arg_docs/#alff.lib.argument_docs","title":"<code>alff.lib.argument_docs</code>","text":"<p><code>alff</code> accepts a configuration file in YAML/JSON/JSONC format.</p> <p>Functions:</p> <ul> <li> <code>param</code>             \u2013              <p>ALFF parameters.</p> </li> <li> <code>not_use_param_seveen</code>             \u2013              <p>SevenNet parameters that are not applicable.</p> </li> <li> <code>machine</code>             \u2013              <p>ALFF parameters for running on a clusters.</p> </li> </ul>"},{"location":"alff_arg_docs/#alff.lib.argument_docs.param","title":"<code>param()</code>","text":"<p>ALFF parameters.</p>"},{"location":"alff_arg_docs/#alff.lib.argument_docs.param--parameters","title":"Parameters","text":"<pre><code>mlp_engine: str\n    The engine to use for training the MLP model. Choices: 'sevenn', 'mace'\nnumb_models: int\n    Number of models to train.\ninit_data_paths: list[str]\n    List of paths to the initial data.\ndistributed: bool\n    Whether to use distributed training.\ndistributed_backend: str\n    The Pytorch backend to use for distributed training. Choices: 'nccl', 'mpi'\nsevenn_args: dict\n    SevenNet's parameters.\nmace_args: dict\n    Mace's parameters.\n</code></pre>"},{"location":"alff_arg_docs/#alff.lib.argument_docs.not_use_param_seveen","title":"<code>not_use_param_seveen()</code>","text":"<p>SevenNet parameters that are not applicable.</p> <p>These parameters are either generated by the ALFF or are not required for running the ALFF.</p>"},{"location":"alff_arg_docs/#alff.lib.argument_docs.not_use_param_seveen--parameters","title":"Parameters","text":"<pre><code>train.random_seed: int\n    Random seed for reproducibility.\ndata.load_dataset_path: list[str]\n    List of paths to the dataset.\n</code></pre>"},{"location":"alff_arg_docs/#alff.lib.argument_docs.machine","title":"<code>machine()</code>","text":"<p>ALFF parameters for running on a clusters.</p>"},{"location":"alff_cli/","title":"CLI","text":"<p>ALLF provides command-line interface (CLI) to run the ALFF processes:</p> <ul> <li>Active learning process</li> <li>generate data for training ML forcefields</li> <li>convert MPtrj files to XYZ datasets.</li> <li>etc.</li> </ul>"},{"location":"alff_cli/#alff-active-learning","title":"ALFF active learning","text":"<p>Run the main ALFF active learning process.</p> <pre><code>alff_al PARAM.yaml MACHINE.yaml\n</code></pre> <ul> <li><code>PARAM.yaml</code>: The parameters of the generator.</li> <li><code>MACHINE.yaml</code>: The settings of the machines running the generator.</li> </ul>"},{"location":"alff_cli/#data-generator","title":"Data generator","text":"<p>Generate data for training ML forcefields.</p> <pre><code>alff_gen PARAM.yaml MACHINE.yaml\n</code></pre> <ul> <li><code>PARAM.yaml</code>: The parameters of the generator.</li> <li><code>MACHINE.yaml</code>: The settings of the machines running the generator.</li> </ul>"},{"location":"alff_cli/#phonon-calculation","title":"Phonon calculation","text":"<p>Perform the phonon calculation.</p> <pre><code>alff_phonon PARAM.yaml MACHINE.yaml\n</code></pre> <ul> <li><code>PARAM.yaml</code>: The parameters of the generator.</li> <li><code>MACHINE.yaml</code>: The settings of the machines running the generator.</li> </ul>"},{"location":"alff_cli/#dataset-tools","title":"Dataset tools","text":"<p>Convert MPtrj to XYZ</p> <pre><code>chgnet_to_xyz MPtrj.json\n</code></pre> <ul> <li><code>MPtrj.json</code>: The MPtrj file to be converted to XYZ dataset.</li> </ul>"},{"location":"alff_gendata/","title":"ALFF: Data generator","text":"<p>To generate labeled data for training ML forcefields, <code>alff_gen</code> is a command-line tool designed to perform the following tasks automatically without needs any user intervention: - Build atomic structures - Generate DFT codes to optimize atomic structures - Submit DFT optimization jobs to the clusters, monitor the job status, and get back the DFT calcualation results - Generate atomic structures by scaling and perturbing the optimized structures - Generate DFT codes to run AIMD simulations - Submit AIMD jobs to the clusters, monitor the job status, and get back the DFT calculation results - Collect the data from the DFT calculations - Convert the data to the format that can ready to used for training ML forcefields.</p> <pre><code>alff_gen PARAM.yaml MACHINE.yaml\n</code></pre> <ul> <li><code>PARAM.yaml</code>: The parameters of the generator.</li> <li><code>MACHINE.yaml</code>: The settings of the machines running the generator's subprocesses.</li> </ul> <p>An example run using <code>alff</code> to generate labeled data:</p> <pre><code>-------------------------------- ALFF --------------------------------\n    Version:  0.1.dev409+g177de1d\n       Path:  C:/conda/envs/py13/Lib/site-packages/alff\n---------------------------- Dependencies ----------------------------\n       numpy  1.26.4       C:/conda/envs/py11/Lib/site-packages/numpy\n       scipy  1.13.0       C:/conda/envs/py11/Lib/site-packages/scipy\n         ase  3.23.1b1     C:/conda/envs/py11/Lib/site-packages/ase\n      polars  1.11.0       C:/conda/envs/py11/Lib/site-packages/polars\n      thutil  0.1.dev122   C:/conda/envs/py11/Lib/site-packages/thutil\n      sevenn  0.10.1       C:/conda/envs/py11/Lib/site-packages/sevenn\n     phonopy  2.29.1       C:/conda/envs/py11/Lib/site-packages/phonopy\n----------------------- Author: C.Thang Nguyen -----------------------\n--------------- Contact: https://thang.eu.org/contact ----------------\n\n                             ___    __    ____________\n                            /   |  / /   / ____/ ____/\n                           / /| | / /   / /_  / /_\n                          / ___ |/ /___/ __/ / __/\n                         /_/  |_/_____/_/   /_/\n\nalff-INFO: START GENERATING DATA\nalff-INFO: -------------------- stage_00: build_structure -------------\n The directory `Mo_bulk_bcc_02x02x02` already existed. Select an action: [yes/backup/no]?\n Yes: overwrite the existing directory that continue or update uncompleted tasks.\n Backup: backup the existing directory and perform fresh tasks.\n No: skip and exit.\n        Your answer (y/b/n): y\n        Overwrite the existing directory\nalff-INFO: Working on the path: Mo_bulk_bcc_02x01x01/00_build_structure\nalff-INFO: Build structures from scratch\nalff-INFO: -------------------- stage_01: optimize --------------------\nalff-INFO: Optimize the structures\nalff-INFO: No DFT task is found. Skip the DFT calculation.\nalff-INFO: -------------------- stage_02: scale_perturb ---------------\nalff-INFO: Scaling on the path: Mo_bulk_bcc_02x01x01/01_scale_perturb\nalff-INFO: -------------------- stage_03: run_dft ---------------------\nalff-INFO: Run AIMD calculations\nalff-INFO: Running DFT jobs... be patient\n               Remote host: some_IP_address\n               Remote path: /uwork/user01/work/w24_alff_job\n               Log file: logs/20241020_220540_dispatcher.log\nalff-INFO: Running chunk 1 of 9 chunks (20 of 431 tasks).\nalff-INFO: Running chunk 2 of 9 chunks (20 of 411 tasks). Estimated time: 1 days, 4:39\nalff-INFO: Running chunk 3 of 9 chunks (20 of 391 tasks). Estimated time: 1 days, 3:15\n...\n\nalff-INFO: -------------------- stage_04: collect_data ----------------\nalff-INFO: Collect data on the path: o_bulk_bcc_02x01x01/02_gendata\nalff-INFO: FINISHED !\n</code></pre>"},{"location":"alff_gendata/#parameters","title":"Parameters","text":"<p>The parameters of the generator are stored in a YAML/JSON/JSONC file. Here is an example of the parameters:</p> <pre><code>stages:\n  - build_structure         # build the atomic structures\n  - optimize                # optimize the structure\n  - scale_perturb           # scale and perturb the structure\n  - run_dft                 # run the DFTsinglepoint/AIMD simulation\n  - collect_data            # collect the data\n\nstructure:  # atomic structure information\n  # from_extxyz: [\"path/to/extxyz_file\"]  # list-of-paths to the EXTXYZ files to be used as the initial structure. If provided, the structure will be read from the file, and the other structure parameters will be ignored.\n\n  from_scratch:               # build the structure from scratch\n    structure_type: \"bulk\"    # bulk, molecule, surface,\n    chem_formula: \"W\"         # chemical formula/element. e.g., \"H2O\", \"Mg2O2\", \"Mg\",\n    cell_size: [ 2, 2, 2 ]    # size of the supercell\n    pbc: [1, 1, 1]\n    ase_arg:                 # ASE kwargs for building the structure. Accept all ASE arguments.\n      crystalstructure: \"fcc\" # choices: sc,fcc,bcc,tetragonal,bct,hcp,rhombohedral,orthorhombic,mcl,diamond,zincblende,rocksalt,cesiumchloride,fluorite,wurtzite.\n      a: 3.15  # lattice constant\n      # cubic: True\n\n\nscale_perturb:                          # scale and perturb the structure\n  scale_x: [0.9, 0.95, 1.0, 1.05, 1.1]  # scale the structure in x-direction\n  scale_y: [0.9, 0.95, 1.0, 1.05, 1.1]  # scale the structure in y-direction\n  scale_z: [0.9, 0.95, 1.0, 1.05, 1.1]  # scale the structure in z-direction\n  perturb_num: 1                        # number of perturbations on each structure\n  perturb_disp: 0.01                    # stadard deviation of the perturb displacement\n\n\ndft:\n  calc_type: 'aimd'              # choices: 'singlepoint', 'aimd'\n  jobs_per_dispatch: 18         # maximum number of jobs per submission to the cluster\n\n  gpaw_arg:                    # accept GPAW parameters\n    mode:\n      name: 'pw'                # use PlaneWave method energy cutoff in eV\n      ecut: 500\n    xc: \"PBE\"                   # exchange-correlation functional\n    kpts: {\"density\": 6, \"gamma\": False }  # if not set `kpts`, then only Gamma-point is used\n    parallel:\n      sl_auto: True             # enable ScaLAPACK parallelization\n      # use_elpa: True          # enable Elpa eigensolver\n      augment_grids: True       # use all cores for XC/Poisson solver\n\n  optimize:                     # run DFT to optimize the structure\n    fmax: 0.05                  # force convergence criteria\n\n  aimd:                         # run AIMD simulation\n    dt: 1.0                     # time step in fs\n    temperature: 300            # temperature in K\n    ensemble: \"NVE\"             # ensemble type. choices: \"NVE\", \"NVT\"\n    collect_frames: 5           # number of frames to be collected. Then nsteps = collect_frames * dump_freq\n    dump_freq: 1                # dump the frames every `dump_freq` steps\n</code></pre>"},{"location":"alff_gendata/#context-options","title":"Context options","text":"<p>When the output directory already exists, the generator will ask for the user's choice to proceed. The options are: - <code>Yes</code>: overwrite the existing directory and continue. - <code>Backup</code>: backup the existing directory and continue. - <code>No</code>: skip the building process and exit.</p> <p><code>Yes</code>: is recommended. With this option, the generator will - Overwrite and continue in the existing directory - Automatically select the unLABELED configurations to run DFT calculations, avoi running DFT for LABELED configurations. - This is the best way to continue the previous uncomplishness or update some more sampling options.</p>"},{"location":"alff_gendata/#machines","title":"Machines","text":"<p>The settings of the machines running the generator's subprocesses are stored in a YAML/JSON/JSONC file. Here is an example of the machine settings:</p> <pre><code>dft:\n  command: \"mpirun -np $NSLOTS gpaw\"\n\n  machine:\n    batch_type: SGE            # Supported systems: SGE, SLURM, PBS, TORQUE, BASH\n    context_type: SSHContext   # Supported contexts: SSH, Local\n    remote_root: /path/of/project/in/remote/machine\n    remote_profile:\n      hostname: some_IP_address         # address of the remote machine\n      username: little_bird             # username to login the remote machine\n      password: \"123456\"                # password to login the remote machine\n      port: 2022                        # port to connect the remote machine\n      timeout: 20                       # timeout for the SSH connection\n      execute_command: \"ssh cluster\"    # command to execute the SSH connection\n\n  resources:\n    group_size: 1\n    queue_name: \"lion-normal.q\"\n    cpu_per_node: 12\n    kwargs:\n      pe_name: lion-normal\n      job_name: zalff_dft\n    custom_flags:\n      - \"#$ -l h_rt=168:00:00\"\n    module_list:\n      - conda/py11gpaw\n    source_list:\n      - /etc/profile.d/modules.sh\n    envs:\n      OMP_NUM_THREADS: 1\n      OMPI_MCA_btl_openib_allow_ib: 1\n      # OMPI_MCA_btl: ^tcp\n</code></pre>"},{"location":"alff_phonon_calc/","title":"ALFF: phonon calculation","text":"<p><code>alff_phonon</code> is a command-line tool designed to perform the phonon calculation. The following tasks is run automatically without needs any user intervention: - Build atomic structures - Generate DFT/MD codes to optimize atomic structures - Submit the optimization jobs to the clusters, monitor the job status, and get back the DFT calcualation results - Generate supercells with displacements - Generate DFT/MD codes to compute atomic forces - Compute the phonon band structure, phonon density of states, and other phonon-related properties.</p> <pre><code>alff_phonon PARAM.yaml MACHINE.yaml\n</code></pre> <ul> <li><code>PARAM.yaml</code>: The parameters of the generator.</li> <li><code>MACHINE.yaml</code>: The settings of the machines running the generator's subprocesses.</li> </ul> <p>The above command <code>alff_phonon</code> is all needed to obtain, for example, the phonon band structure of Silicon as this figure:</p> <p></p> <p>This result from our calculation is strongly consistent with the phonon band structure of Silicon reported in the literature.</p> <pre><code>-------------------------------- ALFF --------------------------------\n    Version:  0.1.dev409+g177de1d\n       Path:  C:/conda/envs/py13/Lib/site-packages/alff\n---------------------------- Dependencies ----------------------------\n       numpy  1.26.4       C:/conda/envs/py11/Lib/site-packages/numpy\n       scipy  1.13.0       C:/conda/envs/py11/Lib/site-packages/scipy\n         ase  3.23.1b1     C:/conda/envs/py11/Lib/site-packages/ase\n      polars  1.11.0       C:/conda/envs/py11/Lib/site-packages/polars\n      thutil  0.1.dev122   C:/conda/envs/py11/Lib/site-packages/thutil\n      sevenn  0.10.1       C:/conda/envs/py11/Lib/site-packages/sevenn\n     phonopy  2.29.1       C:/conda/envs/py11/Lib/site-packages/phonopy\n----------------------- Author: C.Thang Nguyen -----------------------\n--------------- Contact: https://thang.eu.org/contact ----------------\n\n                             ___    __    ____________\n                            /   |  / /   / ____/ ____/\n                           / /| | / /   / /_  / /_\n                          / ___ |/ /___/ __/ / __/\n                         /_/  |_/_____/_/   /_/\n\nalff-INFO: START PHONON CALCULATION\nalff-INFO: --------------- stage_00: build_structure ------------------\n The directory `Si_bulk_diamond_01x01x01` already existed. Select an action: [yes/backup/no]?\n Yes: overwrite the existing directory that continue or update uncompleted tasks.\n Backup: backup the existing directory and perform fresh tasks.\n No: skip and exit.\n        Your answer (y/b/n): y\n        Overwrite the existing directory\nalff-INFO: Working on the path: Si_bulk_diamond_01x01x01/00_build_structure\nalff-INFO: Build structures from scratch\nalff-INFO: --------------- stage_01: relax_initial_structure ----------\nalff-INFO: Optimize the structures\nalff-INFO: No DFT task is found. Skip the DFT calculation.\nalff-INFO: --------------- stage_02: scale_and_relax ------------------\nalff-INFO: Relax the scaled structures\nalff-INFO: No task.\nalff-INFO: --------------- stage_03: compute_force --------------------\nalff-INFO: Running DFT jobs... be patient\n               Remote host: some_IP_address\n               Remote path: /uwork/user01/work/w24_alff_job\n               Log file: logs/20241020_220540_dispatcher.log\nalff-INFO: -------------------- stage_04: compute_phonon --------------\nalff-INFO: FINISHED !\n</code></pre>"},{"location":"alff_phonon_calc/#parameters","title":"Parameters","text":"<p>The parameters of the generator are stored in a YAML/JSON/JSONC file. Here is an example of the parameters:</p> <pre><code>stages:\n  - build_structure             # build initial atomic structures\n  - relax_initial_structure     # relax initial structures\n  - scale_and_relax             # scale and relax the structures\n  - compute_force               # compute the force\n  - compute_phonon              # post_process by phonopy\n\nstructure:  # atomic structure information\n  # from_extxyz: [\"path/to/extxyz_file\"]  # list-of-paths to the EXTXYZ files to be used as the initial structure. If provided, the structure will be read from the file, and the other structure parameters will be ignored.\n\n  from_scratch:               # build the structure from scratch\n    structure_type: \"bulk\"    # bulk, molecule, surface,\n    chem_formula: \"Si\"        # chemical formula/element. e.g., \"H2O\", \"Mg2O2\", \"Mg\",\n    cell_size: [ 1, 1, 1 ]    # size of the supercell\n    pbc: [1, 1, 1]\n    ase_arg:\n      crystalstructure: \"diamond\"\n      a: 5.43\n\n# scale:                # scale and perturb the structure\n#   scale_x: [0.5,1.5]  # scale the structure in x-direction\n#   # scale_y: [0.700]  # scale the structure in y-direction\n#   # scale_z: [0.700, 0.800] # scale the structure in z-direction\n\n\ncalculator: \"gpaw\"        # choices: 'lammps', 'gpaw'. Calculator to calculate atomic forces. Default: 'lammps'\n\ndft:                      # parameters for DFT calculation\n  gpaw_arg:               # accept GPAW parameters\n    mode:\n      name: 'pw'          # use PlaneWave method energy cutoff in eV\n      ecut: 500\n    xc: \"PBE\"             # exchange-correlation functional\n    kpts: {\"density\": 6, \"gamma\": True, 'even': True}  # if not set `kpts`, then only Gamma-point is used\n\n  optimize:               # parameter to optimize the structure by DFT/MS (relax_type: 'opt')\n    fmax: 0.02            # force convergence criteria\n\nmd:                       # parameters for MD calculation\n  # lammps_args:              # accept LAMMPS parameters\n  #   pair_style: \"eam/alloy\" # LAMMPS pair_style\n  #   pair_coeff: [\"* * Mo.eam.alloy Mo\"]  # LAMMPS pair_coeff\n\n\nphonon:                   # phonon calculation\n  supercell_matrix: [[2, 0, 0], [0, 2, 0], [0, 0, 2]]   # 3x3 array\n  displacement: 0.03                                    # small displacement in Angstrom\n  # phonopy_arg:                   # Accept all the phonopy parameters\n  #   nac: False                   # non-analytical correction\n  #   symprec: 1e-5                # symmetry precision\n  #   is_symmetry: True            # use symmetry\n\n  properties:         # properties need to compute from the phonon calculation\n    - band_structure     # phonon band structure\n    - dos                # phonon density of states\n</code></pre>"},{"location":"alff_phonon_calc/#context-options","title":"Context options","text":"<p>When the output directory already exists, the generator will ask for the user's choice to proceed. The options are: - <code>Yes</code>: overwrite the existing directory and continue. - <code>Backup</code>: backup the existing directory and continue. - <code>No</code>: skip the building process and exit.</p> <p><code>Yes</code>: is recommended. With this option, the generator will - Overwrite and continue in the existing directory - Automatically select the unLABELED configurations to run DFT calculations, avoi running DFT for LABELED configurations. - This is the best way to continue the previous uncomplishness or update some more sampling options.</p>"},{"location":"alff_phonon_calc/#machines","title":"Machines","text":"<p>The settings of the machines running the generator's subprocesses are stored in a YAML/JSON/JSONC file. Here is an example of the machine settings:</p> <pre><code>dft:\n  command: \"mpirun -np $NSLOTS gpaw\"\n\n  machine:\n    batch_type: SGE            # Supported systems: SGE, SLURM, PBS, TORQUE, BASH\n    context_type: SSHContext   # Supported contexts: SSH, Local\n    remote_root: /path/of/project/in/remote/machine\n    remote_profile:\n      hostname: some_IP_address         # address of the remote machine\n      username: little_bird             # username to login the remote machine\n      password: \"123456\"                # password to login the remote machine\n      port: 2022                        # port to connect the remote machine\n      timeout: 20                       # timeout for the SSH connection\n      execute_command: \"ssh cluster\"    # command to execute the SSH connection\n\n  resources:\n    group_size: 1\n    queue_name: \"lion-normal.q\"\n    cpu_per_node: 12\n    kwargs:\n      pe_name: lion-normal\n      job_name: zalff_dft\n    custom_flags:\n      - \"#$ -l h_rt=168:00:00\"\n    module_list:\n      - conda/py11gpaw\n    source_list:\n      - /etc/profile.d/modules.sh\n    envs:\n      OMP_NUM_THREADS: 1\n      OMPI_MCA_btl_openib_allow_ib: 1\n      # OMPI_MCA_btl: ^tcp\n</code></pre>"},{"location":"mace_train_param/","title":"MACE train","text":""},{"location":"mace_train_param/#mace-parameters-for-training","title":"MACE parameters for training","text":"<p>See more development parameters here.</p>"},{"location":"mace_train_param/#name-and-seed","title":"Name and seed","text":"<pre><code>    parser.add_argument(\"--name\", help=\"experiment name\", required=True)\n    parser.add_argument(\"--seed\", help=\"random seed\", type=int, default=123)\n</code></pre>"},{"location":"mace_train_param/#directories","title":"Directories","text":"<pre><code>    parser.add_argument(\n        \"--work_dir\",\n        help=\"set directory for all files and folders\",\n        type=str,\n        default=\".\",\n    )\n    parser.add_argument(\n        \"--log_dir\", help=\"directory for log files\", type=str, default=None\n    )\n    parser.add_argument(\n        \"--model_dir\", help=\"directory for final model\", type=str, default=None\n    )\n    parser.add_argument(\n        \"--checkpoints_dir\",\n        help=\"directory for checkpoint files\",\n        type=str,\n        default=None,\n    )\n    parser.add_argument(\n        \"--results_dir\", help=\"directory for results\", type=str, default=None\n    )\n    parser.add_argument(\n        \"--downloads_dir\", help=\"directory for downloads\", type=str, default=None\n    )\n\n    ## Device and logging\n    parser.add_argument(\n        \"--device\",\n        help=\"select device\",\n        type=str,\n        choices=[\"cpu\", \"cuda\", \"mps\", \"xpu\"],\n        default=\"cpu\",\n    )\n    parser.add_argument(\n        \"--default_dtype\",\n        help=\"set default dtype\",\n        type=str,\n        choices=[\"float32\", \"float64\"],\n        default=\"float64\",\n    )\n    parser.add_argument(\n        \"--distributed\",\n        help=\"train in multi-GPU data parallel mode\",\n        action=\"store_true\",\n        default=False,\n    )\n    parser.add_argument(\"--log_level\", help=\"log level\", type=str, default=\"INFO\")\n\n    parser.add_argument(\n        \"--error_table\",\n        help=\"Type of error table produced at the end of the training\",\n        type=str,\n        choices=[\n            \"PerAtomRMSE\",\n            \"TotalRMSE\",\n            \"PerAtomRMSEstressvirials\",\n            \"PerAtomMAEstressvirials\",\n            \"PerAtomMAE\",\n            \"TotalMAE\",\n            \"DipoleRMSE\",\n            \"DipoleMAE\",\n            \"EnergyDipoleRMSE\",\n        ],\n        default=\"PerAtomRMSE\",\n    )\n</code></pre>"},{"location":"mace_train_param/#model","title":"Model","text":"<pre><code>    parser.add_argument(\n        \"--model\",\n        help=\"model type\",\n        default=\"MACE\",\n        choices=[\n            \"BOTNet\",\n            \"MACE\",\n            \"ScaleShiftMACE\",\n            \"ScaleShiftBOTNet\",\n            \"AtomicDipolesMACE\",\n            \"EnergyDipolesMACE\",\n        ],\n    )\n    parser.add_argument(\n        \"--r_max\", help=\"distance cutoff (in Ang)\", type=float, default=5.0\n    )\n    parser.add_argument(\n        \"--radial_type\",\n        help=\"type of radial basis functions\",\n        type=str,\n        default=\"bessel\",\n        choices=[\"bessel\", \"gaussian\", \"chebyshev\"],\n    )\n    parser.add_argument(\n        \"--num_radial_basis\",\n        help=\"number of radial basis functions\",\n        type=int,\n        default=8,\n    )\n    parser.add_argument(\n        \"--num_cutoff_basis\",\n        help=\"number of basis functions for smooth cutoff\",\n        type=int,\n        default=5,\n    )\n    parser.add_argument(\n        \"--pair_repulsion\",\n        help=\"use pair repulsion term with ZBL potential\",\n        action=\"store_true\",\n        default=False,\n    )\n    parser.add_argument(\n        \"--distance_transform\",\n        help=\"use distance transform for radial basis functions\",\n        default=\"None\",\n        choices=[\"None\", \"Agnesi\", \"Soft\"],\n    )\n    parser.add_argument(\n        \"--interaction\",\n        help=\"name of interaction block\",\n        type=str,\n        default=\"RealAgnosticResidualInteractionBlock\",\n        choices=[\n            \"RealAgnosticResidualInteractionBlock\",\n            \"RealAgnosticAttResidualInteractionBlock\",\n            \"RealAgnosticInteractionBlock\",\n        ],\n    )\n    parser.add_argument(\n        \"--interaction_first\",\n        help=\"name of interaction block\",\n        type=str,\n        default=\"RealAgnosticResidualInteractionBlock\",\n        choices=[\n            \"RealAgnosticResidualInteractionBlock\",\n            \"RealAgnosticInteractionBlock\",\n        ],\n    )\n    parser.add_argument(\n        \"--max_ell\", help=r\"highest \\ell of spherical harmonics\", type=int, default=3\n    )\n    parser.add_argument(\n        \"--correlation\", help=\"correlation order at each layer\", type=int, default=3\n    )\n    parser.add_argument(\n        \"--num_interactions\", help=\"number of interactions\", type=int, default=2\n    )\n    parser.add_argument(\n        \"--MLP_irreps\",\n        help=\"hidden irreps of the MLP in last readout\",\n        type=str,\n        default=\"16x0e\",\n    )\n    parser.add_argument(\n        \"--radial_MLP\",\n        help=\"width of the radial MLP\",\n        type=str,\n        default=\"[64, 64, 64]\",\n    )\n    parser.add_argument(\n        \"--hidden_irreps\",\n        help=\"irreps for hidden node states\",\n        type=str,\n        default=None,\n    )\n    ## add option to specify irreps by channel number and max L\n    parser.add_argument(\n        \"--num_channels\",\n        help=\"number of embedding channels\",\n        type=int,\n        default=None,\n    )\n    parser.add_argument(\n        \"--max_L\",\n        help=\"max L equivariance of the message\",\n        type=int,\n        default=None,\n    )\n    parser.add_argument(\n        \"--gate\",\n        help=\"non linearity for last readout\",\n        type=str,\n        default=\"silu\",\n        choices=[\"silu\", \"tanh\", \"abs\", \"None\"],\n    )\n    parser.add_argument(\n        \"--scaling\",\n        help=\"type of scaling to the output\",\n        type=str,\n        default=\"rms_forces_scaling\",\n        choices=[\"std_scaling\", \"rms_forces_scaling\", \"no_scaling\"],\n    )\n    parser.add_argument(\n        \"--avg_num_neighbors\",\n        help=\"normalization factor for the message\",\n        type=float,\n        default=1,\n    )\n    parser.add_argument(\n        \"--compute_avg_num_neighbors\",\n        help=\"normalization factor for the message\",\n        type=str2bool,\n        default=True,\n    )\n    parser.add_argument(\n        \"--compute_stress\",\n        help=\"Select True to compute stress\",\n        type=str2bool,\n        default=False,\n    )\n    parser.add_argument(\n        \"--compute_forces\",\n        help=\"Select True to compute forces\",\n        type=str2bool,\n        default=True,\n    )\n</code></pre>"},{"location":"mace_train_param/#dataset","title":"Dataset","text":"<pre><code>    parser.add_argument(\n        \"--train_file\",\n        help=\"Training set file, format is .xyz or .h5\",\n        type=str,\n        required=False,\n    )\n    parser.add_argument(\n        \"--valid_file\",\n        help=\"Validation set .xyz or .h5 file\",\n        default=None,\n        type=str,\n        required=False,\n    )\n    parser.add_argument(\n        \"--valid_fraction\",\n        help=\"Fraction of training set used for validation\",\n        type=float,\n        default=0.1,\n        required=False,\n    )\n    parser.add_argument(\n        \"--test_file\",\n        help=\"Test set .xyz pt .h5 file\",\n        type=str,\n    )\n    parser.add_argument(\n        \"--test_dir\",\n        help=\"Path to directory with test files named as test_*.h5\",\n        type=str,\n        default=None,\n        required=False,\n    )\n    parser.add_argument(\n        \"--multi_processed_test\",\n        help=\"Boolean value for whether the test data was multiprocessed\",\n        type=str2bool,\n        default=False,\n        required=False,\n    )\n    parser.add_argument(\n        \"--num_workers\",\n        help=\"Number of workers for data loading\",\n        type=int,\n        default=0,\n    )\n    parser.add_argument(\n        \"--pin_memory\",\n        help=\"Pin memory for data loading\",\n        default=True,\n        type=str2bool,\n    )\n    parser.add_argument(\n        \"--atomic_numbers\",\n        help=\"List of atomic numbers\",\n        type=str,\n        default=None,\n        required=False,\n    )\n    parser.add_argument(\n        \"--mean\",\n        help=\"Mean energy per atom of training set\",\n        type=float,\n        default=None,\n        required=False,\n    )\n    parser.add_argument(\n        \"--std\",\n        help=\"Standard deviation of force components in the training set\",\n        type=float,\n        default=None,\n        required=False,\n    )\n    parser.add_argument(\n        \"--statistics_file\",\n        help=\"json file containing statistics of training set\",\n        type=str,\n        default=None,\n        required=False,\n    )\n    parser.add_argument(\n        \"--E0s\",\n        help=\"Dictionary of isolated atom energies\",\n        type=str,\n        default=None,\n        required=False,\n    )\n\n\n\n    ## Keys\n    parser.add_argument(\n        \"--energy_key\",\n        help=\"Key of reference energies in training xyz\",\n        type=str,\n        default=\"REF_energy\",\n    )\n    parser.add_argument(\n        \"--forces_key\",\n        help=\"Key of reference forces in training xyz\",\n        type=str,\n        default=\"REF_forces\",\n    )\n    parser.add_argument(\n        \"--virials_key\",\n        help=\"Key of reference virials in training xyz\",\n        type=str,\n        default=\"REF_virials\",\n    )\n    parser.add_argument(\n        \"--stress_key\",\n        help=\"Key of reference stress in training xyz\",\n        type=str,\n        default=\"REF_stress\",\n    )\n    parser.add_argument(\n        \"--dipole_key\",\n        help=\"Key of reference dipoles in training xyz\",\n        type=str,\n        default=\"REF_dipole\",\n    )\n    parser.add_argument(\n        \"--charges_key\",\n        help=\"Key of atomic charges in training xyz\",\n        type=str,\n        default=\"REF_charges\",\n    )\n</code></pre>"},{"location":"mace_train_param/#fine-tuning","title":"Fine-tuning","text":"<pre><code>    parser.add_argument(\n        \"--foundation_filter_elements\",\n        help=\"Filter element during fine-tuning\",\n        type=str2bool,\n        default=True,\n        required=False,\n    )\n    parser.add_argument(\n        \"--heads\",\n        help=\"Dict of heads: containing individual files and E0s\",\n        type=str,\n        default=None,\n        required=False,\n    )\n    parser.add_argument(\n        \"--multiheads_finetuning\",\n        help=\"Boolean value for whether the model is multiheaded\",\n        type=str2bool,\n        default=True,\n    )\n    parser.add_argument(\n        \"--weight_pt_head\",\n        help=\"Weight of the pretrained head in the loss function\",\n        type=float,\n        default=1.0,\n    )\n    parser.add_argument(\n        \"--num_samples_pt\",\n        help=\"Number of samples in the pretrained head\",\n        type=int,\n        default=1000,\n    )\n    parser.add_argument(\n        \"--subselect_pt\",\n        help=\"Method to subselect the configurations of the pretraining set\",\n        choices=[\"fps\", \"random\"],\n        default=\"random\",\n    )\n    parser.add_argument(\n        \"--pt_train_file\",\n        help=\"Training set file for the pretrained head\",\n        type=str,\n        default=None,\n    )\n    parser.add_argument(\n        \"--pt_valid_file\",\n        help=\"Validation set file for the pretrained head\",\n        type=str,\n        default=None,\n    )\n    parser.add_argument(\n        \"--keep_isolated_atoms\",\n        help=\"Keep isolated atoms in the dataset, useful for transfer learning\",\n        type=str2bool,\n        default=False,\n    )\n</code></pre>"},{"location":"mace_train_param/#loss-and-optimization","title":"Loss and optimization","text":"<pre><code>    parser.add_argument(\n        \"--loss\",\n        help=\"type of loss\",\n        default=\"weighted\",\n        choices=[\n            \"ef\",\n            \"weighted\",\n            \"forces_only\",\n            \"virials\",\n            \"stress\",\n            \"dipole\",\n            \"huber\",\n            \"universal\",\n            \"energy_forces_dipole\",\n        ],\n    )\n    parser.add_argument(\n        \"--forces_weight\", help=\"weight of forces loss\", type=float, default=100.0\n    )\n    parser.add_argument(\n        \"--swa_forces_weight\",\n        \"--stage_two_forces_weight\",\n        help=\"weight of forces loss after starting Stage Two (previously called swa)\",\n        type=float,\n        default=100.0,\n        dest=\"swa_forces_weight\",\n    )\n    parser.add_argument(\n        \"--energy_weight\", help=\"weight of energy loss\", type=float, default=1.0\n    )\n    parser.add_argument(\n        \"--swa_energy_weight\",\n        \"--stage_two_energy_weight\",\n        help=\"weight of energy loss after starting Stage Two (previously called swa)\",\n        type=float,\n        default=1000.0,\n        dest=\"swa_energy_weight\",\n    )\n    parser.add_argument(\n        \"--virials_weight\", help=\"weight of virials loss\", type=float, default=1.0\n    )\n    parser.add_argument(\n        \"--swa_virials_weight\",\n        \"--stage_two_virials_weight\",\n        help=\"weight of virials loss after starting Stage Two (previously called swa)\",\n        type=float,\n        default=10.0,\n        dest=\"swa_virials_weight\",\n    )\n    parser.add_argument(\n        \"--stress_weight\", help=\"weight of virials loss\", type=float, default=1.0\n    )\n    parser.add_argument(\n        \"--swa_stress_weight\",\n        \"--stage_two_stress_weight\",\n        help=\"weight of stress loss after starting Stage Two (previously called swa)\",\n        type=float,\n        default=10.0,\n        dest=\"swa_stress_weight\",\n    )\n    parser.add_argument(\n        \"--dipole_weight\", help=\"weight of dipoles loss\", type=float, default=1.0\n    )\n    parser.add_argument(\n        \"--swa_dipole_weight\",\n        \"--stage_two_dipole_weight\",\n        help=\"weight of dipoles after starting Stage Two (previously called swa)\",\n        type=float,\n        default=1.0,\n        dest=\"swa_dipole_weight\",\n    )\n    parser.add_argument(\n        \"--config_type_weights\",\n        help=\"String of dictionary containing the weights for each config type\",\n        type=str,\n        default='{\"Default\":1.0}',\n    )\n    parser.add_argument(\n        \"--huber_delta\",\n        help=\"delta parameter for huber loss\",\n        type=float,\n        default=0.01,\n    )\n    parser.add_argument(\n        \"--optimizer\",\n        help=\"Optimizer for parameter optimization\",\n        type=str,\n        default=\"adam\",\n        choices=[\"adam\", \"adamw\", \"schedulefree\"],\n    )\n    parser.add_argument(\n        \"--beta\",\n        help=\"Beta parameter for the optimizer\",\n        type=float,\n        default=0.9,\n    )\n    parser.add_argument(\"--batch_size\", help=\"batch size\", type=int, default=10)\n    parser.add_argument(\n        \"--valid_batch_size\", help=\"Validation batch size\", type=int, default=10\n    )\n    parser.add_argument(\n        \"--lr\", help=\"Learning rate of optimizer\", type=float, default=0.01\n    )\n    parser.add_argument(\n        \"--swa_lr\",\n        \"--stage_two_lr\",\n        help=\"Learning rate of optimizer in Stage Two (previously called swa)\",\n        type=float,\n        default=1e-3,\n        dest=\"swa_lr\",\n    )\n    parser.add_argument(\n        \"--weight_decay\", help=\"weight decay (L2 penalty)\", type=float, default=5e-7\n    )\n    parser.add_argument(\n        \"--amsgrad\",\n        help=\"use amsgrad variant of optimizer\",\n        action=\"store_true\",\n        default=True,\n    )\n    parser.add_argument(\n        \"--scheduler\", help=\"Type of scheduler\", type=str, default=\"ReduceLROnPlateau\"\n    )\n    parser.add_argument(\n        \"--lr_factor\", help=\"Learning rate factor\", type=float, default=0.8\n    )\n    parser.add_argument(\n        \"--scheduler_patience\", help=\"Learning rate factor\", type=int, default=50\n    )\n    parser.add_argument(\n        \"--lr_scheduler_gamma\",\n        help=\"Gamma of learning rate scheduler\",\n        type=float,\n        default=0.9993,\n    )\n    parser.add_argument(\n        \"--swa\",\n        \"--stage_two\",\n        help=\"use Stage Two loss weight, which decreases the learning rate and increases the energy weight at the end of the training to help converge them\",\n        action=\"store_true\",\n        default=False,\n        dest=\"swa\",\n    )\n    parser.add_argument(\n        \"--start_swa\",\n        \"--start_stage_two\",\n        help=\"Number of epochs before changing to Stage Two loss weights\",\n        type=int,\n        default=None,\n        dest=\"start_swa\",\n    )\n    parser.add_argument(\n        \"--ema\",\n        help=\"use Exponential Moving Average\",\n        action=\"store_true\",\n        default=False,\n    )\n    parser.add_argument(\n        \"--ema_decay\",\n        help=\"Exponential Moving Average decay\",\n        type=float,\n        default=0.99,\n    )\n    parser.add_argument(\n        \"--max_num_epochs\", help=\"Maximum number of epochs\", type=int, default=2048\n    )\n    parser.add_argument(\n        \"--patience\",\n        help=\"Maximum number of consecutive epochs of increasing loss\",\n        type=int,\n        default=2048,\n    )\n    parser.add_argument(\n        \"--foundation_model\",\n        help=\"Path to the foundation model for transfer learning\",\n        type=str,\n        default=None,\n    )\n    parser.add_argument(\n        \"--foundation_model_readout\",\n        help=\"Use readout of foundation model for transfer learning\",\n        action=\"store_false\",\n        default=True,\n    )\n    parser.add_argument(\n        \"--eval_interval\", help=\"evaluate model every &lt;n&gt; epochs\", type=int, default=1\n    )\n    parser.add_argument(\n        \"--keep_checkpoints\",\n        help=\"keep all checkpoints\",\n        action=\"store_true\",\n        default=False,\n    )\n    parser.add_argument(\n        \"--save_all_checkpoints\",\n        help=\"save all checkpoints\",\n        action=\"store_true\",\n        default=False,\n    )\n    parser.add_argument(\n        \"--restart_latest\",\n        help=\"restart optimizer from latest checkpoint\",\n        action=\"store_true\",\n        default=False,\n    )\n    parser.add_argument(\n        \"--save_cpu\",\n        help=\"Save a model to be loaded on cpu\",\n        action=\"store_true\",\n        default=False,\n    )\n    parser.add_argument(\n        \"--clip_grad\",\n        help=\"Gradient Clipping Value\",\n        type=check_float_or_none,\n        default=10.0,\n    )\n    ## options for using Weights and Biases for experiment tracking\n    ## to install see https://wandb.ai\n    parser.add_argument(\n        \"--wandb\",\n        help=\"Use Weights and Biases for experiment tracking\",\n        action=\"store_true\",\n        default=False,\n    )\n    parser.add_argument(\n        \"--wandb_dir\",\n        help=\"An absolute path to a directory where Weights and Biases metadata will be stored\",\n        type=str,\n        default=None,\n    )\n    parser.add_argument(\n        \"--wandb_project\",\n        help=\"Weights and Biases project name\",\n        type=str,\n        default=\"\",\n    )\n    parser.add_argument(\n        \"--wandb_entity\",\n        help=\"Weights and Biases entity name\",\n        type=str,\n        default=\"\",\n    )\n    parser.add_argument(\n        \"--wandb_name\",\n        help=\"Weights and Biases experiment name\",\n        type=str,\n        default=\"\",\n    )\n    parser.add_argument(\n        \"--wandb_log_hypers\",\n        help=\"The hyperparameters to log in Weights and Biases\",\n        type=list,\n        default=[\n            \"num_channels\",\n            \"max_L\",\n            \"correlation\",\n            \"lr\",\n            \"swa_lr\",\n            \"weight_decay\",\n            \"batch_size\",\n            \"max_num_epochs\",\n            \"start_swa\",\n            \"energy_weight\",\n            \"forces_weight\",\n        ],\n    )\n    return parser\n</code></pre>"},{"location":"sevenn_train_param/","title":"SevenNet parameters for training model","text":"<p>There are preset parameters:</p> <ul> <li>base</li> <li>fine_tune</li> <li>sevennet-0</li> </ul> <p>See full full development parameters here.</p> <p>To access energy, force, and stress, in <code>extxyz</code> dataset, the following keys are used: <pre><code>data:\n    data_format_args:\n        energy_key: 'TotEnergy'\n        force_key: 'force'\n        stress_key: 'stress'\n</code></pre></p>"},{"location":"sevenn_train_param/#base","title":"base","text":"<pre><code># Example input.yaml for training SevenNet.\n# '*' signifies default. You can check log.sevenn for defaults.\n\nmodel:\n    chemical_species: 'Auto'                      # Chemical elements present in the dataset, guess them from load_dataset data if 'auto'\n    cutoff: 5.0                                   # Cutoff radius in Angstroms. If two atoms are within the cutoff, they are connected.\n    channel: 32                                   # The multiplicity(channel) of node features.\n    lmax: 2                                       # Maximum order of irreducible representations (rotation order).\n    num_convolution_layer: 3                      # The number of message passing layers.\n\n    #irreps_manual:                               # Manually set irreps of the model in each layer\n        #- \"128x0e\"\n        #- \"128x0e+64x1e+32x2e\"\n        #- \"128x0e+64x1e+32x2e\"\n        #- \"128x0e+64x1e+32x2e\"\n        #- \"128x0e+64x1e+32x2e\"\n        #- \"128x0e\"\n\n    weight_nn_hidden_neurons: [64, 64]            # Hidden neurons in convolution weight neural network\n    radial_basis:                                 # Function and its parameters to encode radial distance\n        radial_basis_name: 'bessel'               # Only 'bessel' is currently supported\n        bessel_basis_num: 8\n    cutoff_function:                              # Envelop function, multiplied to radial_basis functions to init edge featrues\n        cutoff_function_name: 'poly_cut'          # {'poly_cut' and 'poly_cut_p_value'} or {'XPLOR' and 'cutoff_on'}\n        poly_cut_p_value: 6\n\n    act_gate: {'e': 'silu', 'o': 'tanh'}          # Equivalent to 'nonlinearity_gates' in nequip\n    act_scalar: {'e': 'silu', 'o': 'tanh'}        # Equivalent to 'nonlinearity_scalars' in nequip\n\n    is_parity: False                              # Pairy True (E(3) group) or False (to SE(3) group)\n\n    self_connection_type: 'nequip'                # Default is 'nequip'. 'linear' is used for SevenNet-0.\n\n    conv_denominator: \"avg_num_neigh\"             # Valid options are \"avg_num_neigh*\", \"sqrt_avg_num_neigh\", or float\n    train_denominator: False                      # Enable training for denominator in convolution layer\n    train_shift_scale: False                      # Enable training for shift &amp; scale in output layer\n\ntrain:\n    random_seed: 1\n    is_train_stress: True                         # Includes stress in the loss function\n    epoch: 200                                    # Ends training after this number of epochs\n\n    #loss: 'Huber'                                # Default is 'mse' (mean squared error)\n    #loss_param:\n        #delta: 0.01\n\n    # Each optimizer and scheduler have different available parameters.\n    # You can refer to sevenn/train/optim.py for supporting optimizer &amp; schedulers\n    optimizer: 'adam'                             # Options available are 'sgd', 'adagrad', 'adam', 'adamw', 'radam'\n    optim_param:\n        lr: 0.005\n    scheduler: 'exponentiallr'                    # 'steplr', 'multisteplr', 'exponentiallr', 'cosineannealinglr', 'reducelronplateau', 'linearlr'\n    scheduler_param:\n        gamma: 0.99\n\n    force_loss_weight: 0.1                        # Coefficient for force loss\n    stress_loss_weight: 1e-06                     # Coefficient for stress loss (to kbar unit)\n\n    per_epoch: 10                                 # Generate checkpoints every this epoch\n\n    # ['target y', 'metric']\n    # Target y: TotalEnergy, Energy, Force, Stress, Stress_GPa, TotalLoss\n    # Metric  : RMSE, MAE, or Loss\n    error_record:\n        - ['Energy', 'RMSE']\n        - ['Force', 'RMSE']\n        - ['Stress', 'RMSE']\n        - ['TotalLoss', 'None']\n\n    # Continue training model from given checkpoint, or pre-trained model checkpoint for fine-tuning\n    #continue:\n        #checkpoint: 'checkpoint_best.pth'         # Checkpoint of pre-trained model or a model want to continue training.\n        #reset_optimizer: False                    # Set True for fine-tuning\n        #reset_scheduler: False                    # Set True for fine-tuning\n        #use_statistic_values_of_checkpoint: False # Set True to use shift, scale, and avg_num_neigh from checkpoint or not\n\ndata:\n    batch_size: 4                                 # Per GPU batch size.\n    data_divide_ratio: 0.1                        # Split dataset into training and validation sets by this ratio\n\n    shift: 'per_atom_energy_mean'                 # One of 'per_atom_energy_mean*', 'elemwise_reference_energies', float\n    scale: 'force_rms'                            # One of 'force_rms*', 'per_atom_energy_std', 'elemwise_force_rms', float\n\n    # ase.io.read readable data files or structure_list or .sevenn_data files can be used as dataset.\n    # .sevenn_data is preprocessed data set has edges connected (can be obtained by using sevenn_graph_build or by save_** options below)\n    data_format: 'ase'                            # One of 'ase', 'structure_list' (.sevenn_data is always readable)\n    data_format_args:                             # if `data_format` is `ase`, args will be passed to `ase.io.read`\n        index: ':'                                # see `https://wiki.fysik.dtu.dk/ase/ase/io/io.html` for more valid arguments\n\n    # If only load_dataset_path is provided, train/valid set is automatically decided by splitting dataset by divide ratio\n    # If both load_dataset_path &amp; load_validset_path is provided, use load_dataset_path as training set.\n    load_dataset_path: ['../data/train.extxyz']   # Example of using ase as data_format, support multiple datasets and expansion(*)\n    #load_validset_path: ['./valid.sevenn_data']\n\n    #save_dataset_path: './total'                 # Save the preprocessed (in load_dataset_path) dataset\n    #save_by_train_valid: True                    # Save the preprocessed train.sevenn_data, valid.sevenn_data\n</code></pre>"},{"location":"sevenn_train_param/#fine_tune","title":"fine_tune","text":"<pre><code># Example input.yaml for fine-tuning sevennet-0\n# '*' signifies default. You can check log.sevenn for defaults.\n\nmodel:  # model keys should be consistent except for train_* keys\n    chemical_species: 'Auto'\n    cutoff: 5.0\n    channel: 128\n    is_parity: False\n    lmax: 2\n    num_convolution_layer: 5\n    irreps_manual:\n        - \"128x0e\"\n        - \"128x0e+64x1e+32x2e\"\n        - \"128x0e+64x1e+32x2e\"\n        - \"128x0e+64x1e+32x2e\"\n        - \"128x0e+64x1e+32x2e\"\n        - \"128x0e\"\n\n    weight_nn_hidden_neurons: [64, 64]\n    radial_basis:\n        radial_basis_name: 'bessel'\n        bessel_basis_num: 8\n    cutoff_function:\n        cutoff_function_name: 'XPLOR'\n        cutoff_on: 4.5\n    self_connection_type: 'linear'\n\n    train_shift_scale: False   # customizable (True | False)\n    train_denominator: False   # customizable (True | False)\n\ntrain:  # Customizable\n    random_seed: 1\n    is_train_stress: True\n    epoch: 100\n\n    optimizer: 'adam'\n    optim_param:\n        lr: 0.004\n    scheduler: 'exponentiallr'\n    scheduler_param:\n        gamma: 0.99\n\n    force_loss_weight: 0.1\n    stress_loss_weight: 1e-06\n\n    per_epoch: 10  # Generate checkpoints every this epoch\n\n    # ['target y', 'metric']\n    # Target y: TotalEnergy, Energy, Force, Stress, Stress_GPa, TotalLoss\n    # Metric  : RMSE, MAE, or Loss\n    error_record:\n        - ['Energy', 'RMSE']\n        - ['Force', 'RMSE']\n        - ['Stress', 'RMSE']\n        - ['TotalLoss', 'None']\n\n    continue:\n        reset_optimizer: True\n        reset_scheduler: True\n        reset_epoch: True\n        checkpoint: 'SevenNet-0_11July2024'\n        # Set True to use shift, scale, and avg_num_neigh from checkpoint (highly recommended)\n        use_statistic_values_of_checkpoint: True\n\ndata:  # Customizable\n    batch_size: 4\n    data_divide_ratio: 0.1\n\n    # ase.io.read readable data files or structure_list or .sevenn_data files can be used as dataset.\n    # .sevenn_data is preprocessed data set has edges connected (can be obtained by using sevenn_graph_build or by save_** options below)\n    data_format: 'ase'                            # One of 'ase', 'structure_list' (.sevenn_data is always readable)\n    data_format_args:                             # if `data_format` is `ase`, args will be passed to `ase.io.read`\n        index: ':'                                # see `https://wiki.fysik.dtu.dk/ase/ase/io/io.html` for more valid arguments\n\n    # If only load_dataset_path is provided, train/valid set is automatically decided by splitting dataset by divide ratio\n    # If both load_dataset_path &amp; load_validset_path is provided, use load_dataset_path as training set.\n    load_dataset_path: ['fine_tune.extxyz']       # Support multiple files and expansion(*)\n    #load_validset_path: ['./valid.sevenn_data']\n\n    #save_dataset_path: './total'                 # Save the preprocessed (in load_dataset_path) dataset\n    #save_by_train_valid: True                    # Save the preprocessed train.sevenn_data, valid.sevenn_data\n</code></pre>"},{"location":"sevenn_train_param/#sevennet-0","title":"sevennet-0","text":"<pre><code># SevenNet-0\nmodel:\n    chemical_species: 'auto'\n    cutoff: 5.0\n    channel: 128\n    is_parity: False\n    lmax: 2\n    num_convolution_layer: 5\n    irreps_manual:\n        - \"128x0e\"\n        - \"128x0e+64x1e+32x2e\"\n        - \"128x0e+64x1e+32x2e\"\n        - \"128x0e+64x1e+32x2e\"\n        - \"128x0e+64x1e+32x2e\"\n        - \"128x0e\"\n\n    weight_nn_hidden_neurons: [64, 64]\n    radial_basis:\n        radial_basis_name: 'bessel'\n        bessel_basis_num: 8\n    cutoff_function:\n        cutoff_function_name: 'XPLOR'\n        cutoff_on: 4.5\n\n    act_gate: {'e': 'silu', 'o': 'tanh'}\n    act_scalar: {'e': 'silu', 'o': 'tanh'}\n\n    conv_denominator: 'avg_num_neigh'\n    train_shift_scale: False\n    train_denominator: False\n    self_connection_type: 'linear'\ntrain:\n    train_shuffle: False\n    random_seed: 1\n    is_train_stress : True\n    epoch: 600\n\n    loss: 'Huber'\n    loss_param:\n        delta: 0.01\n\n    optimizer: 'adam'\n    optim_param:\n        lr: 0.01\n    scheduler: 'linearlr'\n    scheduler_param:\n        start_factor: 1.0\n        total_iters: 600\n        end_factor: 0.0001\n\n    force_loss_weight : 1.00\n    stress_loss_weight: 0.01\n\n    error_record:\n        - ['Energy', 'RMSE']\n        - ['Force', 'RMSE']\n        - ['Stress', 'RMSE']\n        - ['Energy', 'MAE']\n        - ['Force', 'MAE']\n        - ['Stress', 'MAE']\n        - ['Energy', 'Loss']\n        - ['Force', 'Loss']\n        - ['Stress', 'Loss']\n        - ['TotalLoss', 'None']\n\n    per_epoch: 10\n    # continue:\n    #    checkpoint: './checkpoint_last.pth'\n    #    reset_optimizer: False\n    #    reset_scheduler: False\ndata:\n    data_shuffle: False\n    batch_size: 128  # per GPU batch size, as the model trained with 32 GPUs, the effective batch size equals 4096.\n    scale: 'per_atom_energy_std'\n    shift: 'elemwise_reference_energies'\n\n    data_format: 'ase'\n    save_by_train_valid: False\n    load_dataset_path: [\"path_to_MPtrj_total.sevenn_data\"]\n    load_validset_path: [\"validaset.sevenn_data\"]\n</code></pre>"},{"location":"sevenn_train_param/#full-parameters","title":"Full parameters","text":"<pre><code># Example input.yaml for training SevenNet.\n# The underlying model is nequip (https://github.com/mir-group/nequip), but the names of hyperparameters might different.\n# Defaults model parameter that works well of channel, lmax, and num_convolution_layer are 32, 1, 3 respectively.\n# '*' signifies default. You can check log.sevenn.\n\nmodel:\n    chemical_species: 'Auto'                      # Chemical elements present in the dataset, guess them from load_dataset data if 'auto'\n    cutoff: 5.0                                   # Cutoff radius in Angstroms. If two atoms are within the cutoff, they are connected.\n    channel: 4                                    # The multiplicity(channel) of node features.\n    lmax: 1                                       # Maximum order of irreducible representations (rotation order).\n    num_convolution_layer: 4                      # The number of message passing layers.\n\n    #irreps_manual:                               # Manually set irreps of the model in each layer\n        #- \"128x0e\"\n        #- \"128x0e+64x1e+32x2e\"\n        #- \"128x0e+64x1e+32x2e\"\n        #- \"128x0e+64x1e+32x2e\"\n        #- \"128x0e+64x1e+32x2e\"\n        #- \"128x0e\"\n\n    weight_nn_hidden_neurons: [64, 64]            # Hidden neurons in convolution weight neural network\n    radial_basis:                                 # Function and its parameters to encode radial distance\n        radial_basis_name: 'bessel'               # Only 'bessel' is currently supported\n        bessel_basis_num: 8\n    cutoff_function:                              # Envelop function, multiplied to radial_basis functions to init edge featrues\n        cutoff_function_name: 'poly_cut'          # {'poly_cut' and 'poly_cut_p_value'} or {'XPLOR' and 'cutoff_on'}\n        poly_cut_p_value: 6\n\n    act_gate: {'e': 'silu', 'o': 'tanh'}          # Equivalent to 'nonlinearity_gates' in nequip\n    act_scalar: {'e': 'silu', 'o': 'tanh'}        # Equivalent to 'nonlinearity_scalars' in nequip\n\n    is_parity: False                              # Pairy True (E(3) group) or False (to SE(3) group)\n\n    self_connection_type: 'nequip'                # Default is 'nequip'. 'linear' is used for SevenNet-0.\n\n    conv_denominator: \"avg_num_neigh\"             # Valid options are \"avg_num_neigh*\", \"sqrt_avg_num_neigh\", or float\n    train_shift_scale: False                      # Enable training for shift &amp; scale in output layer\n    train_denominator: False                      # Enable training for denominator in convolution layer\n\ntrain:\n    random_seed: 1\n    is_train_stress: True                         # Includes stress in the loss function\n    epoch: 10                                     # Ends training after this number of epochs\n\n    #loss: 'Huber'                                # Default is 'mse' (mean squared error)\n    #loss_param:\n        #delta: 0.01\n\n    # Each optimizer and scheduler have different available parameters.\n    # You can refer to sevenn/train/optim.py for supporting optimizer &amp; schedulers\n    optimizer: 'adam'                             # Options available are 'sgd', 'adagrad', 'adam', 'adamw', 'radam'\n    optim_param:\n        lr: 0.005\n    scheduler: 'exponentiallr'                    # One of 'steplr', 'multisteplr', 'exponentiallr', 'cosineannealinglr', 'reducelronplateau', 'linearlr'\n    scheduler_param:\n        gamma: 0.99\n\n    force_loss_weight: 0.1                        # Coefficient for force loss\n    stress_loss_weight: 1e-06                     # Coefficient for stress loss (to kbar unit)\n\n    per_epoch:  5                                # Generate checkpoints every this epoch\n\n    # TotalEnergy, Energy, Force, Stress, Stress_GPa, TotalLoss\n    # RMSE, MAE, or Loss\n    error_record:\n        - ['Energy', 'RMSE']\n        - ['Force', 'RMSE']\n        - ['Stress', 'RMSE']\n        - ['TotalLoss', 'None']\n\n    # Continue training model from given checkpoint, or pre-trained model checkpoint for fine-tuning\n    #continue:\n        #reset_optimizer: False                    # Set True for fine-tuning\n        #reset_scheduler: False                    # Set True for fine-tuning\n        #checkpoint: 'checkpoint_best.pth'         # Checkpoint of pre-trained model or a model want to continue training.\n        #use_statistic_values_of_checkpoint: False # Set True to use shift, scale, and avg_num_neigh from checkpoint or not\n\n    # If the dataset changed (for fine-tuning),\n    # setting 'use_statistic_value_of_checkpoint' to True roughly changes model's accuracy in the beginning of training.\n    # We recommand to use it as False, and turn train_shift_scale and train_avg_num_neigh to True.\n\ndata:\n    batch_size: 2                                 # Per GPU batch size.\n    data_divide_ratio: 0.1                        # Split dataset into training and validation sets by this ratio\n\n    #shift: 'per_atom_energy_mean'                # One of 'per_atom_energy_mean*', 'elemwise_reference_energies', float\n    #scale: 'force_rms'                           # One of 'force_rms*', 'per_atom_energy_std', 'elemwise_force_rms', float\n\n    # ase.io.read readable data files or structure_list or .sevenn_data files can be used as dataset.\n    # .sevenn_data is preprocessed data set has edges connected (can be obtained by using sevenn_graph_build or by save_** options below)\n    data_format: 'ase'                   # Default is 'ase'. Choices are 'ase', 'structure_list', '.sevenn_data'\n    data_format_args:                            # Paramaters, will be passed to ase.io.read\n        energy_key: 'TotEnergy'                  # Key for energy in extxyz file\n        force_key: 'force'                       # Key for force in extxyz file\n\n    # ASE tries to infer its type by extension, in this case, extxyz file is loaded by ase.\n    #load_dataset_path: ['../data/test.extxyz']   # Example of using ase as data_format\n\n    # If only load_dataset_path is provided, train/valid set is automatically decided by splitting dataset by divide ratio\n    # If both load_dataset_path &amp; load_validset_path is provided, use load_dataset_path as training set.\n    load_dataset_path: ['./1_process_data/dataset_1593.xyz']\n    #load_validset_path: ['./valid.sevenn_data']\n\n    #save_dataset_path: 'total'                   # Save the preprocessed (in load_dataset_path) dataset\n    #save_by_train_valid: True                    # Save the preprocessed train.sevenn_data, valid.sevenn_data\n    #save_by_label: False                         # Save the dataset by labels specified in the structure_list\n</code></pre>"}]}