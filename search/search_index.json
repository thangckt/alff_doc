{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"<code>alff</code> Documentation","text":""},{"location":"#alff","title":"<code>alff</code>","text":"<p>ALFF: Active Learning Framework for generating Machine Learning Forcefields.</p> <p>This package is developed and maintained by C.Thang Nguyen</p>"},{"location":"alff_active_learning/","title":"ALFF: Active Learning","text":"<p>Run the main ALFF active learning process.</p> <pre><code>alff_al PARAM.yaml MACHINE.yaml\n</code></pre> <ul> <li><code>PARAM.yaml</code>: The parameters of the generator.</li> <li><code>MACHINE.yaml</code>: The settings of the machines running the generator's subprocesses.</li> </ul> <p>An example run:</p> <pre><code>-------------------------------- ALFF --------------------------------\n    Version:  0.1.dev409+g177de1d\n       Path:  C:/conda/envs/py13/Lib/site-packages/alff\n---------------------------- Dependencies ----------------------------\n       numpy  1.26.4       C:/conda/envs/py11/Lib/site-packages/numpy\n       scipy  1.13.0       C:/conda/envs/py11/Lib/site-packages/scipy\n         ase  3.23.1b1     C:/conda/envs/py11/Lib/site-packages/ase\n      polars  1.11.0       C:/conda/envs/py11/Lib/site-packages/polars\n      thutil  0.1.dev122   C:/conda/envs/py11/Lib/site-packages/thutil\n      sevenn  0.10.1       C:/conda/envs/py11/Lib/site-packages/sevenn\n     phonopy  2.29.1       C:/conda/envs/py11/Lib/site-packages/phonopy\n----------------------- Author: C.Thang Nguyen -----------------------\n--------------- Contact: http://thang.eu.org/email ----------------\n\n                             ___    __    ____________\n                            /   |  / /   / ____/ ____/\n                           / /| | / /   / /_  / /_\n                          / ___ |/ /___/ __/ / __/\n                         /_/  |_/_____/_/   /_/\n\nalff-INFO: START ACTIVE LEARNING\nalff-INFO: ======================= iter_000000 ========================\nalff-INFO: ------------- iter_000000 stage_00: pre_train --------------\nalff-INFO: ------------- iter_000000 stage_01: run_train --------------\nalff-INFO: Trainning ML models... be patient\n               Remote host: some_IP_address\n               Remote path: /uwork/user01/work/w24_alff_job\n               Log file: logs/20241020_220540_dispatcher.log\n</code></pre>"},{"location":"alff_api/","title":"API","text":""},{"location":"alff_api/#alff","title":"<code>alff</code>","text":"<p>ALFF: Active Learning Framework for generating Machine Learning Forcefields.</p> <p>This package is developed and maintained by C.Thang Nguyen</p> <p>Modules:</p> <ul> <li> <code>al</code>           \u2013            </li> <li> <code>cli</code>           \u2013            </li> <li> <code>data</code>           \u2013            </li> <li> <code>elastic</code>           \u2013            </li> <li> <code>phonon</code>           \u2013            </li> <li> <code>util</code>           \u2013            </li> </ul> <p>Attributes:</p> <ul> <li> <code>ROOT_PATH</code>           \u2013            </li> <li> <code>__author__</code>           \u2013            </li> <li> <code>__contact__</code>           \u2013            </li> </ul>"},{"location":"alff_api/#alff.ROOT_PATH","title":"<code>ROOT_PATH = Path(__file__).parent</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.__author__","title":"<code>__author__ = 'C.Thang Nguyen'</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.__contact__","title":"<code>__contact__ = 'http://thang.eu.org/email'</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.al","title":"<code>al</code>","text":"<p>Modules:</p> <ul> <li> <code>active_learning</code>           \u2013            <p>iter:</p> </li> <li> <code>finetune</code>           \u2013            </li> <li> <code>lib_al_gpaw</code>           \u2013            <p>Move all the GPAW related functions to here.</p> </li> <li> <code>lib_al_lammps</code>           \u2013            </li> <li> <code>lib_uncertainty</code>           \u2013            </li> </ul>"},{"location":"alff_api/#alff.al.active_learning","title":"<code>active_learning</code>","text":"iter <p>0_train 1_model_devi 2_dft 3_data</p> <p>Functions:</p> <ul> <li> <code>get_sys_index</code>             \u2013              </li> <li> <code>pre_train</code>             \u2013              <p>This function prepares:</p> </li> <li> <code>run_train</code>             \u2013              </li> <li> <code>post_train</code>             \u2013              </li> <li> <code>pre_md</code>             \u2013              </li> <li> <code>run_md</code>             \u2013              </li> <li> <code>run_md_lammps_7net</code>             \u2013              </li> <li> <code>run_md_model_devi</code>             \u2013              </li> <li> <code>post_md</code>             \u2013              </li> <li> <code>check_cluster</code>             \u2013              </li> <li> <code>check_bad_box</code>             \u2013              </li> <li> <code>pre_fp_custom</code>             \u2013              <p>Make input file for customized FP style.</p> </li> <li> <code>pre_fp</code>             \u2013              <p>Select the candidate strutures and make the input file of FP calculation.</p> </li> <li> <code>pre_fp_calculation</code>             \u2013              <p>Make the input file of FP calculation.</p> </li> <li> <code>run_fp_inner</code>             \u2013              </li> <li> <code>run_fp</code>             \u2013              </li> <li> <code>post_fp_check_fail</code>             \u2013              </li> <li> <code>post_fp_vasp</code>             \u2013              </li> <li> <code>post_fp_custom</code>             \u2013              <p>Post fp for custom fp. Collect data from user-defined <code>output_fn</code>.</p> </li> <li> <code>post_fp</code>             \u2013              </li> <li> <code>al_iteration</code>             \u2013              <p>Run main loop of active learning.</p> </li> </ul>"},{"location":"alff_api/#alff.al.active_learning._get_mlp_engine","title":"<code>_get_mlp_engine(pdict)</code>","text":""},{"location":"alff_api/#alff.al.active_learning.get_sys_index","title":"<code>get_sys_index(task)</code>","text":""},{"location":"alff_api/#alff.al.active_learning.pre_train","title":"<code>pre_train(iter_idx, pdict, mdict)</code>","text":"<p>This function prepares: - collect data files - prepare training args based MLP engine</p>"},{"location":"alff_api/#alff.al.active_learning.run_train","title":"<code>run_train(iter_idx, pdict, mdict)</code>","text":""},{"location":"alff_api/#alff.al.active_learning.post_train","title":"<code>post_train(iter_idx, pdict, mdict)</code>","text":""},{"location":"alff_api/#alff.al.active_learning.pre_md","title":"<code>pre_md(iter_idx, pdict, mdict)</code>","text":""},{"location":"alff_api/#alff.al.active_learning.run_md","title":"<code>run_md(iter_idx, pdict, mdict)</code>","text":""},{"location":"alff_api/#alff.al.active_learning.run_md_lammps_7net","title":"<code>run_md_lammps_7net(iter_idx, pdict, mdict)</code>","text":""},{"location":"alff_api/#alff.al.active_learning.run_md_model_devi","title":"<code>run_md_model_devi(iter_idx, pdict, mdict)</code>","text":""},{"location":"alff_api/#alff.al.active_learning.post_md","title":"<code>post_md(iter_idx, pdict, mdict)</code>","text":""},{"location":"alff_api/#alff.al.active_learning.check_cluster","title":"<code>check_cluster(conf_name, fp_cluster_vacuum, fmt='lammps/dump')</code>","text":""},{"location":"alff_api/#alff.al.active_learning.check_bad_box","title":"<code>check_bad_box(conf_name, criteria, fmt='lammps/dump')</code>","text":""},{"location":"alff_api/#alff.al.active_learning._read_model_devi_file","title":"<code>_read_model_devi_file(task_path: str, model_devi_f_avg_relative: bool = False, model_devi_merge_traj: bool = False)</code>","text":""},{"location":"alff_api/#alff.al.active_learning._select_by_model_devi_standard","title":"<code>_select_by_model_devi_standard(modd_system_task: list[str], f_trust_lo: float, f_trust_hi: float, v_trust_lo: float, v_trust_hi: float, cluster_cutoff: float, model_devi_engine: str, model_devi_skip: int = 0, model_devi_f_avg_relative: bool = False, model_devi_merge_traj: bool = False, detailed_report_pre_fp: bool = True)</code>","text":""},{"location":"alff_api/#alff.al.active_learning._select_by_model_devi_adaptive_trust_low","title":"<code>_select_by_model_devi_adaptive_trust_low(modd_system_task: list[str], f_trust_hi: float, numb_candi_f: int, perc_candi_f: float, v_trust_hi: float, numb_candi_v: int, perc_candi_v: float, model_devi_skip: int = 0, model_devi_f_avg_relative: bool = False, model_devi_merge_traj: bool = False)</code>","text":"<p>modd_system_task    model deviation tasks belonging to one system f_trust_hi numb_candi_f        number of candidate due to the f model deviation perc_candi_f        percentage of candidate due to the f model deviation v_trust_hi numb_candi_v        number of candidate due to the v model deviation perc_candi_v        percentage of candidate due to the v model deviation model_devi_skip.</p>"},{"location":"alff_api/#alff.al.active_learning._select_by_model_devi_adaptive_trust_low--returns","title":"Returns","text":"<p>accur               the accurate set candi               the candidate set failed              the failed set counter             counters, number of elements in the sets f_trust_lo          adapted trust level of f v_trust_lo          adapted trust level of v</p>"},{"location":"alff_api/#alff.al.active_learning.pre_fp_custom","title":"<code>pre_fp_custom(iter_idx, pdict)</code>","text":"<p>Make input file for customized FP style.</p> <p>Convert the POSCAR file to custom format.</p>"},{"location":"alff_api/#alff.al.active_learning.pre_fp_custom--parameters","title":"Parameters","text":"<p>iter_idx : int     iter index pdict : dict     Run parameters.</p>"},{"location":"alff_api/#alff.al.active_learning.pre_fp","title":"<code>pre_fp(iter_idx, pdict, mdict)</code>","text":"<p>Select the candidate strutures and make the input file of FP calculation.</p>"},{"location":"alff_api/#alff.al.active_learning.pre_fp--parameters","title":"Parameters","text":"<p>iter_idx : int     iter index pdict : dict     Run parameters. mdict : dict     Machine parameters.</p>"},{"location":"alff_api/#alff.al.active_learning.pre_fp_calculation","title":"<code>pre_fp_calculation(iter_idx, pdict, mdict)</code>","text":"<p>Make the input file of FP calculation.</p>"},{"location":"alff_api/#alff.al.active_learning.pre_fp_calculation--parameters","title":"Parameters","text":"<p>iter_idx : int     iter index pdict : dict     Run parameters. mdict : dict     Machine parameters.</p>"},{"location":"alff_api/#alff.al.active_learning._vasp_check_fin","title":"<code>_vasp_check_fin(ii)</code>","text":""},{"location":"alff_api/#alff.al.active_learning._qe_check_fin","title":"<code>_qe_check_fin(ii)</code>","text":""},{"location":"alff_api/#alff.al.active_learning.run_fp_inner","title":"<code>run_fp_inner(iter_idx, pdict, mdict, forward_files, backward_files, check_fin, log_file='fp.log', forward_common_files=[])</code>","text":""},{"location":"alff_api/#alff.al.active_learning.run_fp","title":"<code>run_fp(iter_idx, pdict, mdict)</code>","text":""},{"location":"alff_api/#alff.al.active_learning.post_fp_check_fail","title":"<code>post_fp_check_fail(iter_idx, pdict, rfailed=None)</code>","text":""},{"location":"alff_api/#alff.al.active_learning.post_fp_vasp","title":"<code>post_fp_vasp(iter_idx, pdict, rfailed=None)</code>","text":""},{"location":"alff_api/#alff.al.active_learning.post_fp_custom","title":"<code>post_fp_custom(iter_idx, pdict)</code>","text":"<p>Post fp for custom fp. Collect data from user-defined <code>output_fn</code>.</p>"},{"location":"alff_api/#alff.al.active_learning.post_fp_custom--parameters","title":"Parameters","text":"<p>iter_idx : int     The index of the current iteration. pdict : dict     The parameter data.</p>"},{"location":"alff_api/#alff.al.active_learning.post_fp","title":"<code>post_fp(iter_idx, pdict)</code>","text":""},{"location":"alff_api/#alff.al.active_learning.al_iteration","title":"<code>al_iteration(configfile_param, configfile_machine)</code>","text":"<p>Run main loop of active learning.</p>"},{"location":"alff_api/#alff.al.finetune","title":"<code>finetune</code>","text":"<p>Functions:</p> <ul> <li> <code>pre_finetune</code>             \u2013              <p>This function prepares:</p> </li> <li> <code>run_finetune</code>             \u2013              </li> <li> <code>post_finetune</code>             \u2013              </li> <li> <code>fine_tuning</code>             \u2013              <p>Fine tune the existed ML models or train a new ML model.</p> </li> </ul>"},{"location":"alff_api/#alff.al.finetune.pre_finetune","title":"<code>pre_finetune(pdict: dict, mdict: dict)</code>","text":"<p>This function prepares: - collect data files - prepare training args based MLP engine</p>"},{"location":"alff_api/#alff.al.finetune.run_finetune","title":"<code>run_finetune(pdict: dict, mdict: dict)</code>","text":""},{"location":"alff_api/#alff.al.finetune.post_finetune","title":"<code>post_finetune(pdict: dict, mdict: dict)</code>","text":""},{"location":"alff_api/#alff.al.finetune.fine_tuning","title":"<code>fine_tuning(configfile_param: str, configfile_machine: str)</code>","text":"<p>Fine tune the existed ML models or train a new ML model.</p>"},{"location":"alff_api/#alff.al.lib_al_gpaw","title":"<code>lib_al_gpaw</code>","text":"<p>Move all the GPAW related functions to here. - functions for <code>arginfo.py</code> - functions for <code>run.py</code>.</p> <p>Functions:</p> <ul> <li> <code>pre_dft_gpaw</code>             \u2013              <p>Make input file for customized FP style.</p> </li> <li> <code>post_dft_gpaw</code>             \u2013              <p>Post fp for custom fp. Collect data from user-defined <code>output_fn</code>.</p> </li> </ul> <p>Attributes:</p> <ul> <li> <code>LIB_GPAW_PATH</code>           \u2013            </li> <li> <code>fp_name</code>           \u2013            </li> </ul>"},{"location":"alff_api/#alff.al.lib_al_gpaw.LIB_GPAW_PATH","title":"<code>LIB_GPAW_PATH = Path(f'{ROOT_PATH})/al/gpaw')</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.al.lib_al_gpaw.fp_name","title":"<code>fp_name = '02.fp'</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.al.lib_al_gpaw.pre_dft_gpaw","title":"<code>pre_dft_gpaw(iter_index, jdata)</code>","text":"<p>Make input file for customized FP style.</p>"},{"location":"alff_api/#alff.al.lib_al_gpaw.pre_dft_gpaw--parameters","title":"Parameters","text":"<p>iter_index : int     iter index jdata : dict     Run parameters.</p>"},{"location":"alff_api/#alff.al.lib_al_gpaw.post_dft_gpaw","title":"<code>post_dft_gpaw(iter_index, jdata)</code>","text":"<p>Post fp for custom fp. Collect data from user-defined <code>output_fn</code>.</p>"},{"location":"alff_api/#alff.al.lib_al_gpaw.post_dft_gpaw--parameters","title":"Parameters","text":"<p>iter_index : int     The index of the current iteration. jdata : dict     The parameter data.</p>"},{"location":"alff_api/#alff.al.lib_al_lammps","title":"<code>lib_al_lammps</code>","text":"<p>Functions:</p> <ul> <li> <code>pre_md_lammps_7net</code>             \u2013              </li> </ul>"},{"location":"alff_api/#alff.al.lib_al_lammps._get_lammps_arg_default","title":"<code>_get_lammps_arg_default(iter_idx, pdict)</code>","text":""},{"location":"alff_api/#alff.al.lib_al_lammps.pre_md_lammps_7net","title":"<code>pre_md_lammps_7net(iter_idx, pdict, mdict)</code>","text":""},{"location":"alff_api/#alff.al.lib_uncertainty","title":"<code>lib_uncertainty</code>","text":"<p>Functions:</p> <ul> <li> <code>committee_error_e</code>             \u2013              <p>Committee error for energy on a single configuration</p> </li> <li> <code>committee_error_f</code>             \u2013              <p>Committee error for forces on a single configuration</p> </li> <li> <code>committee_error_s</code>             \u2013              <p>Committee error for stress on a single configuration</p> </li> <li> <code>committee_error_SevenNet</code>             \u2013              <p>Committee error for energy, forces and stress on a list of configurations</p> </li> </ul>"},{"location":"alff_api/#alff.al.lib_uncertainty.committee_error_e","title":"<code>committee_error_e(atoms: Atoms, calc_list: list[object])</code>","text":"<p>Committee error for energy on a single configuration</p> <p>Parameters:</p> <ul> <li> <code>atoms</code>               (<code>Atoms</code>)           \u2013            <p>Atoms object</p> </li> <li> <code>calc_list</code>               (<code>list[object]</code>)           \u2013            <p>list of ASE's calculators of ML models in the committee.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>e_std</code> (              <code>float</code> )          \u2013            <p>standard deviation of the energy</p> </li> </ul>"},{"location":"alff_api/#alff.al.lib_uncertainty.committee_error_f","title":"<code>committee_error_f(atoms, calc_list: list[object], rel_force: float = None)</code>","text":"<p>Committee error for forces on a single configuration</p> <p>Parameters:</p> <ul> <li> <code>atoms</code>               (<code>Atoms</code>)           \u2013            <p>Atoms object</p> </li> <li> <code>calc_list</code>               (<code>list[object]</code>)           \u2013            <p>list of ASE's calculators of ML models in the committee.</p> </li> <li> <code>rel_force</code>               (<code>float</code>, default:                   <code>None</code> )           \u2013            <p>relative force. Defaults to None.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>f_std_mean</code> (              <code>float</code> )          \u2013            <p>mean of the standard deviation of atomic forces in the configuration</p> </li> <li> <code>f_std_max</code> (              <code>float</code> )          \u2013            <p>maximum of the standard deviation</p> </li> <li> <code>f_std_min</code> (              <code>float</code> )          \u2013            <p>minimum of the standard deviation</p> </li> </ul>"},{"location":"alff_api/#alff.al.lib_uncertainty.committee_error_s","title":"<code>committee_error_s(atoms: Atoms, calc_list: list[object], rel_stress: float = None)</code>","text":"<p>Committee error for stress on a single configuration</p> <p>Parameters:</p> <ul> <li> <code>atoms</code>               (<code>Atoms</code>)           \u2013            <p>Atoms object</p> </li> <li> <code>calc_list</code>               (<code>list[object]</code>)           \u2013            <p>list of ASE's calculators of ML models in the committee.</p> </li> <li> <code>rel_stress</code>               (<code>float</code>, default:                   <code>None</code> )           \u2013            <p>relative stress. Defaults to None.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>s_std_mean</code> (              <code>float</code> )          \u2013            <p>mean of the standard deviation of the stress in the configuration</p> </li> <li> <code>s_std_max</code> (              <code>float</code> )          \u2013            <p>maximum of the standard deviation</p> </li> <li> <code>s_std_min</code> (              <code>float</code> )          \u2013            <p>minimum of the standard deviation</p> </li> </ul>"},{"location":"alff_api/#alff.al.lib_uncertainty.committee_error_SevenNet","title":"<code>committee_error_SevenNet(extxyz_file: str, model_files: list, sevenn_args: dict = {}, rel_force: float = None, compute_stress: bool = True, rel_stress: float = None)</code>","text":"<p>Committee error for energy, forces and stress on a list of configurations</p> <p>Parameters:</p> <ul> <li> <code>extxyz_files</code>               (<code>list</code>)           \u2013            <p>list of extended xyz files</p> </li> <li> <code>model_files</code>               (<code>list</code>)           \u2013            <p>list of model files</p> </li> </ul> <p>Returns:</p> <ul> <li>           \u2013            <p>file \"committee_error.txt\" with the following columns:</p> </li> </ul>"},{"location":"alff_api/#alff.cli","title":"<code>cli</code>","text":"<p>Functions:</p> <ul> <li> <code>alff_al</code>             \u2013              <p>CLI for active learning</p> </li> <li> <code>alff_gen</code>             \u2013              <p>CLI for data generation</p> </li> <li> <code>alff_finetune</code>             \u2013              <p>CLI for fine-tuning</p> </li> <li> <code>alff_phonon</code>             \u2013              <p>CLI for phonon calculation</p> </li> <li> <code>alff_elastic</code>             \u2013              <p>CLI for elastic constants calculation</p> </li> <li> <code>convert_chgnet_to_xyz</code>             \u2013              <p>CLI for converting the MPCHGNet dataset to XYZ format</p> </li> <li> <code>get_args</code>             \u2013              <p>Get the arguments from the command line</p> </li> </ul> <p>Attributes:</p> <ul> <li> <code>LOGGER</code>           \u2013            </li> </ul>"},{"location":"alff_api/#alff.cli.LOGGER","title":"<code>LOGGER = create_logger('alff', level='INFO', log_file=FILE_LOG_ALFF)</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.cli.alff_al","title":"<code>alff_al()</code>","text":"<p>CLI for active learning</p>"},{"location":"alff_api/#alff.cli.alff_gen","title":"<code>alff_gen()</code>","text":"<p>CLI for data generation</p>"},{"location":"alff_api/#alff.cli.alff_finetune","title":"<code>alff_finetune()</code>","text":"<p>CLI for fine-tuning</p>"},{"location":"alff_api/#alff.cli.alff_phonon","title":"<code>alff_phonon()</code>","text":"<p>CLI for phonon calculation</p>"},{"location":"alff_api/#alff.cli.alff_elastic","title":"<code>alff_elastic()</code>","text":"<p>CLI for elastic constants calculation</p>"},{"location":"alff_api/#alff.cli.convert_chgnet_to_xyz","title":"<code>convert_chgnet_to_xyz()</code>","text":"<p>CLI for converting the MPCHGNet dataset to XYZ format</p>"},{"location":"alff_api/#alff.cli.get_args","title":"<code>get_args()</code>","text":"<p>Get the arguments from the command line</p>"},{"location":"alff_api/#alff.data","title":"<code>data</code>","text":"<p>Modules:</p> <ul> <li> <code>convert_mpchgnet_to_xyz</code>           \u2013            </li> <li> <code>gendata</code>           \u2013            </li> <li> <code>lib_dataset</code>           \u2013            </li> <li> <code>lib_gen_gpaw</code>           \u2013            <p>NOTE:</p> </li> </ul>"},{"location":"alff_api/#alff.data.convert_mpchgnet_to_xyz","title":"<code>convert_mpchgnet_to_xyz</code>","text":"<p>Functions:</p> <ul> <li> <code>chgnet_to_ase_atoms</code>             \u2013              </li> <li> <code>run_convert</code>             \u2013              </li> </ul> <p>Attributes:</p> <ul> <li> <code>info_keys</code>           \u2013            </li> </ul>"},{"location":"alff_api/#alff.data.convert_mpchgnet_to_xyz.info_keys","title":"<code>info_keys = ['uncorrected_total_energy', 'corrected_total_energy', 'energy_per_atom', 'ef_per_atom', 'e_per_atom_relaxed', 'ef_per_atom_relaxed', 'magmom', 'bandgap', 'mp_id']</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.data.convert_mpchgnet_to_xyz.chgnet_to_ase_atoms","title":"<code>chgnet_to_ase_atoms(datum: dict[str, dict[str, Any]]) -&gt; list[Atoms]</code>","text":""},{"location":"alff_api/#alff.data.convert_mpchgnet_to_xyz.run_convert","title":"<code>run_convert()</code>","text":""},{"location":"alff_api/#alff.data.gendata","title":"<code>gendata</code>","text":"<p>Functions:</p> <ul> <li> <code>build_structure</code>             \u2013              <p>Build structures based on input parameters</p> </li> <li> <code>optimize_structure</code>             \u2013              <p>Optimize the structures</p> </li> <li> <code>scale_perturb_structure</code>             \u2013              <p>Scale and perturb the structures</p> </li> <li> <code>copy_structure_files</code>             \u2013              <p>Copy structure files (both labeled or unlabeled) from source directory to destination directory, and rename to FILE_FRAME_unLABELED</p> </li> <li> <code>symlink_structure_files</code>             \u2013              <p>Symlink structure files (both labeled or unlabeled) from source directory to destination directory</p> </li> <li> <code>scale_x_dim</code>             \u2013              <p>Scale the x dimension of the structures</p> </li> <li> <code>scale_y_dim</code>             \u2013              <p>Scale the y dimension of the structures</p> </li> <li> <code>scale_z_dim</code>             \u2013              <p>Scale the z dimension of the structures</p> </li> <li> <code>perturb_structure</code>             \u2013              <p>Perturb the structures</p> </li> <li> <code>run_dft</code>             \u2013              <p>Run DFT calculations</p> </li> <li> <code>collect_data</code>             \u2013              <p>Collect data from DFT simulations</p> </li> <li> <code>data_generator</code>             \u2013              <p>Generate initial data for training ML models</p> </li> </ul>"},{"location":"alff_api/#alff.data.gendata.build_structure","title":"<code>build_structure(pdict, mdict)</code>","text":"<p>Build structures based on input parameters</p>"},{"location":"alff_api/#alff.data.gendata.optimize_structure","title":"<code>optimize_structure(pdict, mdict)</code>","text":"<p>Optimize the structures</p>"},{"location":"alff_api/#alff.data.gendata.scale_perturb_structure","title":"<code>scale_perturb_structure(pdict, mdict)</code>","text":"<p>Scale and perturb the structures</p>"},{"location":"alff_api/#alff.data.gendata.copy_structure_files","title":"<code>copy_structure_files(src_dir: str, dest_dir: str)</code>","text":"<p>Copy structure files (both labeled or unlabeled) from source directory to destination directory, and rename to FILE_FRAME_unLABELED</p>"},{"location":"alff_api/#alff.data.gendata.symlink_structure_files","title":"<code>symlink_structure_files(src_dir: str, dest_dir: str)</code>","text":"<p>Symlink structure files (both labeled or unlabeled) from source directory to destination directory</p>"},{"location":"alff_api/#alff.data.gendata.scale_x_dim","title":"<code>scale_x_dim(struct_files: list, scale_x_list: list)</code>","text":"<p>Scale the x dimension of the structures</p>"},{"location":"alff_api/#alff.data.gendata.scale_y_dim","title":"<code>scale_y_dim(struct_files: list, scale_y_list: list)</code>","text":"<p>Scale the y dimension of the structures</p>"},{"location":"alff_api/#alff.data.gendata.scale_z_dim","title":"<code>scale_z_dim(struct_files: list, scale_z_list: list)</code>","text":"<p>Scale the z dimension of the structures</p>"},{"location":"alff_api/#alff.data.gendata.perturb_structure","title":"<code>perturb_structure(struct_files: list, perturb_num: int, perturb_disp: float)</code>","text":"<p>Perturb the structures</p>"},{"location":"alff_api/#alff.data.gendata._total_conf_num","title":"<code>_total_conf_num(pdict: dict)</code>","text":""},{"location":"alff_api/#alff.data.gendata.run_dft","title":"<code>run_dft(pdict, mdict)</code>","text":"<p>Run DFT calculations</p>"},{"location":"alff_api/#alff.data.gendata.collect_data","title":"<code>collect_data(pdict, mdict)</code>","text":"<p>Collect data from DFT simulations</p>"},{"location":"alff_api/#alff.data.gendata.data_generator","title":"<code>data_generator(configfile_param: str, configfile_machine: str)</code>","text":"<p>Generate initial data for training ML models</p>"},{"location":"alff_api/#alff.data.lib_dataset","title":"<code>lib_dataset</code>","text":"<p>Functions:</p> <ul> <li> <code>split_ase_atoms</code>             \u2013              <p>Split a dataset into training, validation, and test sets.</p> </li> <li> <code>split_dataset_files</code>             \u2013              <p>Split a dataset into training, validation, and test sets.</p> </li> </ul>"},{"location":"alff_api/#alff.data.lib_dataset.split_ase_atoms","title":"<code>split_ase_atoms(data: list[Atoms], train_ratio: float = 0.9, valid_ratio: float = 0.1, test_ratio: float = 0, seed: int = None)</code>","text":"<p>Split a dataset into training, validation, and test sets.</p> <p>Parameters:</p> <ul> <li> <code>data</code>               (<code>list[Atoms]</code>)           \u2013            <p>List of ASE Atoms objects.</p> </li> <li> <code>train_ratio</code>               (<code>float</code>, default:                   <code>0.9</code> )           \u2013            <p>Ratio of training set. Defaults to 0.9.</p> </li> <li> <code>valid_ratio</code>               (<code>float</code>, default:                   <code>0.1</code> )           \u2013            <p>Ratio of validation set. Defaults to 0.1.</p> </li> <li> <code>test_ratio</code>               (<code>float</code>, default:                   <code>0</code> )           \u2013            <p>Ratio of test set. Defaults to 0.</p> </li> <li> <code>seed</code>               (<code>int</code>, default:                   <code>None</code> )           \u2013            <p>Seed number. If given, the produce set is unchanged, it means can be reproduced. Defaults to None.</p> </li> </ul>"},{"location":"alff_api/#alff.data.lib_dataset.split_dataset_files","title":"<code>split_dataset_files(extxyz_files: list[str], train_ratio: float = 0.9, valid_ratio: float = 0.1, test_ratio: float = 0, seed: int = None, outfile_prefix: str = 'dataset')</code>","text":"<p>Split a dataset into training, validation, and test sets.</p> <p>Parameters:</p> <ul> <li> <code>extxyz_files</code>               (<code>list[str]</code>)           \u2013            <p>List of file paths in EXTXYZ format.</p> </li> <li> <code>train_ratio</code>               (<code>float</code>, default:                   <code>0.9</code> )           \u2013            <p>Ratio of training set. Defaults to 0.9.</p> </li> <li> <code>valid_ratio</code>               (<code>float</code>, default:                   <code>0.1</code> )           \u2013            <p>Ratio of validation set. Defaults to 0.1.</p> </li> <li> <code>test_ratio</code>               (<code>float</code>, default:                   <code>0</code> )           \u2013            <p>Ratio of test set. Defaults to 0.</p> </li> <li> <code>seed</code>               (<code>int</code>, default:                   <code>None</code> )           \u2013            <p>Random seed. Defaults to None.</p> </li> </ul>"},{"location":"alff_api/#alff.data.lib_gen_gpaw","title":"<code>lib_gen_gpaw</code>","text":"<p>NOTE: - do not use <code>return</code> in the functions that run <code>dpdispatcher.submission()</code>. - work_path is a folder relative to the run_path - task_paths is folders relative to the work_path</p> <p>Functions:</p> <ul> <li> <code>pregen_gpaw_optimize</code>             \u2013              <p>This function does:</p> </li> <li> <code>rungen_gpaw_optimize</code>             \u2013              <p>This function does:</p> </li> <li> <code>postgen_gpaw_optimize</code>             \u2013              <p>This function does:</p> </li> <li> <code>pregen_gpaw_singlepoint</code>             \u2013              <p>Refer to the <code>pregen_gpaw_optimize()</code> function.</p> </li> <li> <code>rungen_gpaw_singlepoint</code>             \u2013              <p>Refer to the <code>rungen_gpaw_optimize()</code> function.</p> </li> <li> <code>postgen_gpaw_singlepoint</code>             \u2013              <p>Refer to the <code>postgen_gpaw_optimize()</code> function.</p> </li> <li> <code>pregen_gpaw_aimd</code>             \u2013              <p>Refer to the <code>pregen_gpaw_optimize()</code> function.</p> </li> <li> <code>rungen_gpaw_aimd</code>             \u2013              <p>Refer to the <code>rungen_gpaw_optimize()</code> function.</p> </li> <li> <code>postgen_gpaw_aimd</code>             \u2013              <p>Refer to the <code>postgen_gpaw_optimize()</code> function.</p> </li> <li> <code>check_gpaw_input</code>             \u2013              <p>Check the input files for the GPAW calculation, to ensure some necessary fields are set.</p> </li> <li> <code>sort_dft_task_paths</code>             \u2013              <p>Sort the structure paths by its supercell size.</p> </li> </ul>"},{"location":"alff_api/#alff.data.lib_gen_gpaw.pregen_gpaw_optimize","title":"<code>pregen_gpaw_optimize(work_path, pdict)</code>","text":"<p>This function does: - Prepare task_paths: select only unlabeled structures to compute at clusters. - Prepare gpaw_dft and gpaw_run_file</p>"},{"location":"alff_api/#alff.data.lib_gen_gpaw.rungen_gpaw_optimize","title":"<code>rungen_gpaw_optimize(work_path, pdict, mdict)</code>","text":"<p>This function does: - Read task_paths from .yaml file     - Prepare the task_list     - Prepare fordward &amp; backward files     - Prepare command_list - Submit jobs to the cluster - Download the results when finished</p>"},{"location":"alff_api/#alff.data.lib_gen_gpaw.postgen_gpaw_optimize","title":"<code>postgen_gpaw_optimize(work_path, pdict)</code>","text":"<p>This function does: - Remove unlabeled .extxyz files, just keep the labeled ones.</p>"},{"location":"alff_api/#alff.data.lib_gen_gpaw.pregen_gpaw_singlepoint","title":"<code>pregen_gpaw_singlepoint(work_path, pdict)</code>","text":"<p>Refer to the <code>pregen_gpaw_optimize()</code> function.</p>"},{"location":"alff_api/#alff.data.lib_gen_gpaw.rungen_gpaw_singlepoint","title":"<code>rungen_gpaw_singlepoint(work_path, pdict, mdict)</code>","text":"<p>Refer to the <code>rungen_gpaw_optimize()</code> function.</p>"},{"location":"alff_api/#alff.data.lib_gen_gpaw.postgen_gpaw_singlepoint","title":"<code>postgen_gpaw_singlepoint(work_path, pdict)</code>","text":"<p>Refer to the <code>postgen_gpaw_optimize()</code> function.</p>"},{"location":"alff_api/#alff.data.lib_gen_gpaw.pregen_gpaw_aimd","title":"<code>pregen_gpaw_aimd(work_path, pdict)</code>","text":"<p>Refer to the <code>pregen_gpaw_optimize()</code> function.</p>"},{"location":"alff_api/#alff.data.lib_gen_gpaw.rungen_gpaw_aimd","title":"<code>rungen_gpaw_aimd(work_path, pdict, mdict)</code>","text":"<p>Refer to the <code>rungen_gpaw_optimize()</code> function.</p>"},{"location":"alff_api/#alff.data.lib_gen_gpaw.postgen_gpaw_aimd","title":"<code>postgen_gpaw_aimd(work_path, pdict)</code>","text":"<p>Refer to the <code>postgen_gpaw_optimize()</code> function.</p>"},{"location":"alff_api/#alff.data.lib_gen_gpaw.check_gpaw_input","title":"<code>check_gpaw_input(input_file: str) -&gt; None</code>","text":"<p>Check the input files for the GPAW calculation, to ensure some necessary fields are set.</p>"},{"location":"alff_api/#alff.data.lib_gen_gpaw.sort_dft_task_paths","title":"<code>sort_dft_task_paths(task_paths: list, work_path: str) -&gt; list</code>","text":"<p>Sort the structure paths by its supercell size. This helps to chunk the tasks with similar supercell size together (similar supercell size means similar k-point number), which then lead to running DFT calculations in similar time, avoiding the situation that some tasks are finished while others are still running.</p>"},{"location":"alff_api/#alff.elastic","title":"<code>elastic</code>","text":"<p>Modules:</p> <ul> <li> <code>elastic</code>           \u2013            </li> <li> <code>lib_elas_lammps</code>           \u2013            </li> <li> <code>lib_elastic</code>           \u2013            </li> <li> <code>lib_elate</code>           \u2013            </li> </ul>"},{"location":"alff_api/#alff.elastic.elastic","title":"<code>elastic</code>","text":"<p>Functions:</p> <ul> <li> <code>relax_initial_structure</code>             \u2013              <p>Relax the structure by DFT/MD</p> </li> <li> <code>scale_and_relax</code>             \u2013              <p>Scale and relax the structures while fixing box size. Use when want to compute phonon at different volumes.</p> </li> <li> <code>compute_stress_strain</code>             \u2013              <p>Compute stress and strain tensors for each scale-relaxed-structure by DFT/MD.</p> </li> <li> <code>compute_stress_single_structure</code>             \u2013              <p>The function does the following:</p> </li> <li> <code>compute_elastic_tensor_single_structure</code>             \u2013              <p>Compute elastic tensor for a single structure.</p> </li> <li> <code>compute_elastic</code>             \u2013              <p>Compute elastic constants from stress-strain tensors.</p> </li> <li> <code>elastic_calc</code>             \u2013              <p>Generate initial data for training ML models</p> </li> </ul>"},{"location":"alff_api/#alff.elastic.elastic.relax_initial_structure","title":"<code>relax_initial_structure(pdict, mdict)</code>","text":"<p>Relax the structure by DFT/MD</p>"},{"location":"alff_api/#alff.elastic.elastic.scale_and_relax","title":"<code>scale_and_relax(pdict, mdict)</code>","text":"<p>Scale and relax the structures while fixing box size. Use when want to compute phonon at different volumes.</p>"},{"location":"alff_api/#alff.elastic.elastic.compute_stress_strain","title":"<code>compute_stress_strain(pdict: dict, mdict: dict)</code>","text":"<p>Compute stress and strain tensors for each scale-relaxed-structure by DFT/MD.</p>"},{"location":"alff_api/#alff.elastic.elastic.compute_stress_single_structure","title":"<code>compute_stress_single_structure(work_path, pdict, mdict)</code>","text":"<p>The function does the following: - generate supercells with small deformation and compute corresponding strain tensor - run DFT/MD minimize calculation to compute stress tensor for each suppercell. - collect stress and strain tensor for each supercell</p>"},{"location":"alff_api/#alff.elastic.elastic.compute_elastic_tensor_single_structure","title":"<code>compute_elastic_tensor_single_structure(work_path, pdict: dict, mdict: dict)</code>","text":"<p>Compute elastic tensor for a single structure. - Collect stress and strain tensors from calculations on deformed structures. - Compute elastic constants by fitting stress-strain relations.</p>"},{"location":"alff_api/#alff.elastic.elastic.compute_elastic","title":"<code>compute_elastic(pdict: dict, mdict: dict)</code>","text":"<p>Compute elastic constants from stress-strain tensors.</p>"},{"location":"alff_api/#alff.elastic.elastic.elastic_calc","title":"<code>elastic_calc(configfile_param: str, configfile_machine: str)</code>","text":"<p>Generate initial data for training ML models</p>"},{"location":"alff_api/#alff.elastic.lib_elas_lammps","title":"<code>lib_elas_lammps</code>","text":"<p>Functions:</p> <ul> <li> <code>postelast_lammps_optimize</code>             \u2013              <p>This function does:</p> </li> <li> <code>postelast_lammps_singlepoint</code>             \u2013              <p>This function does:</p> </li> </ul>"},{"location":"alff_api/#alff.elastic.lib_elas_lammps.postelast_lammps_optimize","title":"<code>postelast_lammps_optimize(work_path, pdict)</code>","text":"<p>This function does: - Remove unlabeled .extxyz files, just keep the labeled ones. - Convert LAMMPS output to extxyz_labeled.</p>"},{"location":"alff_api/#alff.elastic.lib_elas_lammps.postelast_lammps_singlepoint","title":"<code>postelast_lammps_singlepoint(work_path, pdict)</code>","text":"<p>This function does: - Clean up unlabelled extxyz files - Collect forces from the output files</p>"},{"location":"alff_api/#alff.elastic.lib_elastic","title":"<code>lib_elastic</code>","text":"<p>Classes:</p> <ul> <li> <code>Elasticity</code>           \u2013            <p>Main class to compute the elastic stiffness tensor of the crystal.</p> </li> <li> <code>ElasticConstant</code>           \u2013            <p>Class to manage elastic constants and compute elastic properties.</p> </li> </ul> <p>Functions:</p> <ul> <li> <code>func_MEOS</code>             \u2013              <p>Murnaghan equation of state: https://en.wikipedia.org/wiki/Murnaghan_equation_of_state</p> </li> <li> <code>func_BMEOS</code>             \u2013              <p>Birch-Murnaghan equation of state: https://en.wikipedia.org/wiki/Birch-Murnaghan_equation_of_state</p> </li> <li> <code>get_lattice_type</code>             \u2013              <p>Identify the lattice type and the Bravais lattice of the crystal.</p> </li> <li> <code>generate_elementary_deformations</code>             \u2013              <p>Generate deformed structures with 'elementary deformations' for elastic tensor calculation.</p> </li> <li> <code>deform_1axis</code>             \u2013              <p>Return the deformed structure along one of the cartesian directions.</p> </li> <li> <code>strain_voigt_to_symmetry_matrix</code>             \u2013              <p>Return the strain matrix to be used in stress-strain equation, to compute elastic tensor.</p> </li> <li> <code>get_cij_list</code>             \u2013              <p>Return the order of elastic constants for the structure</p> </li> <li> <code>get_cij_6x6matrix</code>             \u2013              <p>Return the Cij matrix for the structure based on the symmetry of the crystal.</p> </li> <li> <code>get_voigt_strain_vector</code>             \u2013              <p>Calculate the strain tensor between the deformed structure and the reference structure.</p> </li> </ul>"},{"location":"alff_api/#alff.elastic.lib_elastic.Elasticity","title":"<code>Elasticity(ref_cryst: Atoms, symprec: float = 1e-05)</code>","text":"<p>               Bases: <code>object</code></p> <p>Main class to compute the elastic stiffness tensor of the crystal. Steps to compute the elastic tensor:     - Initialize the class with the reference structure.     - Generate deformed structures with 'elementary deformations'     - Compute stress for each deformed structure by DFT/MD.     - Input the deformed structures with stress tensors to the method <code>fit_elastic_tensor</code></p> <p>Parameters:</p> <ul> <li> <code>ref_cryst</code>               (<code>Atoms</code>)           \u2013            <p>ASE Atoms object, reference structure (relaxed/optimized structure)</p> </li> <li> <code>symprec</code>               (<code>float</code>, default:                   <code>1e-05</code> )           \u2013            <p>symmetry precision to check the symmetry of the crystal</p> </li> </ul> <p>Methods:</p> <ul> <li> <code>generate_deformations</code>             \u2013              <p>Generate deformed structures with 'elementary deformations' for elastic tensor calculation.</p> </li> <li> <code>fit_elastic_tensor</code>             \u2013              <p>Calculate elastic tensor from the stress-strain relation by fitting this relation to the set of linear equations, strains and stresses.</p> </li> <li> <code>get_pressure</code>             \u2013              <p>Return external isotropic (hydrostatic) pressure in ASE units.</p> </li> <li> <code>write_cij</code>             \u2013              <p>Write the elastic constants to a text file.</p> </li> <li> <code>fit_BM_EOS</code>             \u2013              <p>Calculate Birch-Murnaghan Equation of State for the crystal.</p> </li> <li> <code>get_bulk_modulus</code>             \u2013              <p>Calculate bulk modulus using the Birch-Murnaghan equation of state.</p> </li> <li> <code>write_MB_EOS</code>             \u2013              <p>Write the Birch-Murnaghan EOS parameters to a text file.</p> </li> <li> <code>write_MB_EOS_pv_data</code>             \u2013              <p>Write the volume-pressure data to a text file.</p> </li> </ul> <p>Attributes:</p> <ul> <li> <code>ref_cryst</code>           \u2013            </li> <li> <code>symprec</code>           \u2013            </li> <li> <code>bravais</code>           \u2013            </li> <li> <code>strain_list</code>           \u2013            </li> <li> <code>stress_list</code>           \u2013            </li> <li> <code>pressure</code>           \u2013            </li> <li> <code>Cij</code>           \u2013            </li> </ul>"},{"location":"alff_api/#alff.elastic.lib_elastic.Elasticity.ref_cryst","title":"<code>ref_cryst = ref_cryst</code>  <code>instance-attribute</code>","text":""},{"location":"alff_api/#alff.elastic.lib_elastic.Elasticity.symprec","title":"<code>symprec = symprec</code>  <code>instance-attribute</code>","text":""},{"location":"alff_api/#alff.elastic.lib_elastic.Elasticity.bravais","title":"<code>bravais = get_lattice_type(self.ref_cryst, self.symprec)[0]</code>  <code>instance-attribute</code>","text":""},{"location":"alff_api/#alff.elastic.lib_elastic.Elasticity.strain_list","title":"<code>strain_list = None</code>  <code>instance-attribute</code>","text":""},{"location":"alff_api/#alff.elastic.lib_elastic.Elasticity.stress_list","title":"<code>stress_list = None</code>  <code>instance-attribute</code>","text":""},{"location":"alff_api/#alff.elastic.lib_elastic.Elasticity.pressure","title":"<code>pressure = None</code>  <code>instance-attribute</code>","text":""},{"location":"alff_api/#alff.elastic.lib_elastic.Elasticity.Cij","title":"<code>Cij = None</code>  <code>instance-attribute</code>","text":""},{"location":"alff_api/#alff.elastic.lib_elastic.Elasticity.generate_deformations","title":"<code>generate_deformations(delta: float = 0.01, n: int = 5)</code>","text":"<p>Generate deformed structures with 'elementary deformations' for elastic tensor calculation. The deformations are created based on the symmetry of the crystal.</p> <p>Parameters:</p> <ul> <li> <code>delta</code>               (<code>float</code>, default:                   <code>0.01</code> )           \u2013            <p>the <code>maximum magnitude</code> of deformation in Angstrom and degrees.</p> </li> <li> <code>n</code>               (<code>int</code>, default:                   <code>5</code> )           \u2013            <p>number of deformations on each non-equivalent axis (number of deformations in each direction)</p> </li> </ul> <p>Returns:</p> <ul> <li>           \u2013            <p>list[Atoms]: list of deformed structures. Number of structures = (n * number_of_axes). These structures are then used in MD/DFT to compute the stress tensor.</p> </li> </ul>"},{"location":"alff_api/#alff.elastic.lib_elastic.Elasticity.fit_elastic_tensor","title":"<code>fit_elastic_tensor(deform_crysts: list[Atoms]) -&gt; tuple[np.array, np.array]</code>","text":"<p>Calculate elastic tensor from the stress-strain relation by fitting this relation to the set of linear equations, strains and stresses. The number of linear equations is computed depends on the symmetry of the crystal.</p> <p>It is assumed that the crystal is converged (relaxed/optimized) under intended pressure/stress. The geometry and stress on this crystal is taken as the reference point. No additional optimization will be run. Then, the strain and stress tensor is computed for each of the deformed structures (exactly, the stress difference from the reference point).</p> <p>This function returns tuple of Cij elastic tensor, and the fitting results returned by <code>numpy.linalg.lstsq</code>: Birch coefficients, residuals, solution rank, singular values.</p> <p>Parameters:</p> <ul> <li> <code>deform_crysts</code>               (<code>list[Atoms]</code>)           \u2013            <p>list of Atoms objects with calculated deformed structures</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>tuple</code> (              <code>tuple[array, array]</code> )          \u2013            <p>tuple of Cij elastic tensor and fitting results. - Cij: in vector form of Voigt notation. - Bij: float vector, residuals, solution rank, singular values</p> </li> </ul>"},{"location":"alff_api/#alff.elastic.lib_elastic.Elasticity.get_pressure","title":"<code>get_pressure(stress) -&gt; float</code>","text":"<p>Return external isotropic (hydrostatic) pressure in ASE units. If the pressure is positive the system is under external pressure. This is a convenience function to convert output of get_stress function into external pressure.</p> <p>Parameters:</p> <ul> <li> <code>stress(np.array</code>           \u2013            <p>stress tensor in Voight (vector) notation as returned by the <code>.get_stress()</code> method.</p> </li> </ul> Return <p>float: external hydrostatic pressure in ASE units.</p>"},{"location":"alff_api/#alff.elastic.lib_elastic.Elasticity.write_cij","title":"<code>write_cij(filename: str = 'cij.txt')</code>","text":"<p>Write the elastic constants to a text file.</p> <p>Parameters:</p> <ul> <li> <code>filename</code>               (<code>str</code>, default:                   <code>'cij.txt'</code> )           \u2013            <p>output file name</p> </li> </ul>"},{"location":"alff_api/#alff.elastic.lib_elastic.Elasticity.fit_BM_EOS","title":"<code>fit_BM_EOS(deform_crysts: list[Atoms])</code>","text":"<p>Calculate Birch-Murnaghan Equation of State for the crystal.</p> \\[ P(V) = \\frac{B_0}{B'_0}\\left[\\left({\\frac{V}{V_0}}\\right)^{-B'_0} - 1\\right] \\] <p>It's coefficients are estimated using n single-point structures ganerated from the crystal (cryst) by the scan_volumes function between two relative volumes. The BM EOS is fitted to the computed points by least squares method.</p> <p>Parameters:</p> <ul> <li> <code>cryst</code>               (<code>Atoms</code>)           \u2013            <p>Atoms object, reference structure (relaxed/optimized structure)</p> </li> <li> <code>deform_crysts</code>               (<code>list[Atoms]</code>)           \u2013            <p>list of Atoms objects with calculated deformed structures</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>tuple</code>          \u2013            <p>tuple of EOS parameters ([V0, B0, B0p], pv data)'.</p> </li> </ul>"},{"location":"alff_api/#alff.elastic.lib_elastic.Elasticity.get_bulk_modulus","title":"<code>get_bulk_modulus(deform_crysts: list[Atoms])</code>","text":"<p>Calculate bulk modulus using the Birch-Murnaghan equation of state. The bulk modulus is the <code>B_0</code> coefficient of the B-M EOS. The units of the result are defined by ASE. To get the result in any particular units (e.g. GPa) you need to divide it by ase.units.:: <pre><code>get_bulk_modulus(cryst)/ase.units.GPa\n</code></pre> <p>Parameters:</p> <ul> <li> <code>cryst</code>               (<code>Atoms</code>)           \u2013            <p>Atoms object, reference structure (relaxed/optimized structure)</p> </li> <li> <code>deform_crysts</code>               (<code>list[Atoms]</code>)           \u2013            <p>list of Atoms objects with calculated deformed structures</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>float</code>          \u2013            <p>bulk modulus <code>B_0</code> in ASE units.</p> </li> </ul>"},{"location":"alff_api/#alff.elastic.lib_elastic.Elasticity.write_MB_EOS","title":"<code>write_MB_EOS(filename: str = 'BMeos.txt')</code>","text":"<p>Write the Birch-Murnaghan EOS parameters to a text file.</p> <p>Parameters:</p> <ul> <li> <code>filename</code>               (<code>str</code>, default:                   <code>'BMeos.txt'</code> )           \u2013            <p>output file name</p> </li> </ul>"},{"location":"alff_api/#alff.elastic.lib_elastic.Elasticity.write_MB_EOS_pv_data","title":"<code>write_MB_EOS_pv_data(filename: str = 'BMeos_pv_data.txt')</code>","text":"<p>Write the volume-pressure data to a text file.</p> <p>Parameters:</p> <ul> <li> <code>filename</code>               (<code>str</code>, default:                   <code>'BMeos_pv_data.txt'</code> )           \u2013            <p>output file name</p> </li> </ul>"},{"location":"alff_api/#alff.elastic.lib_elastic.ElasticConstant","title":"<code>ElasticConstant(cij_mat: np.array = None, cij_dict: dict = None, bravais_lattice: str = 'Cubic')</code>","text":"<p>               Bases: <code>object</code></p> <p>Class to manage elastic constants and compute elastic properties.</p> <p>Parameters:</p> <ul> <li> <code>Cij</code>               (<code>array</code>)           \u2013            <p>(6, 6) array of Voigt representation of elastic stiffness.</p> </li> <li> <code>bravais_lattice</code>               (<code>str</code>, default:                   <code>'Cubic'</code> )           \u2013            <p>Bravais lattice name of the crystal.</p> </li> <li> <code>**kwargs</code>           \u2013            <p>dictionary of elastic constants <code>Cij</code>. Where C11, C12, ... C66 : float,</p> </li> </ul> <p>Methods:</p> <ul> <li> <code>Cij</code>             \u2013              <p>The elastic stiffness constants in Voigt 6x6 format</p> </li> <li> <code>Sij</code>             \u2013              <p>The compliance constants in Voigt 6x6 format</p> </li> <li> <code>bulk</code>             \u2013              <p>Returns a bulk modulus estimate.</p> </li> <li> <code>shear</code>             \u2013              <p>Returns a shear modulus estimate.</p> </li> </ul> <p>Attributes:</p> <ul> <li> <code>bravais</code>           \u2013            </li> </ul>"},{"location":"alff_api/#alff.elastic.lib_elastic.ElasticConstant.bravais","title":"<code>bravais = bravais_lattice</code>  <code>instance-attribute</code>","text":""},{"location":"alff_api/#alff.elastic.lib_elastic.ElasticConstant.Cij","title":"<code>Cij() -&gt; np.ndarray</code>","text":"<p>The elastic stiffness constants in Voigt 6x6 format</p>"},{"location":"alff_api/#alff.elastic.lib_elastic.ElasticConstant.Sij","title":"<code>Sij() -&gt; np.ndarray</code>","text":"<p>The compliance constants in Voigt 6x6 format</p>"},{"location":"alff_api/#alff.elastic.lib_elastic.ElasticConstant.bulk","title":"<code>bulk(style: str = 'Hill') -&gt; float</code>","text":"<p>Returns a bulk modulus estimate.</p> <p>Parameters:</p> <ul> <li> <code>style(str)</code>           \u2013            <p>style of bulk modulus. Default value is 'Hill'. - 'Voigt': Voigt estimate. Uses Cij. - 'Reuss': Reuss estimate. Uses Sij. - 'Hill': Hill estimate (average of Voigt and Reuss).</p> </li> </ul>"},{"location":"alff_api/#alff.elastic.lib_elastic.ElasticConstant.shear","title":"<code>shear(style: str = 'Hill') -&gt; float</code>","text":"<p>Returns a shear modulus estimate.</p> <p>Parameters:</p> <ul> <li> <code>style(str)</code>           \u2013            <p>style of bulk modulus. Default value is 'Hill'. - 'Voigt': Voigt estimate. Uses Cij. - 'Reuss': Reuss estimate. Uses Sij. - 'Hill': Hill estimate (average of Voigt and Reuss).</p> </li> </ul>"},{"location":"alff_api/#alff.elastic.lib_elastic.func_MEOS","title":"<code>func_MEOS(v, v0, b0, b0p)</code>","text":"<p>Murnaghan equation of state: https://en.wikipedia.org/wiki/Murnaghan_equation_of_state</p>"},{"location":"alff_api/#alff.elastic.lib_elastic.func_BMEOS","title":"<code>func_BMEOS(v, v0, b0, b0p)</code>","text":"<p>Birch-Murnaghan equation of state: https://en.wikipedia.org/wiki/Birch-Murnaghan_equation_of_state</p>"},{"location":"alff_api/#alff.elastic.lib_elastic.get_lattice_type","title":"<code>get_lattice_type(cryst: Atoms, symprec=1e-05) -&gt; tuple[int, str, str, int]</code>","text":"<p>Identify the lattice type and the Bravais lattice of the crystal. The lattice type numbers are (numbering starts from 1): Triclinic (1), Monoclinic (2), Orthorhombic (3), Tetragonal (4), Trigonal (5), Hexagonal (6), Cubic (7)</p> <p>Parameters:</p> <ul> <li> <code>cryst</code>               (<code>Atoms</code>)           \u2013            <p>ASE Atoms object</p> </li> <li> <code>symprec</code>               (<code>float</code>, default:                   <code>1e-05</code> )           \u2013            <p>symmetry precision to check the symmetry of the crystal</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>tuple</code> (              <code>tuple[int, str, str, int]</code> )          \u2013            <p>Bravais name, lattice type number (1-7), space-group name, space-group number</p> </li> </ul>"},{"location":"alff_api/#alff.elastic.lib_elastic.generate_elementary_deformations","title":"<code>generate_elementary_deformations(cryst: Atoms, delta: float = 0.01, n: int = 5, bravais_lattice: str = 'Cubic') -&gt; list[Atoms]</code>","text":"<p>Generate deformed structures with 'elementary deformations' for elastic tensor calculation. The deformations are created based on the symmetry of the crystal and are limited to the non-equivalent axes of the crystal.</p> <p>Parameters:</p> <ul> <li> <code>cryst</code>               (<code>Atoms</code>)           \u2013            <p>Atoms object, reference structure (relaxed/optimized structure)</p> </li> <li> <code>delta</code>               (<code>float</code>, default:                   <code>0.01</code> )           \u2013            <p>the <code>maximum magnitude</code> of deformation in Angstrom and degrees.</p> </li> <li> <code>n</code>               (<code>int</code>, default:                   <code>5</code> )           \u2013            <p>number of deformations on each non-equivalent axis (number of deformations in each direction)</p> </li> <li> <code>symprec</code>               (<code>float</code>)           \u2013            <p>symmetry precision to check the symmetry of the crystal</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>list[Atoms]</code>           \u2013            <p>list[Atoms] list of deformed structures. Number of structures = (n * number_of_axes)</p> </li> </ul>"},{"location":"alff_api/#alff.elastic.lib_elastic.deform_1axis","title":"<code>deform_1axis(cryst: Atoms, axis: int = 0, delta: float = 0.01) -&gt; Atoms</code>","text":"<p>Return the deformed structure along one of the cartesian directions. The axis is specified as follows:</p> <pre><code>- tetragonal deformation: 0,1,2 = x,y,z.\n- shear deformation: 3,4,5 = yz, xz, xy.\n</code></pre> <p>Parameters:</p> <ul> <li> <code>cryst</code>               (<code>Atoms</code>)           \u2013            <p>reference structure (structure to be deformed)</p> </li> <li> <code>axis</code>               (<code>int</code>, default:                   <code>0</code> )           \u2013            <p>direction of deformation. 0,1,2 = x,y,z; 3,4,5 = yz, xz, xy.</p> </li> <li> <code>delta</code>               (<code>float</code>, default:                   <code>0.01</code> )           \u2013            <p>magnitude of the deformation. Angstrom and degrees.</p> </li> </ul> Return <p>ase.Atoms: deformed structure</p>"},{"location":"alff_api/#alff.elastic.lib_elastic.strain_voigt_to_symmetry_matrix","title":"<code>strain_voigt_to_symmetry_matrix(u: list, bravais_lattice: str = 'Cubic') -&gt; np.array</code>","text":"<p>Return the strain matrix to be used in stress-strain equation, to compute elastic tensor. The number of Cij constants depends on the symmetry of the crystal. This strain matrix is computed based on the symmetry to reduce the necessary number of equations to be used in the fitting procedure (also reduce the necessary calculations). Refer Landau's textbook for the details.</p> <pre><code>- Triclinic: C11, C22, C33, C12, C13, C23, C44, C55, C66, C16, C26, C36, C46, C56, C14, C15, C25, C45\n- Monoclinic: C11, C22, C33, C12, C13, C23, C44, C55, C66, C16, C26, C36, C45\n- Orthorhombic: C11, C22, C33, C12, C13, C23, C44, C55, C66\n- Tetragonal: C11, C33, C12, C13, C44, C66\n- Trigonal: C11, C33, C12, C13, C44, C14\n- Hexagonal: C11, C33, C12, C13, C44\n- Cubic: C11, C12, C44\n</code></pre> <p>Parameters:</p> <ul> <li> <code>u</code>               (<code>list</code>)           \u2013            <p>vector of strain in Voigt notation [ u_xx, u_yy, u_zz, u_yz, u_xz, u_xy ]</p> </li> <li> <code>bravais_lattice</code>               (<code>str</code>, default:                   <code>'Cubic'</code> )           \u2013            <p>Bravais lattice name of the lattice</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>array</code>           \u2013            <p>np.array: Symmetry defined stress-strain equation matrix</p> </li> </ul>"},{"location":"alff_api/#alff.elastic.lib_elastic.get_cij_list","title":"<code>get_cij_list(bravais_lattice: str = 'Cubic') -&gt; list[str]</code>","text":"<p>Return the order of elastic constants for the structure</p> <p>Parameters:</p> <ul> <li> <code>bravais_lattice</code>               (<code>str</code>, default:                   <code>'Cubic'</code> )           \u2013            <p>Bravais lattice name of the lattice</p> </li> </ul> Return <p>list: list of strings <code>C_ij</code> the order of elastic constants</p>"},{"location":"alff_api/#alff.elastic.lib_elastic.get_cij_6x6matrix","title":"<code>get_cij_6x6matrix(cij_dict: dict[float], bravais_lattice: str = 'Cubic') -&gt; np.array</code>","text":"<p>Return the Cij matrix for the structure based on the symmetry of the crystal.</p> <p>Parameters:</p> <ul> <li> <code>cij_dict</code>               (<code>dict</code>)           \u2013            <p>dictionary of elastic constants <code>Cij</code>. Where C11, C12, ... C66 : float, Individual components of Cij for a standardized representation:</p> <ul> <li>Triclinic: all Cij where i &lt;= j</li> <li>Monoclinic: C11, C12, C13, C15, C22, C23, C25, C33, C35, C44, C46, C55, C66</li> <li>Orthorhombic: C11, C12, C13, C22, C23, C33, C44, C55, C66</li> <li>Tetragonal: C11, C12, C13, C16, C33, C44, C66 (C16 optional)</li> <li>Trigonal: C11, C12, C13, C14, C33, C44</li> <li>Hexagonal: C11, C12, C13, C33, C44, C66 (2*C66=C11-C12)</li> <li>Cubic: C11, C12, C44</li> <li>Isotropic: C11, C12, C44 (2*C44=C11-C12)</li> </ul> </li> <li> <code>bravais_lattice</code>               (<code>str</code>, default:                   <code>'Cubic'</code> )           \u2013            <p>Bravais lattice name of the lattice</p> </li> </ul>"},{"location":"alff_api/#alff.elastic.lib_elastic.get_voigt_strain_vector","title":"<code>get_voigt_strain_vector(cryst: Atoms, ref_cryst: Atoms = None) -&gt; np.array</code>","text":"<p>Calculate the strain tensor between the deformed structure and the reference structure. Return strain in vector form of Voigt notation, component order: u_{xx}, u_{yy}, u_{zz}, u_{yz}, u_{xz}, u_{xy}.</p> <p>Parameters:</p> <ul> <li> <code>cryst</code>               (<code>Atoms</code>)           \u2013            <p>deformed structure</p> </li> <li> <code>ref_cryst</code>               (<code>Atoms</code>, default:                   <code>None</code> )           \u2013            <p>reference, undeformed structure</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>array</code>           \u2013            <p>np.array: vector of strain in Voigt notation.</p> </li> </ul>"},{"location":"alff_api/#alff.elastic.lib_elate","title":"<code>lib_elate</code>","text":""},{"location":"alff_api/#alff.phonon","title":"<code>phonon</code>","text":"<p>Modules:</p> <ul> <li> <code>lib_pho_gpaw</code>           \u2013            </li> <li> <code>lib_pho_lammps</code>           \u2013            </li> <li> <code>lib_phonopy</code>           \u2013            </li> <li> <code>phonon</code>           \u2013            </li> </ul>"},{"location":"alff_api/#alff.phonon.lib_pho_gpaw","title":"<code>lib_pho_gpaw</code>","text":"<p>Functions:</p> <ul> <li> <code>prepho_gpaw_optimize_fixbox</code>             \u2013              <p>Refer to the <code>pregen_gpaw_optimize()</code> function.</p> </li> <li> <code>postpho_gpaw_singlepoint</code>             \u2013              <p>This function does:</p> </li> </ul>"},{"location":"alff_api/#alff.phonon.lib_pho_gpaw.prepho_gpaw_optimize_fixbox","title":"<code>prepho_gpaw_optimize_fixbox(work_path, pdict)</code>","text":"<p>Refer to the <code>pregen_gpaw_optimize()</code> function. Only change <code>gpaw_dft</code> for fixed cell optimization.</p>"},{"location":"alff_api/#alff.phonon.lib_pho_gpaw.postpho_gpaw_singlepoint","title":"<code>postpho_gpaw_singlepoint(work_path, pdict)</code>","text":"<p>This function does: - Clean up unlabelled extxyz files - Collect forces from the output files</p>"},{"location":"alff_api/#alff.phonon.lib_pho_lammps","title":"<code>lib_pho_lammps</code>","text":"<p>Functions:</p> <ul> <li> <code>prepho_lammps_optimize</code>             \u2013              <p>This function does:</p> </li> <li> <code>runpho_lammps_optimize</code>             \u2013              <p>This function does:</p> </li> <li> <code>postpho_lammps_optimize</code>             \u2013              <p>This function does:</p> </li> <li> <code>prepho_lammps_optimize_fixbox</code>             \u2013              <p>This function does:</p> </li> <li> <code>prepho_lammps_singlepoint</code>             \u2013              <p>This function does:</p> </li> <li> <code>postpho_lammps_singlepoint</code>             \u2013              <p>This function does:</p> </li> </ul>"},{"location":"alff_api/#alff.phonon.lib_pho_lammps.prepho_lammps_optimize","title":"<code>prepho_lammps_optimize(work_path, pdict)</code>","text":"<p>This function does: - Prepare task_paths: select only unlabeled structures to compute at clusters. - Prepare lammps_optimize and lammps_input files.     - Convert extxyz to lmpdata.     - Copy potential file to work_path.</p>"},{"location":"alff_api/#alff.phonon.lib_pho_lammps.runpho_lammps_optimize","title":"<code>runpho_lammps_optimize(work_path, pdict, mdict)</code>","text":"<p>This function does: - Read task_paths from .yaml file     - Prepare the task_list     - Prepare fordward &amp; backward files     - Prepare command_list - Submit jobs to the cluster - Download the results when finished</p>"},{"location":"alff_api/#alff.phonon.lib_pho_lammps.postpho_lammps_optimize","title":"<code>postpho_lammps_optimize(work_path, pdict)</code>","text":"<p>This function does: - Remove unlabeled .extxyz files, just keep the labeled ones. - Convert LAMMPS output to extxyz_labeled.</p>"},{"location":"alff_api/#alff.phonon.lib_pho_lammps.prepho_lammps_optimize_fixbox","title":"<code>prepho_lammps_optimize_fixbox(work_path, pdict)</code>","text":"<p>This function does: - Prepare task_paths: select only unlabeled structures to compute at clusters. - Prepare lammps_optimize and lammps_input files.     - Convert extxyz to lmpdata.     - Copy potential file to work_path.</p>"},{"location":"alff_api/#alff.phonon.lib_pho_lammps.prepho_lammps_singlepoint","title":"<code>prepho_lammps_singlepoint(work_path, pdict)</code>","text":"<p>This function does: - Prepare task_paths: select only unlabeled structures to compute at clusters. - Prepare lammps_optimize and lammps_input files.     - Convert extxyz to lmpdata.     - Copy potential file to work_path.</p>"},{"location":"alff_api/#alff.phonon.lib_pho_lammps.postpho_lammps_singlepoint","title":"<code>postpho_lammps_singlepoint(work_path, pdict)</code>","text":"<p>This function does: - Clean up unlabelled extxyz files - Collect forces from the output files</p>"},{"location":"alff_api/#alff.phonon.lib_phonopy","title":"<code>lib_phonopy</code>","text":"<p>Functions:</p> <ul> <li> <code>convert_phonopy2ase</code>             \u2013              </li> <li> <code>convert_ase2phonopy</code>             \u2013              </li> <li> <code>get_band_path</code>             \u2013              </li> <li> <code>get_band_structure</code>             \u2013              </li> <li> <code>get_DOS_n_PDOS</code>             \u2013              </li> <li> <code>get_thermal_properties</code>             \u2013              </li> </ul>"},{"location":"alff_api/#alff.phonon.lib_phonopy.convert_phonopy2ase","title":"<code>convert_phonopy2ase(atoms: PhonopyAtoms) -&gt; Atoms</code>","text":""},{"location":"alff_api/#alff.phonon.lib_phonopy.convert_ase2phonopy","title":"<code>convert_ase2phonopy(atoms: Atoms) -&gt; PhonopyAtoms</code>","text":""},{"location":"alff_api/#alff.phonon.lib_phonopy.get_band_path","title":"<code>get_band_path(atoms: Atoms, path_str: str = None, npoints: int = 61, path_frac=None, labels=None)</code>","text":""},{"location":"alff_api/#alff.phonon.lib_phonopy.get_band_structure","title":"<code>get_band_structure(work_path, pdict)</code>","text":""},{"location":"alff_api/#alff.phonon.lib_phonopy.get_DOS_n_PDOS","title":"<code>get_DOS_n_PDOS(work_path, pdict)</code>","text":""},{"location":"alff_api/#alff.phonon.lib_phonopy.get_thermal_properties","title":"<code>get_thermal_properties(work_path, pdict)</code>","text":""},{"location":"alff_api/#alff.phonon.lib_phonopy._ref_phonon_calc","title":"<code>_ref_phonon_calc(atoms: Atoms, calc: object, supercell_matrix=[[2, 0, 0], [0, 2, 0], [0, 0, 2]], displacement=0.01, NAC: bool = False) -&gt; object</code>","text":"<p>NOTE: this function is note be used. just for reference.</p> <p>Parameters:</p> <ul> <li> <code>atoms</code>               (<code>Atoms</code>)           \u2013            <p>ASE's structure object which is already optimized/relaxed as the ground state.</p> </li> <li> <code>calc</code>               (<code>object</code>)           \u2013            <p>ASE calculator object.</p> </li> <li> <code>supercell_matrix</code>               (<code>list</code>, default:                   <code>[[2, 0, 0], [0, 2, 0], [0, 0, 2]]</code> )           \u2013            <p>The supercell matrix for the phonon calculation.</p> </li> <li> <code>displacement</code>               (<code>float</code>, default:                   <code>0.01</code> )           \u2013            <p>The atomic displacement distance in Angstrom.</p> </li> <li> <code>NAC</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>Whether to use non-analytical corrections (NAC) for the phonon calculation.</p> </li> </ul> <p>NOTE: not yet finished</p>"},{"location":"alff_api/#alff.phonon.phonon","title":"<code>phonon</code>","text":"<p>Functions:</p> <ul> <li> <code>build_structure_phonon</code>             \u2013              </li> <li> <code>relax_initial_structure</code>             \u2013              <p>Relax the structure by DFT/MD</p> </li> <li> <code>scale_and_relax</code>             \u2013              <p>Scale and relax the structures while fixing box size. Use when want to compute phonon at different volumes.</p> </li> <li> <code>compute_force</code>             \u2013              <p>Compute forces for each scale-relaxed-structure by DFT/MD.</p> </li> <li> <code>compute_force_single_structure</code>             \u2013              <p>Run DFT/MD single-point calculation to compute forces for a list of supercells of a single structure. The function does the following:</p> </li> <li> <code>compute_phonon</code>             \u2013              <p>Compute phonon properties by <code>phonopy</code> functions.</p> </li> <li> <code>phonon_calc</code>             \u2013              <p>Generate initial data for training ML models</p> </li> </ul>"},{"location":"alff_api/#alff.phonon.phonon.build_structure_phonon","title":"<code>build_structure_phonon(pdict, mdict)</code>","text":""},{"location":"alff_api/#alff.phonon.phonon.relax_initial_structure","title":"<code>relax_initial_structure(pdict, mdict)</code>","text":"<p>Relax the structure by DFT/MD</p>"},{"location":"alff_api/#alff.phonon.phonon.scale_and_relax","title":"<code>scale_and_relax(pdict, mdict)</code>","text":"<p>Scale and relax the structures while fixing box size. Use when want to compute phonon at different volumes.</p>"},{"location":"alff_api/#alff.phonon.phonon.compute_force","title":"<code>compute_force(pdict, mdict)</code>","text":"<p>Compute forces for each scale-relaxed-structure by DFT/MD.</p>"},{"location":"alff_api/#alff.phonon.phonon.compute_force_single_structure","title":"<code>compute_force_single_structure(work_path, pdict, mdict)</code>","text":"<p>Run DFT/MD single-point calculation to compute forces for a list of supercells of a single structure. The function does the following: - Initialize the <code>phonopy</code> object - generate supercells with displacements - run DFT/MD single-point calculation to compute forces for each supercell - assign forces back to phonopy object - save the phonopy object to a file for latter post-processing</p>"},{"location":"alff_api/#alff.phonon.phonon.compute_phonon","title":"<code>compute_phonon(pdict, mdict)</code>","text":"<p>Compute phonon properties by <code>phonopy</code> functions.</p>"},{"location":"alff_api/#alff.phonon.phonon.phonon_calc","title":"<code>phonon_calc(configfile_param: str, configfile_machine: str)</code>","text":"<p>Generate initial data for training ML models</p>"},{"location":"alff_api/#alff.util","title":"<code>util</code>","text":"<p>Modules:</p> <ul> <li> <code>argument_docs</code>           \u2013            <p><code>alff</code> accepts a configuration file in YAML/JSON/JSONC format.</p> </li> <li> <code>dispatcher</code>           \u2013            </li> <li> <code>gpaw_script</code>           \u2013            </li> <li> <code>key</code>           \u2013            </li> <li> <code>pathtool</code>           \u2013            </li> <li> <code>script_lammps</code>           \u2013            </li> <li> <code>structure</code>           \u2013            </li> <li> <code>util</code>           \u2013            <p>some common utilities for generator, auto_test and data</p> </li> </ul>"},{"location":"alff_api/#alff.util.argument_docs","title":"<code>argument_docs</code>","text":"<p><code>alff</code> accepts a configuration file in YAML/JSON/JSONC format.</p> <p>Functions:</p> <ul> <li> <code>param</code>             \u2013              <p>ALFF parameters.</p> </li> <li> <code>not_use_param_seveen</code>             \u2013              <p>SevenNet parameters that are not applicable.</p> </li> <li> <code>machine</code>             \u2013              <p>ALFF parameters for running on a clusters.</p> </li> </ul>"},{"location":"alff_api/#alff.util.argument_docs.param","title":"<code>param()</code>","text":"<p>ALFF parameters.</p>"},{"location":"alff_api/#alff.util.argument_docs.param--parameters","title":"Parameters","text":"<pre><code>mlp_engine: str\n    The engine to use for training the MLP model. Choices: 'sevenn', 'mace'\nnumb_models: int\n    Number of models to train.\ninit_data_paths: list[str]\n    List of paths to the initial data.\ndistributed: bool\n    Whether to use distributed training.\ndistributed_backend: str\n    The Pytorch backend to use for distributed training. Choices: 'nccl', 'mpi'\nsevenn_args: dict\n    SevenNet's parameters.\nmace_args: dict\n    Mace's parameters.\n</code></pre>"},{"location":"alff_api/#alff.util.argument_docs.not_use_param_seveen","title":"<code>not_use_param_seveen()</code>","text":"<p>SevenNet parameters that are not applicable.</p> <p>These parameters are either generated by the ALFF or are not required for running the ALFF.</p>"},{"location":"alff_api/#alff.util.argument_docs.not_use_param_seveen--parameters","title":"Parameters","text":"<pre><code>train.random_seed: int\n    Random seed for reproducibility.\ndata.load_dataset_path: list[str]\n    List of paths to the dataset.\n</code></pre>"},{"location":"alff_api/#alff.util.argument_docs.machine","title":"<code>machine()</code>","text":"<p>ALFF parameters for running on a clusters.</p>"},{"location":"alff_api/#alff.util.dispatcher","title":"<code>dispatcher</code>","text":"<p>Functions:</p> <ul> <li> <code>submit_job</code>             \u2013              <p>Function to submit a job to the cluster:</p> </li> <li> <code>submit_junk_job</code>             \u2013              <p>Improved version of <code>submit_job</code> to split the task_paths into chunks and submit them.</p> </li> <li> <code>info_current_dispatch</code>             \u2013              <p>Return the information of the current chunk of tasks.</p> </li> <li> <code>remote_info</code>             \u2013              <p>Return the remote machine information.</p> </li> <li> <code>check_task_paths</code>             \u2013              </li> </ul> <p>Attributes:</p> <ul> <li> <code>fh</code>           \u2013            </li> <li> <code>fmt</code>           \u2013            </li> </ul>"},{"location":"alff_api/#alff.util.dispatcher.fh","title":"<code>fh = logging.FileHandler(FILE_LOG_DISPATCH)</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.util.dispatcher.fmt","title":"<code>fmt = logging.Formatter('%(asctime)s | %(name)s-%(levelname)s: %(message)s', '%Y-%b-%d %H:%M:%S')</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.util.dispatcher.submit_job","title":"<code>submit_job(mdict_machine: dict, mdict_resources: dict, command_list: list[str], work_path: str, task_paths: list[str], forward_files: list[str], backward_files: list[str], forward_common_files: list[str], outlog: str, errlog: str)</code>","text":"<p>Function to submit a job to the cluster: - Prepare the task list - Make the submission and wait for the job to finish - Download the results</p>"},{"location":"alff_api/#alff.util.dispatcher.submit_junk_job","title":"<code>submit_junk_job(mdict_machine: dict, mdict_resources: dict, command_list: list[str], work_path: str, task_paths: list[str], forward_files: list[str], backward_files: list[str], forward_common_files: list[str], outlog: str, errlog: str, jobs_per_dispatch: int)</code>","text":"<p>Improved version of <code>submit_job</code> to split the task_paths into chunks and submit them.</p>"},{"location":"alff_api/#alff.util.dispatcher.info_current_dispatch","title":"<code>info_current_dispatch(task_paths, jobs_per_dispatch, chunk_count, paths_in_chunk, last_time=None, current_time=None) -&gt; str</code>","text":"<p>Return the information of the current chunk of tasks.</p>"},{"location":"alff_api/#alff.util.dispatcher.remote_info","title":"<code>remote_info(mdict, job_type: str = 'dft') -&gt; str</code>","text":"<p>Return the remote machine information. Args:     job_type: 'train', 'dft', 'md'.</p>"},{"location":"alff_api/#alff.util.dispatcher.check_task_paths","title":"<code>check_task_paths(task_paths: list[str], mdict: dict, job_type: str) -&gt; str</code>","text":""},{"location":"alff_api/#alff.util.gpaw_script","title":"<code>gpaw_script</code>","text":"<p>Modules:</p> <ul> <li> <code>cli_gpaw_aimd</code>           \u2013            <p>Some notes:</p> </li> <li> <code>cli_gpaw_optimize</code>           \u2013            <p>Some notes</p> </li> <li> <code>cli_gpaw_singlepoint</code>           \u2013            <p>Some notes</p> </li> <li> <code>script_ase_md_template</code>           \u2013            </li> </ul>"},{"location":"alff_api/#alff.util.gpaw_script.cli_gpaw_aimd","title":"<code>cli_gpaw_aimd</code>","text":"<p>Some notes: - Run MD in ase following this tutorial: https://wiki.fysik.dtu.dk/ase/tutorials/md/md.html - For MD run, control symmetry to avoid error: <code>broken symmetry</code>. - Must set txt='calc.txt' in GPAW calculator for backward files. - param_yaml must contain     - a dict <code>gpaw_calc</code> with GPAW parameters.     - a dict <code>aimd</code> with ASE MD parameters.</p> <p>Functions:</p> <ul> <li> <code>print_properties</code>             \u2013              <p>Function to print the potential, kinetic and total energy.</p> </li> <li> <code>write_xyz</code>             \u2013              </li> </ul> <p>Attributes:</p> <ul> <li> <code>parser</code>           \u2013            </li> <li> <code>args</code>           \u2013            </li> <li> <code>configfile</code>           \u2013            </li> <li> <code>pdict</code>           \u2013            </li> <li> <code>extxyz_file</code>           \u2013            </li> <li> <code>atoms</code>           \u2013            </li> <li> <code>params</code>           \u2013            </li> <li> <code>gpaw_arg</code>           \u2013            </li> <li> <code>calc</code>           \u2013            </li> <li> <code>aimd</code>           \u2013            </li> <li> <code>dt</code>           \u2013            </li> <li> <code>temperature</code>           \u2013            </li> <li> <code>ensemble</code>           \u2013            </li> <li> <code>collect_frames</code>           \u2013            </li> <li> <code>traj_freq</code>           \u2013            </li> <li> <code>nsteps</code>           \u2013            </li> <li> <code>dyn</code>           \u2013            </li> </ul>"},{"location":"alff_api/#alff.util.gpaw_script.cli_gpaw_aimd.parser","title":"<code>parser = argparse.ArgumentParser(description='Optimize structure using GPAW')</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.util.gpaw_script.cli_gpaw_aimd.args","title":"<code>args = parser.parse_args()</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.util.gpaw_script.cli_gpaw_aimd.configfile","title":"<code>configfile = args.param</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.util.gpaw_script.cli_gpaw_aimd.pdict","title":"<code>pdict = yaml.safe_load(f)</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.util.gpaw_script.cli_gpaw_aimd.extxyz_file","title":"<code>extxyz_file = pdict['input_extxyz_path']</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.util.gpaw_script.cli_gpaw_aimd.atoms","title":"<code>atoms = read(extxyz_file, format='extxyz', index='-1')</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.util.gpaw_script.cli_gpaw_aimd.params","title":"<code>params = {'mode': {'name': 'pw', 'ecut': 500}, 'xc': 'PBE', 'convergence': {'energy': 1e-06, 'density': 0.0001, 'eigenstates': 1e-08}, 'occupations': {'name': 'fermi-dirac', 'width': 0.01}, 'txt': 'calc_aimd.txt', 'symmetry': 'off'}</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.util.gpaw_script.cli_gpaw_aimd.gpaw_arg","title":"<code>gpaw_arg = pdict.get('gpaw_calc', {})</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.util.gpaw_script.cli_gpaw_aimd.calc","title":"<code>calc = GPAW(**params)</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.util.gpaw_script.cli_gpaw_aimd.aimd","title":"<code>aimd = pdict.get('aimd', {})</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.util.gpaw_script.cli_gpaw_aimd.dt","title":"<code>dt = aimd.get('dt', 1)</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.util.gpaw_script.cli_gpaw_aimd.temperature","title":"<code>temperature = aimd.get('temperature', 300)</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.util.gpaw_script.cli_gpaw_aimd.ensemble","title":"<code>ensemble = aimd.get('ensemble', 'NVE')</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.util.gpaw_script.cli_gpaw_aimd.collect_frames","title":"<code>collect_frames = aimd.get('collect_frames', 5)</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.util.gpaw_script.cli_gpaw_aimd.traj_freq","title":"<code>traj_freq = aimd.get('traj_freq', 1)</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.util.gpaw_script.cli_gpaw_aimd.nsteps","title":"<code>nsteps = collect_frames * traj_freq</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.util.gpaw_script.cli_gpaw_aimd.dyn","title":"<code>dyn = VelocityVerlet(atoms, timestep=dt * units.fs)</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.util.gpaw_script.cli_gpaw_aimd.print_properties","title":"<code>print_properties(atoms=atoms, filename='calc_properties.txt')</code>","text":"<p>Function to print the potential, kinetic and total energy.</p>"},{"location":"alff_api/#alff.util.gpaw_script.cli_gpaw_aimd.write_xyz","title":"<code>write_xyz(atoms=atoms, filename='traj_label.extxyz')</code>","text":""},{"location":"alff_api/#alff.util.gpaw_script.cli_gpaw_optimize","title":"<code>cli_gpaw_optimize</code>","text":"<p>Some notes - Must set txt='calc.txt' in GPAW calculator for backward files. - param_yaml must contain     - a dict <code>gpaw</code> with GPAW parameters.     - a dict <code>optimize</code> with ASE optimization parameters.</p> <p>Attributes:</p> <ul> <li> <code>parser</code>           \u2013            </li> <li> <code>args</code>           \u2013            </li> <li> <code>configfile</code>           \u2013            </li> <li> <code>pdict</code>           \u2013            </li> <li> <code>extxyz_file</code>           \u2013            </li> <li> <code>atoms</code>           \u2013            </li> <li> <code>params</code>           \u2013            </li> <li> <code>gpaw_arg</code>           \u2013            </li> <li> <code>calc</code>           \u2013            </li> <li> <code>opt_args</code>           \u2013            </li> <li> <code>relax_dim</code>           \u2013            </li> <li> <code>pbc</code>           \u2013            </li> <li> <code>fmax</code>           \u2013            </li> <li> <code>max_steps</code>           \u2013            </li> <li> <code>atoms_filter</code>           \u2013            </li> <li> <code>opt</code>           \u2013            </li> <li> <code>pot_energy</code>           \u2013            </li> <li> <code>forces</code>           \u2013            </li> <li> <code>stress</code>           \u2013            </li> <li> <code>output_file</code>           \u2013            </li> </ul>"},{"location":"alff_api/#alff.util.gpaw_script.cli_gpaw_optimize.parser","title":"<code>parser = argparse.ArgumentParser(description='Optimize structure using GPAW')</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.util.gpaw_script.cli_gpaw_optimize.args","title":"<code>args = parser.parse_args()</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.util.gpaw_script.cli_gpaw_optimize.configfile","title":"<code>configfile = args.param</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.util.gpaw_script.cli_gpaw_optimize.pdict","title":"<code>pdict = yaml.safe_load(f)</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.util.gpaw_script.cli_gpaw_optimize.extxyz_file","title":"<code>extxyz_file = pdict['input_extxyz_path']</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.util.gpaw_script.cli_gpaw_optimize.atoms","title":"<code>atoms = read(extxyz_file, format='extxyz', index='-1')</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.util.gpaw_script.cli_gpaw_optimize.params","title":"<code>params = {'mode': {'name': 'pw', 'ecut': 500}, 'xc': 'PBE', 'convergence': {'energy': 1e-06, 'density': 0.0001, 'eigenstates': 1e-08}, 'occupations': {'name': 'fermi-dirac', 'width': 0.01}, 'txt': 'calc_optimize.txt'}</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.util.gpaw_script.cli_gpaw_optimize.gpaw_arg","title":"<code>gpaw_arg = pdict.get('gpaw_calc', {})</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.util.gpaw_script.cli_gpaw_optimize.calc","title":"<code>calc = GPAW(**params)</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.util.gpaw_script.cli_gpaw_optimize.opt_args","title":"<code>opt_args = pdict.get('optimize', {})</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.util.gpaw_script.cli_gpaw_optimize.relax_dim","title":"<code>relax_dim = opt_args.get('relax_dim', None)</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.util.gpaw_script.cli_gpaw_optimize.pbc","title":"<code>pbc = atoms.get_pbc()</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.util.gpaw_script.cli_gpaw_optimize.fmax","title":"<code>fmax = opt_args.get('fmax', 0.05)</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.util.gpaw_script.cli_gpaw_optimize.max_steps","title":"<code>max_steps = opt_args.get('max_steps', 10000)</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.util.gpaw_script.cli_gpaw_optimize.atoms_filter","title":"<code>atoms_filter = FrechetCellFilter(atoms, mask=relax_dim)</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.util.gpaw_script.cli_gpaw_optimize.opt","title":"<code>opt = BFGS(atoms_filter)</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.util.gpaw_script.cli_gpaw_optimize.pot_energy","title":"<code>pot_energy = atoms.get_potential_energy(force_consistent=True)</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.util.gpaw_script.cli_gpaw_optimize.forces","title":"<code>forces = atoms.get_forces()</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.util.gpaw_script.cli_gpaw_optimize.stress","title":"<code>stress = atoms.get_stress()</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.util.gpaw_script.cli_gpaw_optimize.output_file","title":"<code>output_file = extxyz_file.replace('.extxyz', '_label.extxyz')</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.util.gpaw_script.cli_gpaw_singlepoint","title":"<code>cli_gpaw_singlepoint</code>","text":"<p>Some notes - Must set txt='calc.txt' in GPAW calculator for backward files. - param_yaml must contain     - a dict <code>gpaw</code> with GPAW parameters.</p> <p>Attributes:</p> <ul> <li> <code>parser</code>           \u2013            </li> <li> <code>args</code>           \u2013            </li> <li> <code>configfile</code>           \u2013            </li> <li> <code>pdict</code>           \u2013            </li> <li> <code>extxyz_file</code>           \u2013            </li> <li> <code>atoms</code>           \u2013            </li> <li> <code>params</code>           \u2013            </li> <li> <code>gpaw_arg</code>           \u2013            </li> <li> <code>calc</code>           \u2013            </li> <li> <code>pot_energy</code>           \u2013            </li> <li> <code>forces</code>           \u2013            </li> <li> <code>stress</code>           \u2013            </li> <li> <code>output_file</code>           \u2013            </li> </ul>"},{"location":"alff_api/#alff.util.gpaw_script.cli_gpaw_singlepoint.parser","title":"<code>parser = argparse.ArgumentParser(description='Optimize structure using GPAW')</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.util.gpaw_script.cli_gpaw_singlepoint.args","title":"<code>args = parser.parse_args()</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.util.gpaw_script.cli_gpaw_singlepoint.configfile","title":"<code>configfile = args.param</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.util.gpaw_script.cli_gpaw_singlepoint.pdict","title":"<code>pdict = yaml.safe_load(f)</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.util.gpaw_script.cli_gpaw_singlepoint.extxyz_file","title":"<code>extxyz_file = pdict['input_extxyz_path']</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.util.gpaw_script.cli_gpaw_singlepoint.atoms","title":"<code>atoms = read(extxyz_file, format='extxyz', index='-1')</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.util.gpaw_script.cli_gpaw_singlepoint.params","title":"<code>params = {'mode': {'name': 'pw', 'ecut': 500}, 'xc': 'PBE', 'convergence': {'energy': 1e-06, 'density': 0.0001, 'eigenstates': 1e-08}, 'occupations': {'name': 'fermi-dirac', 'width': 0.01}, 'txt': 'calc_singlepoint.txt'}</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.util.gpaw_script.cli_gpaw_singlepoint.gpaw_arg","title":"<code>gpaw_arg = pdict.get('gpaw_calc', {})</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.util.gpaw_script.cli_gpaw_singlepoint.calc","title":"<code>calc = GPAW(**params)</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.util.gpaw_script.cli_gpaw_singlepoint.pot_energy","title":"<code>pot_energy = atoms.get_potential_energy(force_consistent=True)</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.util.gpaw_script.cli_gpaw_singlepoint.forces","title":"<code>forces = atoms.get_forces()</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.util.gpaw_script.cli_gpaw_singlepoint.stress","title":"<code>stress = atoms.get_stress()</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.util.gpaw_script.cli_gpaw_singlepoint.output_file","title":"<code>output_file = extxyz_file.replace('.extxyz', '_label.extxyz')</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.util.gpaw_script.script_ase_md_template","title":"<code>script_ase_md_template</code>","text":""},{"location":"alff_api/#alff.util.key","title":"<code>key</code>","text":"<p>Attributes:</p> <ul> <li> <code>time_str</code>           \u2013            </li> <li> <code>DIR_LOG</code>           \u2013            </li> <li> <code>FILE_LOG_ALFF</code>           \u2013            </li> <li> <code>FILE_LOG_DISPATCH</code>           \u2013            </li> <li> <code>DIR_TRAIN</code>           \u2013            </li> <li> <code>DIR_MD</code>           \u2013            </li> <li> <code>DIR_DFT</code>           \u2013            </li> <li> <code>DIR_DATA</code>           \u2013            </li> <li> <code>DIR_TMP</code>           \u2013            </li> <li> <code>DIR_TMP_DATA</code>           \u2013            </li> <li> <code>DIR_TMP_MODEL</code>           \u2013            </li> <li> <code>FILE_ITER_LOG</code>           \u2013            </li> <li> <code>FILE_DATAPATH</code>           \u2013            </li> <li> <code>FILE_MODELPATH</code>           \u2013            </li> <li> <code>FILE_TRAIN_PARAM</code>           \u2013            </li> <li> <code>FILE_LAMMPS_SCRIPT</code>           \u2013            </li> <li> <code>FILE_LAMMPS_ARG</code>           \u2013            </li> <li> <code>FILE_GPAW_ARG</code>           \u2013            </li> <li> <code>FMT_ITER</code>           \u2013            </li> <li> <code>FMT_STAGE</code>           \u2013            </li> <li> <code>FMT_MODEL</code>           \u2013            </li> <li> <code>FMT_CONF</code>           \u2013            </li> <li> <code>FMT_TASK_MD</code>           \u2013            </li> <li> <code>FMT_TASK_DFT</code>           \u2013            </li> <li> <code>DIR_BUILD</code>           \u2013            </li> <li> <code>DIR_SCALE</code>           \u2013            </li> <li> <code>DIR_GENDATA</code>           \u2013            </li> <li> <code>FILE_FRAME_unLABELED</code>           \u2013            </li> <li> <code>FILE_FRAME_LABELED</code>           \u2013            </li> <li> <code>FILE_TRAJ_LABELED</code>           \u2013            </li> <li> <code>FILE_FINAL_DATA</code>           \u2013            </li> <li> <code>DIR_SUPERCELL</code>           \u2013            </li> <li> <code>DIR_PHONON</code>           \u2013            </li> <li> <code>DIR_ELASTIC</code>           \u2013            </li> <li> <code>LIB_GPAW_PATH</code>           \u2013            </li> </ul>"},{"location":"alff_api/#alff.util.key.time_str","title":"<code>time_str = time.strftime('%Y%m%d_%H%M%S')</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.util.key.DIR_LOG","title":"<code>DIR_LOG = 'log'</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.util.key.FILE_LOG_ALFF","title":"<code>FILE_LOG_ALFF = f'{DIR_LOG}/{time_str}_alff.log'</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.util.key.FILE_LOG_DISPATCH","title":"<code>FILE_LOG_DISPATCH = FILE_LOG_ALFF.replace('alff', 'dispatch')</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.util.key.DIR_TRAIN","title":"<code>DIR_TRAIN = '00_train'</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.util.key.DIR_MD","title":"<code>DIR_MD = '01_md'</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.util.key.DIR_DFT","title":"<code>DIR_DFT = '02_dft'</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.util.key.DIR_DATA","title":"<code>DIR_DATA = '03_data'</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.util.key.DIR_TMP","title":"<code>DIR_TMP = 'tmp_dir'</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.util.key.DIR_TMP_DATA","title":"<code>DIR_TMP_DATA = 'copied_data'</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.util.key.DIR_TMP_MODEL","title":"<code>DIR_TMP_MODEL = 'copied_model'</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.util.key.FILE_ITER_LOG","title":"<code>FILE_ITER_LOG = '_alff_iter.record'</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.util.key.FILE_DATAPATH","title":"<code>FILE_DATAPATH = 'data_paths.yaml'</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.util.key.FILE_MODELPATH","title":"<code>FILE_MODELPATH = 'model_paths.yaml'</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.util.key.FILE_TRAIN_PARAM","title":"<code>FILE_TRAIN_PARAM = 'train_param.yaml'</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.util.key.FILE_LAMMPS_SCRIPT","title":"<code>FILE_LAMMPS_SCRIPT = 'lammps_script.in'</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.util.key.FILE_LAMMPS_ARG","title":"<code>FILE_LAMMPS_ARG = 'lammps_arg.yaml'</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.util.key.FILE_GPAW_ARG","title":"<code>FILE_GPAW_ARG = 'gpaw_arg.yaml'</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.util.key.FMT_ITER","title":"<code>FMT_ITER = '06d'</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.util.key.FMT_STAGE","title":"<code>FMT_STAGE = '02d'</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.util.key.FMT_MODEL","title":"<code>FMT_MODEL = '03d'</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.util.key.FMT_CONF","title":"<code>FMT_CONF = '04d'</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.util.key.FMT_TASK_MD","title":"<code>FMT_TASK_MD = '06d'</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.util.key.FMT_TASK_DFT","title":"<code>FMT_TASK_DFT = '06d'</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.util.key.DIR_BUILD","title":"<code>DIR_BUILD = '00_build_structure'</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.util.key.DIR_SCALE","title":"<code>DIR_SCALE = '01_scale_perturb'</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.util.key.DIR_GENDATA","title":"<code>DIR_GENDATA = '02_gendata'</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.util.key.FILE_FRAME_unLABELED","title":"<code>FILE_FRAME_unLABELED = 'conf.extxyz'</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.util.key.FILE_FRAME_LABELED","title":"<code>FILE_FRAME_LABELED = 'conf_label.extxyz'</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.util.key.FILE_TRAJ_LABELED","title":"<code>FILE_TRAJ_LABELED = 'traj_label.extxyz'</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.util.key.FILE_FINAL_DATA","title":"<code>FILE_FINAL_DATA = 'data_label.extxyz'</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.util.key.DIR_SUPERCELL","title":"<code>DIR_SUPERCELL = '01_supercell'</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.util.key.DIR_PHONON","title":"<code>DIR_PHONON = '02_phonon'</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.util.key.DIR_ELASTIC","title":"<code>DIR_ELASTIC = '02_elastic'</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.util.key.LIB_GPAW_PATH","title":"<code>LIB_GPAW_PATH = f'{ROOT_PATH}/lib/gpaw_script'</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.util.pathtool","title":"<code>pathtool</code>","text":"<p>Functions:</p> <ul> <li> <code>mkname_structure</code>             \u2013              <p>Create the directory name for the structure</p> </li> <li> <code>ask_for_backup_dir</code>             \u2013              </li> <li> <code>ask_yes_no</code>             \u2013              <p>Asks a yes/no question and returns True for 'yes' and False for 'no'.</p> </li> </ul>"},{"location":"alff_api/#alff.util.pathtool.mkname_structure","title":"<code>mkname_structure(pdict)</code>","text":"<p>Create the directory name for the structure</p>"},{"location":"alff_api/#alff.util.pathtool.ask_for_backup_dir","title":"<code>ask_for_backup_dir(dir_path: str)</code>","text":""},{"location":"alff_api/#alff.util.pathtool.ask_yes_no","title":"<code>ask_yes_no(question: str) -&gt; str</code>","text":"<p>Asks a yes/no question and returns True for 'yes' and False for 'no'.</p>"},{"location":"alff_api/#alff.util.script_lammps","title":"<code>script_lammps</code>","text":"<p>Functions:</p> <ul> <li> <code>generate_input_lammps_md</code>             \u2013              <p>Generate lammps input file for MD simulation.</p> </li> <li> <code>generate_script_lammps_singlepoint</code>             \u2013              <p>Generate lammps script for single-point calculation.</p> </li> <li> <code>generate_script_lammps_minimize</code>             \u2013              <p>Generate lammps script for minimization.</p> </li> <li> <code>lmp_section_atom_forcefield</code>             \u2013              <p>Generate lammps input block for atom and forcefield.</p> </li> <li> <code>lmp_section_common_setting</code>             \u2013              </li> <li> <code>lmp_section_run0</code>             \u2013              </li> <li> <code>lmp_section_minimize</code>             \u2013              <p>Generate lammps input block for minimization.</p> </li> <li> <code>lmp_section_dynamic_setting</code>             \u2013              </li> <li> <code>lmp_section_dynamic_nve</code>             \u2013              </li> <li> <code>lmp_section_dynamic_nvt</code>             \u2013              </li> <li> <code>lmp_section_dynamic_npt</code>             \u2013              </li> <li> <code>lmp_section_dynamic_nph</code>             \u2013              </li> <li> <code>lmp_section_custom_lines</code>             \u2013              </li> </ul>"},{"location":"alff_api/#alff.util.script_lammps.generate_input_lammps_md","title":"<code>generate_input_lammps_md(file_data: str, pair_style: str = ['e3gnn/parallel'], pair_coeff: str = ['* * numb_layers /path/to/potential Cu'], dt: float = 0.001, temp: float = 300, press: float = 0.0, tau_t: int = 100, tau_p: int = 1000, sampling_ensemble: str = 'npt', relax_ensemble: str = None, relax_steps: int = 10000, collect_frames: int = 100, traj_freq: int = 500, thermo_freq: int = 5000, file_plumed: str = None, units: str = 'metal', atom_style: str = 'atomic', pbc: list = [1, 1, 1], dir_output: str = 'output_md', file_output: str = 'lammps_input.in')</code>","text":"<p>Generate lammps input file for MD simulation.</p> <p>Parameters:</p> <ul> <li> <code>relax_ensemble</code>               (<code>str</code>, default:                   <code>None</code> )           \u2013            <p>Ensemble for relaxation before sampling. If None, use the same ensemble as sampling_ensemble.</p> </li> <li> <code>collect_frames</code>               (<code>int</code>, default:                   <code>100</code> )           \u2013            <p>Number of frames to be collected. Then total MD nsteps = collect_frames * traj_freq</p> </li> </ul> Note <ul> <li><code>re.search(r\"sub_text\\s+\", line)</code> matches <code>sub_text</code> followed by at least 1 space.</li> </ul>"},{"location":"alff_api/#alff.util.script_lammps._revise_lammps_npt","title":"<code>_revise_lammps_npt(lines, relax_ensemble, sampling_ensemble)</code>","text":"<p>Revise lammps input file to use npt ensemble</p>"},{"location":"alff_api/#alff.util.script_lammps._revise_lammps_nvt","title":"<code>_revise_lammps_nvt(lines, relax_ensemble, sampling_ensemble)</code>","text":"<p>Revise lammps input file to use nvt ensemble</p>"},{"location":"alff_api/#alff.util.script_lammps._revise_lammps_nve","title":"<code>_revise_lammps_nve(lines, relax_ensemble, sampling_ensemble)</code>","text":"<p>Revise lammps input file to use nve ensemble</p>"},{"location":"alff_api/#alff.util.script_lammps._revise_lammps_plumed","title":"<code>_revise_lammps_plumed(lines, file_plumed)</code>","text":"<p>Revise lammps input file to use plumed</p>"},{"location":"alff_api/#alff.util.script_lammps.generate_script_lammps_singlepoint","title":"<code>generate_script_lammps_singlepoint(units: str = 'metal', atom_style: str = 'atomic', dimension: int = 3, pbc: list = [1, 1, 1], read_data: str = 'path_to_file.lmpdata', read_restart: str = None, pair_style: list[str] = ['eam/alloy'], pair_coeff: list[str] = ['* * Cu_Mishin2001.eam.alloy  Cu'], dir_output: str = 'output_md', save_script: str = 'script_lammps.in')</code>","text":"<p>Generate lammps script for single-point calculation.</p>"},{"location":"alff_api/#alff.util.script_lammps.generate_script_lammps_minimize","title":"<code>generate_script_lammps_minimize(units: str = 'metal', atom_style: str = 'atomic', dimension: int = 3, pbc: list = [1, 1, 1], read_data: str = 'path_to_file.lmpdata', read_restart: str = None, pair_style: list[str] = ['eam/alloy'], pair_coeff: list[str] = ['* * Cu_Mishin2001.eam.alloy  Cu'], min_style: str = 'cg', etol: float = 1e-09, ftol: float = 1e-09, maxiter: int = 100000, maxeval: int = 100000, dmax: float = 0.01, press: list = [None, None, None], couple: str = 'none', dir_output: str = 'output_md', save_script: str = 'script_lammps.in')</code>","text":"<p>Generate lammps script for minimization.</p> <p>Parameters:</p> <ul> <li> <code>etol</code>               (<code>float</code>, default:                   <code>1e-09</code> )           \u2013            <p>Energy tolerance for minimization. Default 1.0e-9</p> </li> <li> <code>ftol</code>               (<code>float</code>, default:                   <code>1e-09</code> )           \u2013            <p>Force tolerance for minimization. Default 1.0e-9</p> </li> <li> <code>maxiter</code>               (<code>int</code>, default:                   <code>100000</code> )           \u2013            <p>Maximum number of iterations. Default 100000</p> </li> <li> <code>maxeval</code>               (<code>int</code>, default:                   <code>100000</code> )           \u2013            <p>Maximum number of evaluations. Default 100000</p> </li> <li> <code>dmax</code>               (<code>float</code>, default:                   <code>0.01</code> )           \u2013            <p>maximum distance for line search to move (distance units). Default: 0.01</p> </li> </ul>"},{"location":"alff_api/#alff.util.script_lammps._pbc_string","title":"<code>_pbc_string(pbc: list = [1, 1, 0]) -&gt; str</code>","text":"<p>Convert pbc list to string. [1, 1, 0] -&gt; \"p p f\". See https://docs.lammps.org/boundary.html</p> <p>Acceptable values: 1, 0, p, f, s, m</p>"},{"location":"alff_api/#alff.util.script_lammps._pressure_string","title":"<code>_pressure_string(press: Union[list, float] = [0.0, 0.0, 0.0]) -&gt; str</code>","text":""},{"location":"alff_api/#alff.util.script_lammps._revise_input_pressure","title":"<code>_revise_input_pressure(press: list, pbc: list = [1, 1, 1]) -&gt; list</code>","text":"<p>Revise pressure string based on pbc</p>"},{"location":"alff_api/#alff.util.script_lammps.lmp_section_atom_forcefield","title":"<code>lmp_section_atom_forcefield(units: str = 'metal', atom_style: str = 'atomic', dimension: int = 3, pbc: list = [1, 1, 1], read_data: str = 'path_to_file.lmpdata', read_restart: str = None, pair_style: list[str] = ['eam/alloy'], pair_coeff: list[str] = ['* * Cu_Mishin2001.eam.alloy  Cu']) -&gt; list[str]</code>","text":"<p>Generate lammps input block for atom and forcefield.</p> <p>Parameters:</p> <ul> <li> <code>read_data</code>               (<code>str</code>, default:                   <code>'path_to_file.lmpdata'</code> )           \u2013            <p>Path to the data file. e.g. \"path_to_lmpdata\"</p> </li> <li> <code>read_restart</code>               (<code>str</code>, default:                   <code>None</code> )           \u2013            <p>Path to the restart file. e.g. \"path_to_restart\". If provided, <code>read_restart</code> is used instead of <code>read_data</code>.</p> </li> </ul>"},{"location":"alff_api/#alff.util.script_lammps.lmp_section_common_setting","title":"<code>lmp_section_common_setting(dir_output: str = 'output_md') -&gt; list[str]</code>","text":""},{"location":"alff_api/#alff.util.script_lammps.lmp_section_run0","title":"<code>lmp_section_run0()</code>","text":""},{"location":"alff_api/#alff.util.script_lammps.lmp_section_minimize","title":"<code>lmp_section_minimize(min_style: str = 'cg', etol: float = 1e-09, ftol: float = 1e-09, maxiter: int = 100000, maxeval: int = 100000, dmax: float = 0.01, press: list = [None, None, None], couple: str = 'none') -&gt; list[str]</code>","text":"<p>Generate lammps input block for minimization.</p>"},{"location":"alff_api/#alff.util.script_lammps.lmp_section_dynamic_setting","title":"<code>lmp_section_dynamic_setting(dt: float) -&gt; list[str]</code>","text":""},{"location":"alff_api/#alff.util.script_lammps.lmp_section_dynamic_nve","title":"<code>lmp_section_dynamic_nve()</code>","text":""},{"location":"alff_api/#alff.util.script_lammps.lmp_section_dynamic_nvt","title":"<code>lmp_section_dynamic_nvt()</code>","text":""},{"location":"alff_api/#alff.util.script_lammps.lmp_section_dynamic_npt","title":"<code>lmp_section_dynamic_npt()</code>","text":""},{"location":"alff_api/#alff.util.script_lammps.lmp_section_dynamic_nph","title":"<code>lmp_section_dynamic_nph()</code>","text":""},{"location":"alff_api/#alff.util.script_lammps.lmp_section_custom_lines","title":"<code>lmp_section_custom_lines(lines: list[str]) -&gt; list[str]</code>","text":""},{"location":"alff_api/#alff.util.structure","title":"<code>structure</code>","text":"<p>Functions:</p> <ul> <li> <code>build_conf</code>             \u2013              <p>Build atomic configuration, using library <code>ase.build</code></p> </li> <li> <code>scale_atoms</code>             \u2013              <p>Scale the atoms by the given factors along the three directions.</p> </li> <li> <code>perturb_atoms</code>             \u2013              <p>Perturb the atoms by random displacements. This method adds random displacements to the atomic positions. See more</p> </li> <li> <code>align_atom_to_origin</code>             \u2013              <p>Align min atoms position to the origin.</p> </li> <li> <code>poscar2lmpdata</code>             \u2013              <p>Convert POSCAR file to LAMMPS data file.</p> </li> <li> <code>extxyz2lmpdata</code>             \u2013              <p>Convert extxyz file to LAMMPS data file.</p> </li> <li> <code>lmpdata2extxyz</code>             \u2013              <p>Convert LAMMPS data file to extxyz file.</p> </li> <li> <code>lmpdump2extxyz</code>             \u2013              <p>Convert LAMMPS dump file to extxyz file.</p> </li> <li> <code>write_extxyz</code>             \u2013              <p>Write a list of Atoms object to an extxyz file. The exited <code>ase.io.write</code> function does not support writing file if the parent directory does not exist. This function will overcome this problem.</p> </li> <li> <code>read_extxyz</code>             \u2013              <p>Read extxyz file. The exited <code>ase.io.read</code> returns a single Atoms object if file contains only one frame. This function will return a list of Atoms object.</p> </li> <li> <code>change_key_in_extxyz</code>             \u2013              <p>NOTE: when Atoms object contains reversed_keys: <code>energy</code>, <code>forces</code>, <code>stress</code>, <code>momenta</code>, <code>free_energy</code>,... it will has a <code>SinglePointCalculator</code> object attached to the Atoms, and these keys can be accessed via <code>atoms.calc.results</code> or <code>.get_()</code> methods.</p> </li> <li> <code>remove_key_in_extxyz</code>             \u2013              <p>Remove unwanted keys from extxyz file to keep it clean.</p> </li> <li> <code>select_extxyz_frames</code>             \u2013              <p>Choose frames from a extxyz trajectory file, based on some criteria.</p> </li> <li> <code>find_primitive_cell</code>             \u2013              <p>Find the primitive cell of the given atoms object.</p> </li> </ul>"},{"location":"alff_api/#alff.util.structure.build_conf","title":"<code>build_conf(pdict: dict)</code>","text":"<p>Build atomic configuration, using library <code>ase.build</code></p> <p>Supported structure types: - bulk: sc, fcc, bcc, tetragonal, bct, hcp, rhombohedral, orthorhombic, mcl, diamond, zincblende, rocksalt, cesiumchloride, fluorite or wurtzite. - molecule: molecule - mx2: MX2</p> <p>Parameters:</p> <ul> <li> <code>pdict</code>               (<code>dict</code>)           \u2013            <p>Parameters dictionary</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>outfile</code>          \u2013            <p>Save atomic configuration with format specified by ext of <code>outfile</code>. All ASE supported formats are allowed.</p> </li> </ul>"},{"location":"alff_api/#alff.util.structure.scale_atoms","title":"<code>scale_atoms(atoms: Atoms, factors: list = [1, 1, 1]) -&gt; Atoms</code>","text":"<p>Scale the atoms by the given factors along the three directions.</p>"},{"location":"alff_api/#alff.util.structure.perturb_atoms","title":"<code>perturb_atoms(atoms: Atoms, std_disp: float) -&gt; Atoms</code>","text":"<p>Perturb the atoms by random displacements. This method adds random displacements to the atomic positions. See more</p>"},{"location":"alff_api/#alff.util.structure.align_atom_to_origin","title":"<code>align_atom_to_origin(atoms: Atoms) -&gt; Atoms</code>","text":"<p>Align min atoms position to the origin.</p>"},{"location":"alff_api/#alff.util.structure.poscar2lmpdata","title":"<code>poscar2lmpdata(poscar_file: str, lmpdata_file: str, atom_style: str = 'atomic') -&gt; list[str]</code>","text":"<p>Convert POSCAR file to LAMMPS data file.</p>"},{"location":"alff_api/#alff.util.structure.extxyz2lmpdata","title":"<code>extxyz2lmpdata(extxyz_file: str, lmpdata_file: str, atom_style: str = 'atomic') -&gt; list[str]</code>","text":"<p>Convert extxyz file to LAMMPS data file. NOTE: need to save original_cell to able to recover the original orientation of the crystal.</p>"},{"location":"alff_api/#alff.util.structure.lmpdata2extxyz","title":"<code>lmpdata2extxyz(lmpdata_file: str, extxyz_file: str, original_cell_file: str = None)</code>","text":"<p>Convert LAMMPS data file to extxyz file.</p>"},{"location":"alff_api/#alff.util.structure.lmpdump2extxyz","title":"<code>lmpdump2extxyz(lmpdump_file: str, extxyz_file: str, original_cell_file: str = None, stress_file: str = None, lammps_units: str = 'metal')</code>","text":"<p>Convert LAMMPS dump file to extxyz file.</p> <p>Parameters:</p> <ul> <li> <code>lmpdump_file</code>               (<code>str</code>)           \u2013            <p>Path to the LAMMPS dump file.</p> </li> <li> <code>extxyz_file</code>               (<code>str</code>)           \u2013            <p>Path to the output extxyz file.</p> </li> <li> <code>original_cell_file</code>               (<code>str</code>, default:                   <code>None</code> )           \u2013            <p>Path to the text file contains original_cell. It should a simple text file that can write/read with numpy. If not provided, try to find in the same directory as <code>lmpdump_file</code> with the extension <code>.original_cell</code>. Defaults to None.</p> </li> <li> <code>stress_file</code>               (<code>str</code>, default:                   <code>None</code> )           \u2013            <p>Path to the text file contains stress tensor. Defaults to None.</p> </li> </ul> Restriction <ul> <li>Current ver: stress is mapped based on frame_index, it requires that frames in text stress file must be in the same \"length and order\" as in the LAMMPS dump file.</li> <li> </li> </ul>"},{"location":"alff_api/#alff.util.structure.lmpdump2extxyz--todo-map-based-on-timestep-need-to-modify-ase-to-read-timestep-from-lammps-dump-file","title":"TODO: map based on timestep. Need to modify ASE to read timestep from LAMMPS dump file.","text":""},{"location":"alff_api/#alff.util.structure.write_extxyz","title":"<code>write_extxyz(outfile: str, atoms: list)</code>","text":"<p>Write a list of Atoms object to an extxyz file. The exited <code>ase.io.write</code> function does not support writing file if the parent directory does not exist. This function will overcome this problem.</p> <p>Parameters:</p> <ul> <li> <code>atoms</code>               (<code>list</code>)           \u2013            <p>List of Atoms object.</p> </li> <li> <code>outfile</code>               (<code>str</code>)           \u2013            <p>Path to the output file.</p> </li> </ul>"},{"location":"alff_api/#alff.util.structure.read_extxyz","title":"<code>read_extxyz(extxyz_file: str, index=':') -&gt; list[Atoms]</code>","text":"<p>Read extxyz file. The exited <code>ase.io.read</code> returns a single Atoms object if file contains only one frame. This function will return a list of Atoms object.</p> <p>Parameters:</p> <ul> <li> <code>extxyz_file</code>               (<code>str</code>)           \u2013            <p>Path to the output file.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>list</code> (              <code>list[Atoms]</code> )          \u2013            <p>List of Atoms object.</p> </li> </ul> Note <ul> <li><code>ase.io.read</code> returns a single Atoms object or a list of Atoms object, depending on the <code>index</code> argument.<ul> <li><code>index=\":\"</code> will always return a list.</li> <li><code>index=0</code> or <code>index=-1</code> will return a single Atoms object.</li> </ul> </li> <li>this function will always return a list of Atoms object, even <code>index=0</code> or <code>index=-1</code></li> </ul>"},{"location":"alff_api/#alff.util.structure.change_key_in_extxyz","title":"<code>change_key_in_extxyz(extxyz_file: str, keys: dict[str, str])</code>","text":"<p>NOTE: when Atoms object contains reversed_keys: <code>energy</code>, <code>forces</code>, <code>stress</code>, <code>momenta</code>, <code>free_energy</code>,... it will has a <code>SinglePointCalculator</code> object attached to the Atoms, and these keys can be accessed via <code>atoms.calc.results</code> or <code>.get_()</code> methods.</p> <p>These keys are not stored in <code>atoms.arrays</code> or <code>atoms.info</code>. So to access these properties via <code>atoms.arrays</code> or <code>atoms.info</code>, we need to change the keys that differ from the reserved keys.</p> <p>Parameters:</p> <ul> <li> <code>extxyz_file</code>               (<code>str</code>)           \u2013            <p>Path to the extxyz file.</p> </li> <li> <code>keys</code>               (<code>dict</code>)           \u2013            <p>Dictionary of key pairs {\"old_key\": \"new_key\"} to change. Example: <code>{\"old_key\": \"new_key\", \"forces\": \"ref_forces\", \"stress\": \"ref_stress\"}</code></p> </li> </ul>"},{"location":"alff_api/#alff.util.structure.remove_key_in_extxyz","title":"<code>remove_key_in_extxyz(extxyz_file: str, keys: list[str])</code>","text":"<p>Remove unwanted keys from extxyz file to keep it clean.</p>"},{"location":"alff_api/#alff.util.structure.select_extxyz_frames","title":"<code>select_extxyz_frames(extxyz_file: str, has_symbols: list = None, only_symbols: list = None, exact_symbols: list = None, has_properties: list = None, only_properties: list = None, has_columns: list = None, only_columns: list = None, output_file: str = 'selected_frames.extxyz') -&gt; list[Atoms]</code>","text":"<p>Choose frames from a extxyz trajectory file, based on some criteria.</p> <p>Parameters:</p> <ul> <li> <code>extxyz_file</code>               (<code>str</code>)           \u2013            <p>Path to the extxyz file.</p> </li> <li> <code>has_symbols</code>               (<code>list</code>, default:                   <code>None</code> )           \u2013            <p>List of symbols that each frame must have at least one of them.</p> </li> <li> <code>only_symbols</code>               (<code>list</code>, default:                   <code>None</code> )           \u2013            <p>List of symbols that each frame must have only these symbols.</p> </li> <li> <code>exact_symbols</code>               (<code>list</code>, default:                   <code>None</code> )           \u2013            <p>List of symbols that each frame must have exactly these symbols.</p> </li> <li> <code>has_properties</code>               (<code>list</code>, default:                   <code>None</code> )           \u2013            <p>List of properties that each frame must have at least one of them.</p> </li> <li> <code>only_properties</code>               (<code>list</code>, default:                   <code>None</code> )           \u2013            <p>List of properties that each frame must have only these properties.</p> </li> <li> <code>has_columns</code>               (<code>list</code>, default:                   <code>None</code> )           \u2013            <p>List of columns that each frame must have at least one of them.</p> </li> <li> <code>only_columns</code>               (<code>list</code>, default:                   <code>None</code> )           \u2013            <p>List of columns that each frame must have only these columns.</p> </li> <li> <code>output_file</code>               (<code>str</code>, default:                   <code>'selected_frames.extxyz'</code> )           \u2013            <p>Path to the output file.</p> </li> </ul>"},{"location":"alff_api/#alff.util.structure.find_primitive_cell","title":"<code>find_primitive_cell(atoms: Atoms, symprec=1e-05, angle_tolerance=-1.0) -&gt; Atoms</code>","text":"<p>Find the primitive cell of the given atoms object. NOTE: must use <code>.get_scaled_positions()</code> to define the cell in <code>spglib</code>.</p>"},{"location":"alff_api/#alff.util.util","title":"<code>util</code>","text":"<p>some common utilities for generator, auto_test and data</p> <p>Functions:</p> <ul> <li> <code>text_pkg_info</code>             \u2013              </li> <li> <code>text_logo</code>             \u2013              </li> <li> <code>record_iter</code>             \u2013              </li> <li> <code>iter_str</code>             \u2013              </li> <li> <code>replace</code>             \u2013              </li> <li> <code>copy_file_list</code>             \u2013              </li> <li> <code>cmd_append_log</code>             \u2013              </li> <li> <code>repeat_to_length</code>             \u2013              </li> <li> <code>expand_idx</code>             \u2013              <p>Expand the input list of indices to a list of integers.</p> </li> </ul>"},{"location":"alff_api/#alff.util.util.text_pkg_info","title":"<code>text_pkg_info(modules=['numpy', 'scipy', 'ase', 'polars', 'thutil', 'sevenn', 'phonopy'])</code>","text":""},{"location":"alff_api/#alff.util.util.text_logo","title":"<code>text_logo()</code>","text":""},{"location":"alff_api/#alff.util.util.record_iter","title":"<code>record_iter(filename, iter_idx, stage_idx)</code>","text":""},{"location":"alff_api/#alff.util.util.iter_str","title":"<code>iter_str(iter_idx: int) -&gt; str</code>","text":""},{"location":"alff_api/#alff.util.util.replace","title":"<code>replace(file_name, pattern, subst)</code>","text":""},{"location":"alff_api/#alff.util.util.copy_file_list","title":"<code>copy_file_list(file_list, from_path, to_path)</code>","text":""},{"location":"alff_api/#alff.util.util.cmd_append_log","title":"<code>cmd_append_log(cmd, log_file)</code>","text":""},{"location":"alff_api/#alff.util.util.repeat_to_length","title":"<code>repeat_to_length(input_str: str, length) -&gt; str</code>","text":""},{"location":"alff_api/#alff.util.util.expand_idx","title":"<code>expand_idx(in_list: list[int, str]) -&gt; list[int]</code>","text":"<p>Expand the input list of indices to a list of integers. Eg: in_list = [1, 2, \"3-5:2\", \"6-10\"]</p>"},{"location":"alff_arg_docs/","title":"alff parameters","text":""},{"location":"alff_arg_docs/#alff.util.argument_docs","title":"<code>alff.util.argument_docs</code>","text":"<p><code>alff</code> accepts a configuration file in YAML/JSON/JSONC format.</p> <p>Functions:</p> <ul> <li> <code>param</code>             \u2013              <p>ALFF parameters.</p> </li> <li> <code>not_use_param_seveen</code>             \u2013              <p>SevenNet parameters that are not applicable.</p> </li> <li> <code>machine</code>             \u2013              <p>ALFF parameters for running on a clusters.</p> </li> </ul>"},{"location":"alff_arg_docs/#alff.util.argument_docs.param","title":"<code>param()</code>","text":"<p>ALFF parameters.</p>"},{"location":"alff_arg_docs/#alff.util.argument_docs.param--parameters","title":"Parameters","text":"<pre><code>mlp_engine: str\n    The engine to use for training the MLP model. Choices: 'sevenn', 'mace'\nnumb_models: int\n    Number of models to train.\ninit_data_paths: list[str]\n    List of paths to the initial data.\ndistributed: bool\n    Whether to use distributed training.\ndistributed_backend: str\n    The Pytorch backend to use for distributed training. Choices: 'nccl', 'mpi'\nsevenn_args: dict\n    SevenNet's parameters.\nmace_args: dict\n    Mace's parameters.\n</code></pre>"},{"location":"alff_arg_docs/#alff.util.argument_docs.not_use_param_seveen","title":"<code>not_use_param_seveen()</code>","text":"<p>SevenNet parameters that are not applicable.</p> <p>These parameters are either generated by the ALFF or are not required for running the ALFF.</p>"},{"location":"alff_arg_docs/#alff.util.argument_docs.not_use_param_seveen--parameters","title":"Parameters","text":"<pre><code>train.random_seed: int\n    Random seed for reproducibility.\ndata.load_dataset_path: list[str]\n    List of paths to the dataset.\n</code></pre>"},{"location":"alff_arg_docs/#alff.util.argument_docs.machine","title":"<code>machine()</code>","text":"<p>ALFF parameters for running on a clusters.</p>"},{"location":"alff_cli/","title":"CLI","text":"<p>ALLF provides command-line interface (CLI) to run the ALFF processes:</p> <ul> <li>Active learning process</li> <li>generate data for training ML forcefields</li> <li>convert MPtrj files to XYZ datasets.</li> <li>etc.</li> </ul>"},{"location":"alff_cli/#alff-active-learning","title":"ALFF active learning","text":"<p>Run the main ALFF active learning process.</p> <pre><code>alff_al PARAM.yaml MACHINE.yaml\n</code></pre> <ul> <li><code>PARAM.yaml</code>: The parameters of the generator.</li> <li><code>MACHINE.yaml</code>: The settings of the machines running the generator.</li> </ul>"},{"location":"alff_cli/#data-generator","title":"Data generator","text":"<p>Generate data for training ML forcefields.</p> <pre><code>alff_gen PARAM.yaml MACHINE.yaml\n</code></pre> <ul> <li><code>PARAM.yaml</code>: The parameters of the generator.</li> <li><code>MACHINE.yaml</code>: The settings of the machines running the generator.</li> </ul>"},{"location":"alff_cli/#phonon-calculation","title":"Phonon calculation","text":"<p>Perform the phonon calculation.</p> <pre><code>alff_phonon PARAM.yaml MACHINE.yaml\n</code></pre> <ul> <li><code>PARAM.yaml</code>: The parameters of the generator.</li> <li><code>MACHINE.yaml</code>: The settings of the machines running the generator.</li> </ul>"},{"location":"alff_cli/#dataset-tools","title":"Dataset tools","text":"<p>Convert MPtrj to XYZ</p> <pre><code>chgnet_to_xyz MPtrj.json\n</code></pre> <ul> <li><code>MPtrj.json</code>: The MPtrj file to be converted to XYZ dataset.</li> </ul>"},{"location":"alff_elastic_calc/","title":"ALFF: elastic stiffness tensor calculation","text":"<p><code>alff_elastic</code> is a command-line tool designed to perform the calculation of the elastic stiffness tensor of materials. The following tasks are run automatically without the need for any user intervention:</p> <ul> <li>Build atomic structures</li> <li>Generate DFT/MD codes to optimize atomic structures</li> <li>Submit the optimization jobs to the clusters, monitor the job status, and get back the DFT calcualation results</li> <li>Generate supercells with small deformations.</li> <li>Generate DFT/MD codes to compute atomic forces</li> <li>Compute the elastic stiffness tensor and other elastic-related properties.</li> </ul> <pre><code>alff_elastic PARAM.yaml MACHINE.yaml\n</code></pre> <ul> <li><code>PARAM.yaml</code>: The parameters of the generator.</li> <li><code>MACHINE.yaml</code>: The settings of the machines running the generator's subprocesses.</li> </ul>"},{"location":"alff_gendata/","title":"ALFF: Data generator","text":"<p>To generate labeled data for training ML forcefields, <code>alff_gen</code> is a command-line tool designed to perform the following tasks automatically without needs any user intervention: - Build atomic structures - Generate DFT codes to optimize atomic structures - Submit DFT optimization jobs to the clusters, monitor the job status, and get back the DFT calcualation results - Generate atomic structures by scaling and perturbing the optimized structures - Generate DFT codes to run AIMD simulations - Submit AIMD jobs to the clusters, monitor the job status, and get back the DFT calculation results - Collect the data from the DFT calculations - Convert the data to the format that can ready to used for training ML forcefields.</p> <pre><code>alff_gen PARAM.yaml MACHINE.yaml\n</code></pre> <ul> <li><code>PARAM.yaml</code>: The parameters of the generator.</li> <li><code>MACHINE.yaml</code>: The settings of the machines running the generator's subprocesses.</li> </ul> <p>An example run using <code>alff</code> to generate labeled data:</p> <pre><code>-------------------------------- ALFF --------------------------------\n    Version:  0.1.dev409+g177de1d\n       Path:  C:/conda/envs/py13/Lib/site-packages/alff\n---------------------------- Dependencies ----------------------------\n       numpy  1.26.4       C:/conda/envs/py11/Lib/site-packages/numpy\n       scipy  1.13.0       C:/conda/envs/py11/Lib/site-packages/scipy\n         ase  3.23.1b1     C:/conda/envs/py11/Lib/site-packages/ase\n      polars  1.11.0       C:/conda/envs/py11/Lib/site-packages/polars\n      thutil  0.1.dev122   C:/conda/envs/py11/Lib/site-packages/thutil\n      sevenn  0.10.1       C:/conda/envs/py11/Lib/site-packages/sevenn\n     phonopy  2.29.1       C:/conda/envs/py11/Lib/site-packages/phonopy\n----------------------- Author: C.Thang Nguyen -----------------------\n--------------- Contact: http://thang.eu.org/email ----------------\n\n                             ___    __    ____________\n                            /   |  / /   / ____/ ____/\n                           / /| | / /   / /_  / /_\n                          / ___ |/ /___/ __/ / __/\n                         /_/  |_/_____/_/   /_/\n\nalff-INFO: START GENERATING DATA\nalff-INFO: -------------------- stage_00: build_structure -------------\n The directory `Mo_bulk_bcc_02x02x02` already existed. Select an action: [yes/backup/no]?\n Yes: overwrite the existing directory that continue or update uncompleted tasks.\n Backup: backup the existing directory and perform fresh tasks.\n No: skip and exit.\n        Your answer (y/b/n): y\n        Overwrite the existing directory\nalff-INFO: Working on the path: Mo_bulk_bcc_02x01x01/00_build_structure\nalff-INFO: Build structures from scratch\nalff-INFO: -------------------- stage_01: optimize --------------------\nalff-INFO: Optimize the structures\nalff-INFO: No DFT task is found. Skip the DFT calculation.\nalff-INFO: -------------------- stage_02: scale_perturb ---------------\nalff-INFO: Scaling on the path: Mo_bulk_bcc_02x01x01/01_scale_perturb\nalff-INFO: -------------------- stage_03: run_dft ---------------------\nalff-INFO: Run AIMD calculations\nalff-INFO: Running DFT jobs... be patient\n               Remote host: some_IP_address\n               Remote path: /uwork/user01/work/w24_alff_job\n               Log file: logs/20241020_220540_dispatcher.log\nalff-INFO: Running chunk 1 of 9 chunks (20 of 431 tasks).\nalff-INFO: Running chunk 2 of 9 chunks (20 of 411 tasks). Estimated time: 1 days, 4:39\nalff-INFO: Running chunk 3 of 9 chunks (20 of 391 tasks). Estimated time: 1 days, 3:15\n...\n\nalff-INFO: -------------------- stage_04: collect_data ----------------\nalff-INFO: Collect data on the path: o_bulk_bcc_02x01x01/02_gendata\nalff-INFO: FINISHED !\n</code></pre>"},{"location":"alff_gendata/#parameters","title":"Parameters","text":"<p>The parameters of the generator are stored in a YAML/JSON/JSONC file. Here is an example of the parameters:</p> <pre><code>stages:\n  - build_structure         # build the atomic structures\n  - optimize                # optimize the structure\n  - scale_perturb           # scale and perturb the structure\n  - run_dft                 # run the DFTsinglepoint/AIMD simulation\n  - collect_data            # collect the data\n\nstructure:  # atomic structure information\n  # from_extxyz: [\"path/to/extxyz_file\"]  # list-of-paths to the EXTXYZ files to be used as the initial structure. If provided, the structure will be read from the file, and the other structure parameters will be ignored.\n\n  from_scratch:               # build the structure from scratch\n    structure_type: \"bulk\"    # bulk, molecule, surface,\n    chem_formula: \"W\"         # chemical formula/element. e.g., \"H2O\", \"Mg2O2\", \"Mg\",\n    supercell: [ 2, 2, 2 ]    # size of the supercell\n    pbc: [1, 1, 1]\n    ase_arg:                 # ASE kwargs for building the structure. Accept all ASE arguments.\n      crystalstructure: \"fcc\" # choices: sc,fcc,bcc,tetragonal,bct,hcp,rhombohedral,orthorhombic,mcl,diamond,zincblende,rocksalt,cesiumchloride,fluorite,wurtzite.\n      a: 3.15  # lattice constant\n      # cubic: True\n\n\nscale_perturb:                          # scale and perturb the structure\n  scale_x: [0.9, 0.95, 1.0, 1.05, 1.1]  # scale the structure in x-direction\n  scale_y: [0.9, 0.95, 1.0, 1.05, 1.1]  # scale the structure in y-direction\n  scale_z: [0.9, 0.95, 1.0, 1.05, 1.1]  # scale the structure in z-direction\n  perturb_num: 1                        # number of perturbations on each structure\n  perturb_disp: 0.01                    # stadard deviation of the perturb displacement\n\n\ndft:\n  calc_type: 'aimd'              # choices: 'singlepoint', 'aimd'\n  jobs_per_dispatch: 18         # maximum number of jobs per submission to the cluster\n\n  gpaw_calc:                    # accept GPAW parameters\n    mode:\n      name: 'pw'                # use PlaneWave method energy cutoff in eV\n      ecut: 500\n    xc: \"PBE\"                   # exchange-correlation functional\n    kpts: {\"density\": 6, \"gamma\": False }  # if not set `kpts`, then only Gamma-point is used\n    parallel:\n      sl_auto: True             # enable ScaLAPACK parallelization\n      # use_elpa: True          # enable Elpa eigensolver\n      augment_grids: True       # use all cores for XC/Poisson solver\n\n  optimize:                     # run DFT to optimize the structure\n    fmax: 0.05                  # force convergence criteria\n\n  aimd:                         # run AIMD simulation\n    dt: 1.0                     # time step in fs\n    temperature: 300            # temperature in K\n    ensemble: \"NVE\"             # ensemble type. choices: \"NVE\", \"NVT\"\n    collect_frames: 5           # number of frames to be collected. Then nsteps = collect_frames * traj_freq\n    traj_freq: 1                # dump the frames every `traj_freq` steps\n</code></pre>"},{"location":"alff_gendata/#context-options","title":"Context options","text":"<p>When the output directory already exists, the generator will ask for the user's choice to proceed. The options are: - <code>Yes</code>: overwrite the existing directory and continue. - <code>Backup</code>: backup the existing directory and continue. - <code>No</code>: skip the building process and exit.</p> <p><code>Yes</code>: is recommended. With this option, the generator will - Overwrite and continue in the existing directory - Automatically select the unLABELED configurations to run DFT calculations, avoi running DFT for LABELED configurations. - This is the best way to continue the previous uncomplishness or update some more sampling options.</p>"},{"location":"alff_gendata/#machines","title":"Machines","text":"<p>The settings of the machines running the generator's subprocesses are stored in a YAML/JSON/JSONC file. Here is an example of the machine settings:</p> <pre><code>dft:\n  command: \"mpirun -np $NSLOTS gpaw\"\n\n  machine:\n    batch_type: SGE            # Supported systems: SGE, SLURM, PBS, TORQUE, BASH\n    context_type: SSHContext   # Supported contexts: SSH, Local\n    remote_root: /path/of/project/in/remote/machine\n    remote_profile:\n      hostname: some_IP_address         # address of the remote machine\n      username: little_bird             # username to login the remote machine\n      password: \"123456\"                # password to login the remote machine\n      port: 2022                        # port to connect the remote machine\n      timeout: 20                       # timeout for the SSH connection\n      execute_command: \"ssh cluster\"    # command to execute the SSH connection\n\n  resources:\n    group_size: 1\n    queue_name: \"lion-normal.q\"\n    cpu_per_node: 12\n    kwargs:\n      pe_name: lion-normal\n      job_name: zalff_dft\n    custom_flags:\n      - \"#$ -l h_rt=168:00:00\"\n    module_list:\n      - conda/py11gpaw\n    source_list:\n      - /etc/profile.d/modules.sh\n    envs:\n      OMP_NUM_THREADS: 1\n      OMPI_MCA_btl_openib_allow_ib: 1\n      # OMPI_MCA_btl: ^tcp\n</code></pre>"},{"location":"alff_phonon_calc/","title":"ALFF: phonon calculation","text":"<p><code>alff_phonon</code> is a command-line tool designed to perform the phonon calculation. The following tasks is run automatically without the need for any user intervention:</p> <ul> <li>Build atomic structures</li> <li>Generate DFT/MD codes to optimize atomic structures</li> <li>Submit the optimization jobs to the clusters, monitor the job status, and get back the DFT calcualation results</li> <li>Generate supercells with displacements</li> <li>Generate DFT/MD codes to compute atomic forces</li> <li>Compute the phonon band structure, phonon density of states, and other phonon-related properties.</li> </ul> <pre><code>alff_phonon PARAM.yaml MACHINE.yaml\n</code></pre> <ul> <li><code>PARAM.yaml</code>: The parameters of the generator.</li> <li><code>MACHINE.yaml</code>: The settings of the machines running the generator's subprocesses.</li> </ul> <p>The above <code>alff_phonon</code> command is all needed to obtain, for example, the phonon band structure of Silicon as following figures:</p> <ul> <li>Phonon band structure of bulk Silicon using DFT calculator</li> </ul> <p></p> <ul> <li>Phonon band structure of bulk Silicon using MD calculator with a classical forcefield</li> </ul> <p></p> <p>The results from our calculations are strongly consistent with the reference phonon band structure of Silicon reported in the literature.</p> <pre><code>-------------------------------- ALFF --------------------------------\n    Version:  0.1.dev409+g177de1d\n       Path:  C:/conda/envs/py13/Lib/site-packages/alff\n---------------------------- Dependencies ----------------------------\n       numpy  1.26.4       C:/conda/envs/py11/Lib/site-packages/numpy\n       scipy  1.13.0       C:/conda/envs/py11/Lib/site-packages/scipy\n         ase  3.23.1b1     C:/conda/envs/py11/Lib/site-packages/ase\n      polars  1.11.0       C:/conda/envs/py11/Lib/site-packages/polars\n      thutil  0.1.dev122   C:/conda/envs/py11/Lib/site-packages/thutil\n      sevenn  0.10.1       C:/conda/envs/py11/Lib/site-packages/sevenn\n     phonopy  2.30.0       C:/conda/envs/py11/Lib/site-packages/phonopy\n----------------------- Author: C.Thang Nguyen -----------------------\n--------------- Contact: http://thang.eu.org/email ----------------\n\n                             ___    __    ____________\n                            /   |  / /   / ____/ ____/\n                           / /| | / /   / /_  / /_\n                          / ___ |/ /___/ __/ / __/\n                         /_/  |_/_____/_/   /_/\n\nalff-INFO: START PHONON CALCULATION\nalff-INFO: --------------- stage_00: build_structure ------------------\n The directory `Si_bulk_diamond_01x01x01` already existed. Select an action: [yes/backup/no]?\n Yes: overwrite the existing directory that continue or update uncompleted tasks.\n Backup: backup the existing directory and perform fresh tasks.\n No: skip and exit.\n        Your answer (y/b/n): y\n        Overwrite the existing directory\nalff-INFO: Working on the path: Si_bulk_diamond_01x01x01/00_build_structure\nalff-INFO: Build structures from scratch\nalff-INFO: --------------- stage_01: relax_initial_structure ----------\nalff-INFO: Optimize the structures\nalff-INFO: No DFT task is found. Skip the DFT calculation.\nalff-INFO: --------------- stage_02: scale_and_relax ------------------\nalff-INFO: Relax the scaled structures\nalff-INFO: No task.\nalff-INFO: --------------- stage_03: compute_force --------------------\nalff-INFO: Running DFT jobs... be patient\n               Remote host: some_IP_address\n               Remote path: /uwork/user01/work/w24_alff_job\n               Log file: logs/20241020_220540_dispatcher.log\nalff-INFO: -------------------- stage_04: compute_phonon --------------\nalff-INFO: FINISHED !\n</code></pre>"},{"location":"alff_phonon_calc/#parameters","title":"Parameters","text":"<p>The parameters of the generator are stored in a YAML/JSON/JSONC file. Here is an example of the parameters:</p> <pre><code>stages:\n  - build_structure             # build initial atomic structures\n  - relax_initial_structure     # relax initial structures\n  - scale_and_relax             # scale and relax the structures\n  - compute_force               # compute the force\n  - compute_phonon              # post_process by phonopy\n\nstructure:  # atomic structure information\n  # from_extxyz: [\"path/to/extxyz_file\"]  # list-of-paths to the EXTXYZ files to be used as the initial structure. If provided, the structure will be read from the file, and the other structure parameters will be ignored.\n\n  from_scratch:               # build the structure from scratch\n    structure_type: \"bulk\"    # bulk, molecule, surface,\n    chem_formula: \"Si\"        # chemical formula/element. e.g., \"H2O\", \"Mg2O2\", \"Mg\",\n    pbc: [1, 1, 1]\n    ase_arg:\n      crystalstructure: \"diamond\"\n      a: 5.43\n\n# scale:                # scale and perturb the structure\n#   scale_x: [0.5,1.5]  # scale the structure in x-direction\n#   # scale_y: [0.700]  # scale the structure in y-direction\n#   # scale_z: [0.700, 0.800] # scale the structure in z-direction\n\n\nphonon:                           # phonon calculation\n  supercell_matrix: [2, 2, 2]     # 1x3 array\n  displacement: 0.03              # small displacement in Angstrom\n  phonopy_arg:                   # Accept all the phonopy parameters\n    is_symmetry: True            # use symmetry\n    symprec: 1e-5                # symmetry precision\n  #   nac: False                   # non-analytical correction\n\n  compute:                      # properties need to compute from the phonon calculation\n    mesh: [20, 20, 20]          # Set sampling mesh (set_mesh) in reciprocal space\n    band_structure:              # phonon band structure\n      path_str: 'auto'          # 'GXU,KGLWX' or 'auto' or None   # k-path for band structure. Choices: input_str, 'auto', None. If not set (None), k-path is genrated using `ase`. If set 'auto', k-path is generated using `seekpath`.\n      npoints: 50            # number of k-points\n    dos: True                     # phonon density of states\n    pdos: True                    # phonon projected density of states\n    thermal_properties:           # phonon thermal properties\n      t_min: 0.0                  # minimum temperature\n      t_max: 1000.0               # maximum temperature\n      t_step: 10.0                # temperature step\n\n\ncalculator: \"lammps\"        # choices: 'lammps', 'gpaw'. Calculator to calculate atomic forces. Default: 'lammps'\nrelax_supercell: True     # relax the initial structure using the supercell. Default: False. This is useful when compute with clssical MD, which can avoid the PBC effect.\n\n# dft:                      # parameters for DFT calculation\n#   gpaw_calc:               # accept GPAW parameters\n#     mode:\n#       name: 'pw'          # use PlaneWave method energy cutoff in eV\n#       ecut: 500\n#     xc: \"PBE\"             # exchange-correlation functional\n#     kpts: {\"density\": 6, \"gamma\": False}  # if not set `kpts`, then only Gamma-point is used\n\n#   optimize:               # parameter to optimize the structure by DFT/MS (relax_type: 'opt')\n#     fmax: 0.02            # force convergence criteria\n\nmd:                         # parameters for MD calculation\n  file_potentials: [\"SiC.tersoff\"]  # path to the potential file\n\n  lammps_arg:               # accept LAMMPS parameters\n    pair_style: [\"tersoff\"]   # LAMMPS pair_style\n    pair_coeff: [\"* * ../SiC.tersoff Si\"]  # LAMMPS pair_coeff, don't input atom names here\n\n  minimize:                 # parameter to minimize the structure by MD (relax_type: 'min')\n    ftol: 1e-12              # force convergence criteria\n    etol: 0                 # energy convergence criteria\n    # dmax: 0.001             # maximum distance for line search to move (distance units). Default: 0.01\n</code></pre>"},{"location":"alff_phonon_calc/#context-options","title":"Context options","text":"<p>When the output directory already exists, the generator will ask for the user's choice to proceed. The options are:</p> <ul> <li><code>Yes</code>: overwrite the existing directory and continue.</li> <li><code>Backup</code>: backup the existing directory and continue.</li> <li><code>No</code>: skip the building process and exit.</li> </ul> <p><code>Yes</code>: is recommended. With this option, the generator will</p> <ul> <li>Overwrite and continue in the existing directory</li> <li>Automatically select the unLABELED configurations to run DFT calculations, avoi running DFT for LABELED configurations.</li> <li>This is the best way to continue the previous uncomplishness or update some more sampling options.</li> </ul>"},{"location":"alff_phonon_calc/#machines","title":"Machines","text":"<p>The settings of the machines running the generator's subprocesses are stored in a YAML/JSON/JSONC file. Here is an example of the machine settings:</p> <pre><code>dft:\n  command: \"mpirun -np $NSLOTS gpaw\"\n\n  machine:\n    batch_type: SGE            # Supported systems: SGE, SLURM, PBS, TORQUE, BASH\n    context_type: SSHContext   # Supported contexts: SSH, Local\n    remote_root: /path/of/project/in/remote/machine\n    remote_profile:\n      hostname: some_IP_address         # address of the remote machine\n      username: little_bird             # username to login the remote machine\n      password: \"123456\"                # password to login the remote machine\n      port: 2022                        # port to connect the remote machine\n      timeout: 20                       # timeout for the SSH connection\n      execute_command: \"ssh cluster\"    # command to execute the SSH connection\n\n  resources:\n    group_size: 1\n    queue_name: \"lion-normal.q\"\n    cpu_per_node: 12\n    kwargs:\n      pe_name: lion-normal\n      job_name: zalff_dft\n    custom_flags:\n      - \"#$ -l h_rt=168:00:00\"\n    module_list:\n      - conda/py11gpaw\n    source_list:\n      - /etc/profile.d/modules.sh\n    envs:\n      OMP_NUM_THREADS: 1\n      OMPI_MCA_btl_openib_allow_ib: 1\n      # OMPI_MCA_btl: ^tcp\n</code></pre>"},{"location":"mace_train_param/","title":"MACE train","text":""},{"location":"mace_train_param/#mace-parameters-for-training","title":"MACE parameters for training","text":"<p>See more development parameters here.</p>"},{"location":"mace_train_param/#name-and-seed","title":"Name and seed","text":"<pre><code>    parser.add_argument(\"--name\", help=\"experiment name\", required=True)\n    parser.add_argument(\"--seed\", help=\"random seed\", type=int, default=123)\n</code></pre>"},{"location":"mace_train_param/#directories","title":"Directories","text":"<pre><code>    parser.add_argument(\n        \"--work_dir\",\n        help=\"set directory for all files and folders\",\n        type=str,\n        default=\".\",\n    )\n    parser.add_argument(\n        \"--log_dir\", help=\"directory for log files\", type=str, default=None\n    )\n    parser.add_argument(\n        \"--model_dir\", help=\"directory for final model\", type=str, default=None\n    )\n    parser.add_argument(\n        \"--checkpoints_dir\",\n        help=\"directory for checkpoint files\",\n        type=str,\n        default=None,\n    )\n    parser.add_argument(\n        \"--results_dir\", help=\"directory for results\", type=str, default=None\n    )\n    parser.add_argument(\n        \"--downloads_dir\", help=\"directory for downloads\", type=str, default=None\n    )\n\n    ## Device and logging\n    parser.add_argument(\n        \"--device\",\n        help=\"select device\",\n        type=str,\n        choices=[\"cpu\", \"cuda\", \"mps\", \"xpu\"],\n        default=\"cpu\",\n    )\n    parser.add_argument(\n        \"--default_dtype\",\n        help=\"set default dtype\",\n        type=str,\n        choices=[\"float32\", \"float64\"],\n        default=\"float64\",\n    )\n    parser.add_argument(\n        \"--distributed\",\n        help=\"train in multi-GPU data parallel mode\",\n        action=\"store_true\",\n        default=False,\n    )\n    parser.add_argument(\"--log_level\", help=\"log level\", type=str, default=\"INFO\")\n\n    parser.add_argument(\n        \"--error_table\",\n        help=\"Type of error table produced at the end of the training\",\n        type=str,\n        choices=[\n            \"PerAtomRMSE\",\n            \"TotalRMSE\",\n            \"PerAtomRMSEstressvirials\",\n            \"PerAtomMAEstressvirials\",\n            \"PerAtomMAE\",\n            \"TotalMAE\",\n            \"DipoleRMSE\",\n            \"DipoleMAE\",\n            \"EnergyDipoleRMSE\",\n        ],\n        default=\"PerAtomRMSE\",\n    )\n</code></pre>"},{"location":"mace_train_param/#model","title":"Model","text":"<pre><code>    parser.add_argument(\n        \"--model\",\n        help=\"model type\",\n        default=\"MACE\",\n        choices=[\n            \"BOTNet\",\n            \"MACE\",\n            \"ScaleShiftMACE\",\n            \"ScaleShiftBOTNet\",\n            \"AtomicDipolesMACE\",\n            \"EnergyDipolesMACE\",\n        ],\n    )\n    parser.add_argument(\n        \"--r_max\", help=\"distance cutoff (in Ang)\", type=float, default=5.0\n    )\n    parser.add_argument(\n        \"--radial_type\",\n        help=\"type of radial basis functions\",\n        type=str,\n        default=\"bessel\",\n        choices=[\"bessel\", \"gaussian\", \"chebyshev\"],\n    )\n    parser.add_argument(\n        \"--num_radial_basis\",\n        help=\"number of radial basis functions\",\n        type=int,\n        default=8,\n    )\n    parser.add_argument(\n        \"--num_cutoff_basis\",\n        help=\"number of basis functions for smooth cutoff\",\n        type=int,\n        default=5,\n    )\n    parser.add_argument(\n        \"--pair_repulsion\",\n        help=\"use pair repulsion term with ZBL potential\",\n        action=\"store_true\",\n        default=False,\n    )\n    parser.add_argument(\n        \"--distance_transform\",\n        help=\"use distance transform for radial basis functions\",\n        default=\"None\",\n        choices=[\"None\", \"Agnesi\", \"Soft\"],\n    )\n    parser.add_argument(\n        \"--interaction\",\n        help=\"name of interaction block\",\n        type=str,\n        default=\"RealAgnosticResidualInteractionBlock\",\n        choices=[\n            \"RealAgnosticResidualInteractionBlock\",\n            \"RealAgnosticAttResidualInteractionBlock\",\n            \"RealAgnosticInteractionBlock\",\n        ],\n    )\n    parser.add_argument(\n        \"--interaction_first\",\n        help=\"name of interaction block\",\n        type=str,\n        default=\"RealAgnosticResidualInteractionBlock\",\n        choices=[\n            \"RealAgnosticResidualInteractionBlock\",\n            \"RealAgnosticInteractionBlock\",\n        ],\n    )\n    parser.add_argument(\n        \"--max_ell\", help=r\"highest \\ell of spherical harmonics\", type=int, default=3\n    )\n    parser.add_argument(\n        \"--correlation\", help=\"correlation order at each layer\", type=int, default=3\n    )\n    parser.add_argument(\n        \"--num_interactions\", help=\"number of interactions\", type=int, default=2\n    )\n    parser.add_argument(\n        \"--MLP_irreps\",\n        help=\"hidden irreps of the MLP in last readout\",\n        type=str,\n        default=\"16x0e\",\n    )\n    parser.add_argument(\n        \"--radial_MLP\",\n        help=\"width of the radial MLP\",\n        type=str,\n        default=\"[64, 64, 64]\",\n    )\n    parser.add_argument(\n        \"--hidden_irreps\",\n        help=\"irreps for hidden node states\",\n        type=str,\n        default=None,\n    )\n    ## add option to specify irreps by channel number and max L\n    parser.add_argument(\n        \"--num_channels\",\n        help=\"number of embedding channels\",\n        type=int,\n        default=None,\n    )\n    parser.add_argument(\n        \"--max_L\",\n        help=\"max L equivariance of the message\",\n        type=int,\n        default=None,\n    )\n    parser.add_argument(\n        \"--gate\",\n        help=\"non linearity for last readout\",\n        type=str,\n        default=\"silu\",\n        choices=[\"silu\", \"tanh\", \"abs\", \"None\"],\n    )\n    parser.add_argument(\n        \"--scaling\",\n        help=\"type of scaling to the output\",\n        type=str,\n        default=\"rms_forces_scaling\",\n        choices=[\"std_scaling\", \"rms_forces_scaling\", \"no_scaling\"],\n    )\n    parser.add_argument(\n        \"--avg_num_neighbors\",\n        help=\"normalization factor for the message\",\n        type=float,\n        default=1,\n    )\n    parser.add_argument(\n        \"--compute_avg_num_neighbors\",\n        help=\"normalization factor for the message\",\n        type=str2bool,\n        default=True,\n    )\n    parser.add_argument(\n        \"--compute_stress\",\n        help=\"Select True to compute stress\",\n        type=str2bool,\n        default=False,\n    )\n    parser.add_argument(\n        \"--compute_forces\",\n        help=\"Select True to compute forces\",\n        type=str2bool,\n        default=True,\n    )\n</code></pre>"},{"location":"mace_train_param/#dataset","title":"Dataset","text":"<pre><code>    parser.add_argument(\n        \"--train_file\",\n        help=\"Training set file, format is .xyz or .h5\",\n        type=str,\n        required=False,\n    )\n    parser.add_argument(\n        \"--valid_file\",\n        help=\"Validation set .xyz or .h5 file\",\n        default=None,\n        type=str,\n        required=False,\n    )\n    parser.add_argument(\n        \"--valid_fraction\",\n        help=\"Fraction of training set used for validation\",\n        type=float,\n        default=0.1,\n        required=False,\n    )\n    parser.add_argument(\n        \"--test_file\",\n        help=\"Test set .xyz pt .h5 file\",\n        type=str,\n    )\n    parser.add_argument(\n        \"--test_dir\",\n        help=\"Path to directory with test files named as test_*.h5\",\n        type=str,\n        default=None,\n        required=False,\n    )\n    parser.add_argument(\n        \"--multi_processed_test\",\n        help=\"Boolean value for whether the test data was multiprocessed\",\n        type=str2bool,\n        default=False,\n        required=False,\n    )\n    parser.add_argument(\n        \"--num_workers\",\n        help=\"Number of workers for data loading\",\n        type=int,\n        default=0,\n    )\n    parser.add_argument(\n        \"--pin_memory\",\n        help=\"Pin memory for data loading\",\n        default=True,\n        type=str2bool,\n    )\n    parser.add_argument(\n        \"--atomic_numbers\",\n        help=\"List of atomic numbers\",\n        type=str,\n        default=None,\n        required=False,\n    )\n    parser.add_argument(\n        \"--mean\",\n        help=\"Mean energy per atom of training set\",\n        type=float,\n        default=None,\n        required=False,\n    )\n    parser.add_argument(\n        \"--std\",\n        help=\"Standard deviation of force components in the training set\",\n        type=float,\n        default=None,\n        required=False,\n    )\n    parser.add_argument(\n        \"--statistics_file\",\n        help=\"json file containing statistics of training set\",\n        type=str,\n        default=None,\n        required=False,\n    )\n    parser.add_argument(\n        \"--E0s\",\n        help=\"Dictionary of isolated atom energies\",\n        type=str,\n        default=None,\n        required=False,\n    )\n\n\n\n    ## Keys\n    parser.add_argument(\n        \"--energy_key\",\n        help=\"Key of reference energies in training xyz\",\n        type=str,\n        default=\"REF_energy\",\n    )\n    parser.add_argument(\n        \"--forces_key\",\n        help=\"Key of reference forces in training xyz\",\n        type=str,\n        default=\"REF_forces\",\n    )\n    parser.add_argument(\n        \"--virials_key\",\n        help=\"Key of reference virials in training xyz\",\n        type=str,\n        default=\"REF_virials\",\n    )\n    parser.add_argument(\n        \"--stress_key\",\n        help=\"Key of reference stress in training xyz\",\n        type=str,\n        default=\"REF_stress\",\n    )\n    parser.add_argument(\n        \"--dipole_key\",\n        help=\"Key of reference dipoles in training xyz\",\n        type=str,\n        default=\"REF_dipole\",\n    )\n    parser.add_argument(\n        \"--charges_key\",\n        help=\"Key of atomic charges in training xyz\",\n        type=str,\n        default=\"REF_charges\",\n    )\n</code></pre>"},{"location":"mace_train_param/#fine-tuning","title":"Fine-tuning","text":"<pre><code>    parser.add_argument(\n        \"--foundation_filter_elements\",\n        help=\"Filter element during fine-tuning\",\n        type=str2bool,\n        default=True,\n        required=False,\n    )\n    parser.add_argument(\n        \"--heads\",\n        help=\"Dict of heads: containing individual files and E0s\",\n        type=str,\n        default=None,\n        required=False,\n    )\n    parser.add_argument(\n        \"--multiheads_finetuning\",\n        help=\"Boolean value for whether the model is multiheaded\",\n        type=str2bool,\n        default=True,\n    )\n    parser.add_argument(\n        \"--weight_pt_head\",\n        help=\"Weight of the pretrained head in the loss function\",\n        type=float,\n        default=1.0,\n    )\n    parser.add_argument(\n        \"--num_samples_pt\",\n        help=\"Number of samples in the pretrained head\",\n        type=int,\n        default=1000,\n    )\n    parser.add_argument(\n        \"--subselect_pt\",\n        help=\"Method to subselect the configurations of the pretraining set\",\n        choices=[\"fps\", \"random\"],\n        default=\"random\",\n    )\n    parser.add_argument(\n        \"--pt_train_file\",\n        help=\"Training set file for the pretrained head\",\n        type=str,\n        default=None,\n    )\n    parser.add_argument(\n        \"--pt_valid_file\",\n        help=\"Validation set file for the pretrained head\",\n        type=str,\n        default=None,\n    )\n    parser.add_argument(\n        \"--keep_isolated_atoms\",\n        help=\"Keep isolated atoms in the dataset, useful for transfer learning\",\n        type=str2bool,\n        default=False,\n    )\n</code></pre>"},{"location":"mace_train_param/#loss-and-optimization","title":"Loss and optimization","text":"<pre><code>    parser.add_argument(\n        \"--loss\",\n        help=\"type of loss\",\n        default=\"weighted\",\n        choices=[\n            \"ef\",\n            \"weighted\",\n            \"forces_only\",\n            \"virials\",\n            \"stress\",\n            \"dipole\",\n            \"huber\",\n            \"universal\",\n            \"energy_forces_dipole\",\n        ],\n    )\n    parser.add_argument(\n        \"--forces_weight\", help=\"weight of forces loss\", type=float, default=100.0\n    )\n    parser.add_argument(\n        \"--swa_forces_weight\",\n        \"--stage_two_forces_weight\",\n        help=\"weight of forces loss after starting Stage Two (previously called swa)\",\n        type=float,\n        default=100.0,\n        dest=\"swa_forces_weight\",\n    )\n    parser.add_argument(\n        \"--energy_weight\", help=\"weight of energy loss\", type=float, default=1.0\n    )\n    parser.add_argument(\n        \"--swa_energy_weight\",\n        \"--stage_two_energy_weight\",\n        help=\"weight of energy loss after starting Stage Two (previously called swa)\",\n        type=float,\n        default=1000.0,\n        dest=\"swa_energy_weight\",\n    )\n    parser.add_argument(\n        \"--virials_weight\", help=\"weight of virials loss\", type=float, default=1.0\n    )\n    parser.add_argument(\n        \"--swa_virials_weight\",\n        \"--stage_two_virials_weight\",\n        help=\"weight of virials loss after starting Stage Two (previously called swa)\",\n        type=float,\n        default=10.0,\n        dest=\"swa_virials_weight\",\n    )\n    parser.add_argument(\n        \"--stress_weight\", help=\"weight of virials loss\", type=float, default=1.0\n    )\n    parser.add_argument(\n        \"--swa_stress_weight\",\n        \"--stage_two_stress_weight\",\n        help=\"weight of stress loss after starting Stage Two (previously called swa)\",\n        type=float,\n        default=10.0,\n        dest=\"swa_stress_weight\",\n    )\n    parser.add_argument(\n        \"--dipole_weight\", help=\"weight of dipoles loss\", type=float, default=1.0\n    )\n    parser.add_argument(\n        \"--swa_dipole_weight\",\n        \"--stage_two_dipole_weight\",\n        help=\"weight of dipoles after starting Stage Two (previously called swa)\",\n        type=float,\n        default=1.0,\n        dest=\"swa_dipole_weight\",\n    )\n    parser.add_argument(\n        \"--config_type_weights\",\n        help=\"String of dictionary containing the weights for each config type\",\n        type=str,\n        default='{\"Default\":1.0}',\n    )\n    parser.add_argument(\n        \"--huber_delta\",\n        help=\"delta parameter for huber loss\",\n        type=float,\n        default=0.01,\n    )\n    parser.add_argument(\n        \"--optimizer\",\n        help=\"Optimizer for parameter optimization\",\n        type=str,\n        default=\"adam\",\n        choices=[\"adam\", \"adamw\", \"schedulefree\"],\n    )\n    parser.add_argument(\n        \"--beta\",\n        help=\"Beta parameter for the optimizer\",\n        type=float,\n        default=0.9,\n    )\n    parser.add_argument(\"--batch_size\", help=\"batch size\", type=int, default=10)\n    parser.add_argument(\n        \"--valid_batch_size\", help=\"Validation batch size\", type=int, default=10\n    )\n    parser.add_argument(\n        \"--lr\", help=\"Learning rate of optimizer\", type=float, default=0.01\n    )\n    parser.add_argument(\n        \"--swa_lr\",\n        \"--stage_two_lr\",\n        help=\"Learning rate of optimizer in Stage Two (previously called swa)\",\n        type=float,\n        default=1e-3,\n        dest=\"swa_lr\",\n    )\n    parser.add_argument(\n        \"--weight_decay\", help=\"weight decay (L2 penalty)\", type=float, default=5e-7\n    )\n    parser.add_argument(\n        \"--amsgrad\",\n        help=\"use amsgrad variant of optimizer\",\n        action=\"store_true\",\n        default=True,\n    )\n    parser.add_argument(\n        \"--scheduler\", help=\"Type of scheduler\", type=str, default=\"ReduceLROnPlateau\"\n    )\n    parser.add_argument(\n        \"--lr_factor\", help=\"Learning rate factor\", type=float, default=0.8\n    )\n    parser.add_argument(\n        \"--scheduler_patience\", help=\"Learning rate factor\", type=int, default=50\n    )\n    parser.add_argument(\n        \"--lr_scheduler_gamma\",\n        help=\"Gamma of learning rate scheduler\",\n        type=float,\n        default=0.9993,\n    )\n    parser.add_argument(\n        \"--swa\",\n        \"--stage_two\",\n        help=\"use Stage Two loss weight, which decreases the learning rate and increases the energy weight at the end of the training to help converge them\",\n        action=\"store_true\",\n        default=False,\n        dest=\"swa\",\n    )\n    parser.add_argument(\n        \"--start_swa\",\n        \"--start_stage_two\",\n        help=\"Number of epochs before changing to Stage Two loss weights\",\n        type=int,\n        default=None,\n        dest=\"start_swa\",\n    )\n    parser.add_argument(\n        \"--ema\",\n        help=\"use Exponential Moving Average\",\n        action=\"store_true\",\n        default=False,\n    )\n    parser.add_argument(\n        \"--ema_decay\",\n        help=\"Exponential Moving Average decay\",\n        type=float,\n        default=0.99,\n    )\n    parser.add_argument(\n        \"--max_num_epochs\", help=\"Maximum number of epochs\", type=int, default=2048\n    )\n    parser.add_argument(\n        \"--patience\",\n        help=\"Maximum number of consecutive epochs of increasing loss\",\n        type=int,\n        default=2048,\n    )\n    parser.add_argument(\n        \"--foundation_model\",\n        help=\"Path to the foundation model for transfer learning\",\n        type=str,\n        default=None,\n    )\n    parser.add_argument(\n        \"--foundation_model_readout\",\n        help=\"Use readout of foundation model for transfer learning\",\n        action=\"store_false\",\n        default=True,\n    )\n    parser.add_argument(\n        \"--eval_interval\", help=\"evaluate model every &lt;n&gt; epochs\", type=int, default=1\n    )\n    parser.add_argument(\n        \"--keep_checkpoints\",\n        help=\"keep all checkpoints\",\n        action=\"store_true\",\n        default=False,\n    )\n    parser.add_argument(\n        \"--save_all_checkpoints\",\n        help=\"save all checkpoints\",\n        action=\"store_true\",\n        default=False,\n    )\n    parser.add_argument(\n        \"--restart_latest\",\n        help=\"restart optimizer from latest checkpoint\",\n        action=\"store_true\",\n        default=False,\n    )\n    parser.add_argument(\n        \"--save_cpu\",\n        help=\"Save a model to be loaded on cpu\",\n        action=\"store_true\",\n        default=False,\n    )\n    parser.add_argument(\n        \"--clip_grad\",\n        help=\"Gradient Clipping Value\",\n        type=check_float_or_none,\n        default=10.0,\n    )\n    ## options for using Weights and Biases for experiment tracking\n    ## to install see https://wandb.ai\n    parser.add_argument(\n        \"--wandb\",\n        help=\"Use Weights and Biases for experiment tracking\",\n        action=\"store_true\",\n        default=False,\n    )\n    parser.add_argument(\n        \"--wandb_dir\",\n        help=\"An absolute path to a directory where Weights and Biases metadata will be stored\",\n        type=str,\n        default=None,\n    )\n    parser.add_argument(\n        \"--wandb_project\",\n        help=\"Weights and Biases project name\",\n        type=str,\n        default=\"\",\n    )\n    parser.add_argument(\n        \"--wandb_entity\",\n        help=\"Weights and Biases entity name\",\n        type=str,\n        default=\"\",\n    )\n    parser.add_argument(\n        \"--wandb_name\",\n        help=\"Weights and Biases experiment name\",\n        type=str,\n        default=\"\",\n    )\n    parser.add_argument(\n        \"--wandb_log_hypers\",\n        help=\"The hyperparameters to log in Weights and Biases\",\n        type=list,\n        default=[\n            \"num_channels\",\n            \"max_L\",\n            \"correlation\",\n            \"lr\",\n            \"swa_lr\",\n            \"weight_decay\",\n            \"batch_size\",\n            \"max_num_epochs\",\n            \"start_swa\",\n            \"energy_weight\",\n            \"forces_weight\",\n        ],\n    )\n    return parser\n</code></pre>"},{"location":"sevenn_train_param/","title":"SevenNet parameters for training model","text":"<p>There are preset parameters:</p> <ul> <li>base</li> <li>fine_tune</li> <li>sevennet-0</li> </ul> <p>See full full development parameters here.</p> <p>To access energy, force, and stress, in <code>extxyz</code> dataset, the following keys are used: <pre><code>data:\n    data_format_args:\n        energy_key: 'TotEnergy'\n        force_key: 'force'\n        stress_key: 'stress'\n</code></pre></p>"},{"location":"sevenn_train_param/#base","title":"base","text":"<pre><code># Example input.yaml for training SevenNet.\n# '*' signifies default. You can check log.sevenn for defaults.\n\nmodel:\n    chemical_species: 'Auto'                      # Chemical elements present in the dataset, guess them from load_dataset data if 'auto'\n    cutoff: 5.0                                   # Cutoff radius in Angstroms. If two atoms are within the cutoff, they are connected.\n    channel: 32                                   # The multiplicity(channel) of node features.\n    lmax: 2                                       # Maximum order of irreducible representations (rotation order).\n    num_convolution_layer: 3                      # The number of message passing layers.\n\n    #irreps_manual:                               # Manually set irreps of the model in each layer\n        #- \"128x0e\"\n        #- \"128x0e+64x1e+32x2e\"\n        #- \"128x0e+64x1e+32x2e\"\n        #- \"128x0e+64x1e+32x2e\"\n        #- \"128x0e+64x1e+32x2e\"\n        #- \"128x0e\"\n\n    weight_nn_hidden_neurons: [64, 64]            # Hidden neurons in convolution weight neural network\n    radial_basis:                                 # Function and its parameters to encode radial distance\n        radial_basis_name: 'bessel'               # Only 'bessel' is currently supported\n        bessel_basis_num: 8\n    cutoff_function:                              # Envelop function, multiplied to radial_basis functions to init edge featrues\n        cutoff_function_name: 'poly_cut'          # {'poly_cut' and 'poly_cut_p_value'} or {'XPLOR' and 'cutoff_on'}\n        poly_cut_p_value: 6\n\n    act_gate: {'e': 'silu', 'o': 'tanh'}          # Equivalent to 'nonlinearity_gates' in nequip\n    act_scalar: {'e': 'silu', 'o': 'tanh'}        # Equivalent to 'nonlinearity_scalars' in nequip\n\n    is_parity: False                              # Pairy True (E(3) group) or False (to SE(3) group)\n\n    self_connection_type: 'nequip'                # Default is 'nequip'. 'linear' is used for SevenNet-0.\n\n    conv_denominator: \"avg_num_neigh\"             # Valid options are \"avg_num_neigh*\", \"sqrt_avg_num_neigh\", or float\n    train_denominator: False                      # Enable training for denominator in convolution layer\n    train_shift_scale: False                      # Enable training for shift &amp; scale in output layer\n\ntrain:\n    random_seed: 1\n    is_train_stress: True                         # Includes stress in the loss function\n    epoch: 200                                    # Ends training after this number of epochs\n\n    #loss: 'Huber'                                # Default is 'mse' (mean squared error)\n    #loss_param:\n        #delta: 0.01\n\n    # Each optimizer and scheduler have different available parameters.\n    # You can refer to sevenn/train/optim.py for supporting optimizer &amp; schedulers\n    optimizer: 'adam'                             # Options available are 'sgd', 'adagrad', 'adam', 'adamw', 'radam'\n    optim_param:\n        lr: 0.005\n    scheduler: 'exponentiallr'                    # 'steplr', 'multisteplr', 'exponentiallr', 'cosineannealinglr', 'reducelronplateau', 'linearlr'\n    scheduler_param:\n        gamma: 0.99\n\n    force_loss_weight: 0.1                        # Coefficient for force loss\n    stress_loss_weight: 1e-06                     # Coefficient for stress loss (to kbar unit)\n\n    per_epoch: 10                                 # Generate checkpoints every this epoch\n\n    # ['target y', 'metric']\n    # Target y: TotalEnergy, Energy, Force, Stress, Stress_GPa, TotalLoss\n    # Metric  : RMSE, MAE, or Loss\n    error_record:\n        - ['Energy', 'RMSE']\n        - ['Force', 'RMSE']\n        - ['Stress', 'RMSE']\n        - ['TotalLoss', 'None']\n\n    # Continue training model from given checkpoint, or pre-trained model checkpoint for fine-tuning\n    #continue:\n        #checkpoint: 'checkpoint_best.pth'         # Checkpoint of pre-trained model or a model want to continue training.\n        #reset_optimizer: False                    # Set True for fine-tuning\n        #reset_scheduler: False                    # Set True for fine-tuning\n        #use_statistic_values_of_checkpoint: False # Set True to use shift, scale, and avg_num_neigh from checkpoint or not\n\ndata:\n    batch_size: 4                                 # Per GPU batch size.\n    data_divide_ratio: 0.1                        # Split dataset into training and validation sets by this ratio\n\n    shift: 'per_atom_energy_mean'                 # One of 'per_atom_energy_mean*', 'elemwise_reference_energies', float\n    scale: 'force_rms'                            # One of 'force_rms*', 'per_atom_energy_std', 'elemwise_force_rms', float\n\n    # ase.io.read readable data files or structure_list or .sevenn_data files can be used as dataset.\n    # .sevenn_data is preprocessed data set has edges connected (can be obtained by using sevenn_graph_build or by save_** options below)\n    data_format: 'ase'                            # One of 'ase', 'structure_list' (.sevenn_data is always readable)\n    data_format_args:                             # if `data_format` is `ase`, args will be passed to `ase.io.read`\n        index: ':'                                # see `https://wiki.fysik.dtu.dk/ase/ase/io/io.html` for more valid arguments\n\n    # If only load_dataset_path is provided, train/valid set is automatically decided by splitting dataset by divide ratio\n    # If both load_dataset_path &amp; load_validset_path is provided, use load_dataset_path as training set.\n    load_dataset_path: ['../data/train.extxyz']   # Example of using ase as data_format, support multiple datasets and expansion(*)\n    #load_validset_path: ['./valid.sevenn_data']\n\n    #save_dataset_path: './total'                 # Save the preprocessed (in load_dataset_path) dataset\n    #save_by_train_valid: True                    # Save the preprocessed train.sevenn_data, valid.sevenn_data\n</code></pre>"},{"location":"sevenn_train_param/#fine_tune","title":"fine_tune","text":"<pre><code># Example input.yaml for fine-tuning sevennet-0\n# '*' signifies default. You can check log.sevenn for defaults.\n\nmodel:  # model keys should be consistent except for train_* keys\n    chemical_species: 'Auto'\n    cutoff: 5.0\n    channel: 128\n    is_parity: False\n    lmax: 2\n    num_convolution_layer: 5\n    irreps_manual:\n        - \"128x0e\"\n        - \"128x0e+64x1e+32x2e\"\n        - \"128x0e+64x1e+32x2e\"\n        - \"128x0e+64x1e+32x2e\"\n        - \"128x0e+64x1e+32x2e\"\n        - \"128x0e\"\n\n    weight_nn_hidden_neurons: [64, 64]\n    radial_basis:\n        radial_basis_name: 'bessel'\n        bessel_basis_num: 8\n    cutoff_function:\n        cutoff_function_name: 'XPLOR'\n        cutoff_on: 4.5\n    self_connection_type: 'linear'\n\n    train_shift_scale: False   # customizable (True | False)\n    train_denominator: False   # customizable (True | False)\n\ntrain:  # Customizable\n    random_seed: 1\n    is_train_stress: True\n    epoch: 100\n\n    optimizer: 'adam'\n    optim_param:\n        lr: 0.004\n    scheduler: 'exponentiallr'\n    scheduler_param:\n        gamma: 0.99\n\n    force_loss_weight: 0.1\n    stress_loss_weight: 1e-06\n\n    per_epoch: 10  # Generate checkpoints every this epoch\n\n    # ['target y', 'metric']\n    # Target y: TotalEnergy, Energy, Force, Stress, Stress_GPa, TotalLoss\n    # Metric  : RMSE, MAE, or Loss\n    error_record:\n        - ['Energy', 'RMSE']\n        - ['Force', 'RMSE']\n        - ['Stress', 'RMSE']\n        - ['TotalLoss', 'None']\n\n    continue:\n        reset_optimizer: True\n        reset_scheduler: True\n        reset_epoch: True\n        checkpoint: 'SevenNet-0_11July2024'\n        # Set True to use shift, scale, and avg_num_neigh from checkpoint (highly recommended)\n        use_statistic_values_of_checkpoint: True\n\ndata:  # Customizable\n    batch_size: 4\n    data_divide_ratio: 0.1\n\n    # ase.io.read readable data files or structure_list or .sevenn_data files can be used as dataset.\n    # .sevenn_data is preprocessed data set has edges connected (can be obtained by using sevenn_graph_build or by save_** options below)\n    data_format: 'ase'                            # One of 'ase', 'structure_list' (.sevenn_data is always readable)\n    data_format_args:                             # if `data_format` is `ase`, args will be passed to `ase.io.read`\n        index: ':'                                # see `https://wiki.fysik.dtu.dk/ase/ase/io/io.html` for more valid arguments\n\n    # If only load_dataset_path is provided, train/valid set is automatically decided by splitting dataset by divide ratio\n    # If both load_dataset_path &amp; load_validset_path is provided, use load_dataset_path as training set.\n    load_dataset_path: ['fine_tune.extxyz']       # Support multiple files and expansion(*)\n    #load_validset_path: ['./valid.sevenn_data']\n\n    #save_dataset_path: './total'                 # Save the preprocessed (in load_dataset_path) dataset\n    #save_by_train_valid: True                    # Save the preprocessed train.sevenn_data, valid.sevenn_data\n</code></pre>"},{"location":"sevenn_train_param/#sevennet-0","title":"sevennet-0","text":"<pre><code># SevenNet-0\nmodel:\n    chemical_species: 'auto'\n    cutoff: 5.0\n    channel: 128\n    is_parity: False\n    lmax: 2\n    num_convolution_layer: 5\n    irreps_manual:\n        - \"128x0e\"\n        - \"128x0e+64x1e+32x2e\"\n        - \"128x0e+64x1e+32x2e\"\n        - \"128x0e+64x1e+32x2e\"\n        - \"128x0e+64x1e+32x2e\"\n        - \"128x0e\"\n\n    weight_nn_hidden_neurons: [64, 64]\n    radial_basis:\n        radial_basis_name: 'bessel'\n        bessel_basis_num: 8\n    cutoff_function:\n        cutoff_function_name: 'XPLOR'\n        cutoff_on: 4.5\n\n    act_gate: {'e': 'silu', 'o': 'tanh'}\n    act_scalar: {'e': 'silu', 'o': 'tanh'}\n\n    conv_denominator: 'avg_num_neigh'\n    train_shift_scale: False\n    train_denominator: False\n    self_connection_type: 'linear'\ntrain:\n    train_shuffle: False\n    random_seed: 1\n    is_train_stress : True\n    epoch: 600\n\n    loss: 'Huber'\n    loss_param:\n        delta: 0.01\n\n    optimizer: 'adam'\n    optim_param:\n        lr: 0.01\n    scheduler: 'linearlr'\n    scheduler_param:\n        start_factor: 1.0\n        total_iters: 600\n        end_factor: 0.0001\n\n    force_loss_weight : 1.00\n    stress_loss_weight: 0.01\n\n    error_record:\n        - ['Energy', 'RMSE']\n        - ['Force', 'RMSE']\n        - ['Stress', 'RMSE']\n        - ['Energy', 'MAE']\n        - ['Force', 'MAE']\n        - ['Stress', 'MAE']\n        - ['Energy', 'Loss']\n        - ['Force', 'Loss']\n        - ['Stress', 'Loss']\n        - ['TotalLoss', 'None']\n\n    per_epoch: 10\n    # continue:\n    #    checkpoint: './checkpoint_last.pth'\n    #    reset_optimizer: False\n    #    reset_scheduler: False\ndata:\n    data_shuffle: False\n    batch_size: 128  # per GPU batch size, as the model trained with 32 GPUs, the effective batch size equals 4096.\n    scale: 'per_atom_energy_std'\n    shift: 'elemwise_reference_energies'\n\n    data_format: 'ase'\n    save_by_train_valid: False\n    load_dataset_path: [\"path_to_MPtrj_total.sevenn_data\"]\n    load_validset_path: [\"validaset.sevenn_data\"]\n</code></pre>"},{"location":"sevenn_train_param/#full-parameters","title":"Full parameters","text":"<pre><code># Example input.yaml for training SevenNet.\n# The underlying model is nequip (https://github.com/mir-group/nequip), but the names of hyperparameters might different.\n# Defaults model parameter that works well of channel, lmax, and num_convolution_layer are 32, 1, 3 respectively.\n# '*' signifies default. You can check log.sevenn.\n\nmodel:\n    chemical_species: 'Auto'                      # Chemical elements present in the dataset, guess them from load_dataset data if 'auto'\n    cutoff: 5.0                                   # Cutoff radius in Angstroms. If two atoms are within the cutoff, they are connected.\n    channel: 4                                    # The multiplicity(channel) of node features.\n    lmax: 1                                       # Maximum order of irreducible representations (rotation order).\n    num_convolution_layer: 4                      # The number of message passing layers.\n\n    #irreps_manual:                               # Manually set irreps of the model in each layer\n        #- \"128x0e\"\n        #- \"128x0e+64x1e+32x2e\"\n        #- \"128x0e+64x1e+32x2e\"\n        #- \"128x0e+64x1e+32x2e\"\n        #- \"128x0e+64x1e+32x2e\"\n        #- \"128x0e\"\n\n    weight_nn_hidden_neurons: [64, 64]            # Hidden neurons in convolution weight neural network\n    radial_basis:                                 # Function and its parameters to encode radial distance\n        radial_basis_name: 'bessel'               # Only 'bessel' is currently supported\n        bessel_basis_num: 8\n    cutoff_function:                              # Envelop function, multiplied to radial_basis functions to init edge featrues\n        cutoff_function_name: 'poly_cut'          # {'poly_cut' and 'poly_cut_p_value'} or {'XPLOR' and 'cutoff_on'}\n        poly_cut_p_value: 6\n\n    act_gate: {'e': 'silu', 'o': 'tanh'}          # Equivalent to 'nonlinearity_gates' in nequip\n    act_scalar: {'e': 'silu', 'o': 'tanh'}        # Equivalent to 'nonlinearity_scalars' in nequip\n\n    is_parity: False                              # Pairy True (E(3) group) or False (to SE(3) group)\n\n    self_connection_type: 'nequip'                # Default is 'nequip'. 'linear' is used for SevenNet-0.\n\n    conv_denominator: \"avg_num_neigh\"             # Valid options are \"avg_num_neigh*\", \"sqrt_avg_num_neigh\", or float\n    train_shift_scale: False                      # Enable training for shift &amp; scale in output layer\n    train_denominator: False                      # Enable training for denominator in convolution layer\n\ntrain:\n    random_seed: 1\n    is_train_stress: True                         # Includes stress in the loss function\n    epoch: 10                                     # Ends training after this number of epochs\n\n    #loss: 'Huber'                                # Default is 'mse' (mean squared error)\n    #loss_param:\n        #delta: 0.01\n\n    # Each optimizer and scheduler have different available parameters.\n    # You can refer to sevenn/train/optim.py for supporting optimizer &amp; schedulers\n    optimizer: 'adam'                             # Options available are 'sgd', 'adagrad', 'adam', 'adamw', 'radam'\n    optim_param:\n        lr: 0.005\n    scheduler: 'exponentiallr'                    # One of 'steplr', 'multisteplr', 'exponentiallr', 'cosineannealinglr', 'reducelronplateau', 'linearlr'\n    scheduler_param:\n        gamma: 0.99\n\n    force_loss_weight: 0.1                        # Coefficient for force loss\n    stress_loss_weight: 1e-06                     # Coefficient for stress loss (to kbar unit)\n\n    per_epoch:  5                                # Generate checkpoints every this epoch\n\n    # TotalEnergy, Energy, Force, Stress, Stress_GPa, TotalLoss\n    # RMSE, MAE, or Loss\n    error_record:\n        - ['Energy', 'RMSE']\n        - ['Force', 'RMSE']\n        - ['Stress', 'RMSE']\n        - ['TotalLoss', 'None']\n\n    # Continue training model from given checkpoint, or pre-trained model checkpoint for fine-tuning\n    #continue:\n        #reset_optimizer: False                    # Set True for fine-tuning\n        #reset_scheduler: False                    # Set True for fine-tuning\n        #checkpoint: 'checkpoint_best.pth'         # Checkpoint of pre-trained model or a model want to continue training.\n        #use_statistic_values_of_checkpoint: False # Set True to use shift, scale, and avg_num_neigh from checkpoint or not\n\n    # If the dataset changed (for fine-tuning),\n    # setting 'use_statistic_value_of_checkpoint' to True roughly changes model's accuracy in the beginning of training.\n    # We recommand to use it as False, and turn train_shift_scale and train_avg_num_neigh to True.\n\ndata:\n    batch_size: 2                                 # Per GPU batch size.\n    data_divide_ratio: 0.1                        # Split dataset into training and validation sets by this ratio\n\n    #shift: 'per_atom_energy_mean'                # One of 'per_atom_energy_mean*', 'elemwise_reference_energies', float\n    #scale: 'force_rms'                           # One of 'force_rms*', 'per_atom_energy_std', 'elemwise_force_rms', float\n\n    # ase.io.read readable data files or structure_list or .sevenn_data files can be used as dataset.\n    # .sevenn_data is preprocessed data set has edges connected (can be obtained by using sevenn_graph_build or by save_** options below)\n    data_format: 'ase'                   # Default is 'ase'. Choices are 'ase', 'structure_list', '.sevenn_data'\n    data_format_args:                            # Paramaters, will be passed to ase.io.read\n        energy_key: 'TotEnergy'                  # Key for energy in extxyz file\n        force_key: 'force'                       # Key for force in extxyz file\n\n    # ASE tries to infer its type by extension, in this case, extxyz file is loaded by ase.\n    #load_dataset_path: ['../data/test.extxyz']   # Example of using ase as data_format\n\n    # If only load_dataset_path is provided, train/valid set is automatically decided by splitting dataset by divide ratio\n    # If both load_dataset_path &amp; load_validset_path is provided, use load_dataset_path as training set.\n    load_dataset_path: ['./1_process_data/dataset_1593.xyz']\n    #load_validset_path: ['./valid.sevenn_data']\n\n    #save_dataset_path: 'total'                   # Save the preprocessed (in load_dataset_path) dataset\n    #save_by_train_valid: True                    # Save the preprocessed train.sevenn_data, valid.sevenn_data\n    #save_by_label: False                         # Save the dataset by labels specified in the structure_list\n</code></pre>"}]}