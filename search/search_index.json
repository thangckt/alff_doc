{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"<code>alff</code> Documentation","text":""},{"location":"#alff","title":"<code>alff</code>","text":"<p>ALFF: Active Learning Framework for ML-based Forcefields generation.</p> <p>This package is developed and maintained by C.Thang Nguyen</p>"},{"location":"alff_api/","title":"API","text":""},{"location":"alff_api/#alff","title":"<code>alff</code>","text":"<p>ALFF: Active Learning Framework for ML-based Forcefields generation.</p> <p>This package is developed and maintained by C.Thang Nguyen</p>"},{"location":"alff_api/#alff.ROOT_PATH","title":"<code>ROOT_PATH = Path(__file__).parent</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.__author__","title":"<code>__author__ = 'C.Thang Nguyen'</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.__email__","title":"<code>__email__ = 'thangckt@gmail.com'</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.cli","title":"<code>cli</code>","text":""},{"location":"alff_api/#alff.cli.alff_main","title":"<code>alff_main()</code>","text":""},{"location":"alff_api/#alff.cli.alff_gen_bulk","title":"<code>alff_gen_bulk()</code>","text":""},{"location":"alff_api/#alff.constant","title":"<code>constant</code>","text":""},{"location":"alff_api/#alff.constant.DIR_TRAIN","title":"<code>DIR_TRAIN = '00_train'</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.constant.DIR_MD","title":"<code>DIR_MD = '01_md'</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.constant.DIR_FP","title":"<code>DIR_FP = '02_fp'</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.constant.DIR_DATA","title":"<code>DIR_DATA = '03_data'</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.constant.DIR_TEMPLATE","title":"<code>DIR_TEMPLATE = 'template'</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.constant.DIR_TMP_DATA","title":"<code>DIR_TMP_DATA = 'copied_data'</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.constant.DIR_TMP_MODEL","title":"<code>DIR_TMP_MODEL = 'copied_model'</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.constant.FILE_ITER_LOG","title":"<code>FILE_ITER_LOG = 'alff_iter.record'</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.constant.FILE_DATAPATH","title":"<code>FILE_DATAPATH = 'data_paths.yaml'</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.constant.FILE_MODELPATH","title":"<code>FILE_MODELPATH = 'model_paths.yaml'</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.constant.FILE_TRAIN_INPUT","title":"<code>FILE_TRAIN_INPUT = 'train_input.yaml'</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.constant.FILE_MD_INPUT","title":"<code>FILE_MD_INPUT = 'lammps_input.in'</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.constant.train_tmpl_path","title":"<code>train_tmpl_path = os.path.join(DIR_TEMPLATE, DIR_TRAIN)</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.constant.FMT_ITER","title":"<code>FMT_ITER = '06d'</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.constant.FMT_STAGE","title":"<code>FMT_STAGE = '02d'</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.constant.FMT_MODEL","title":"<code>FMT_MODEL = '03d'</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.constant.FMT_MD_CONF","title":"<code>FMT_MD_CONF = '04d'</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.constant.FMT_MD_TASK","title":"<code>FMT_MD_TASK = '06d'</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.constant.FMT_FP_TASK","title":"<code>FMT_FP_TASK = '06d'</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.constant.DIR_LOG","title":"<code>DIR_LOG = 'logs'</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.constant.logdir","title":"<code>logdir = Path(DIR_LOG)</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.constant.LOGGER","title":"<code>LOGGER = create_logger('alff', level='INFO', log_file=f'{logdir}/alff.log')</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.data_generator","title":"<code>data_generator</code>","text":""},{"location":"alff_api/#alff.data_generator.const","title":"<code>const</code>","text":""},{"location":"alff_api/#alff.data_generator.const.DIR_BOX","title":"<code>DIR_BOX = '00_place_element'</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.data_generator.const.DIR_SCALE","title":"<code>DIR_SCALE = '01_scale_perturb'</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.data_generator.const.DIR_AIMD","title":"<code>DIR_AIMD = '02_aimd'</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.data_generator.gen_bulk","title":"<code>gen_bulk</code>","text":""},{"location":"alff_api/#alff.data_generator.gen_bulk.generate_struct","title":"<code>generate_struct(pdict, mdict)</code>","text":"<p>Place elements in the system</p>"},{"location":"alff_api/#alff.data_generator.gen_bulk.scale_perturb","title":"<code>scale_perturb(pdict, mdict)</code>","text":"<p>Scale and perturb the system</p>"},{"location":"alff_api/#alff.data_generator.gen_bulk.run_aimd","title":"<code>run_aimd(pdict, mdict)</code>","text":"<p>Run AIMD simulation</p>"},{"location":"alff_api/#alff.data_generator.gen_bulk.collect_data","title":"<code>collect_data(pdict, mdict)</code>","text":"<p>Collect data from AIMD simulation</p>"},{"location":"alff_api/#alff.data_generator.gen_bulk.gen_init_bulk","title":"<code>gen_init_bulk(configfile_param: str, configfile_machine: str)</code>","text":"<p>Generate initial data for training ML models</p>"},{"location":"alff_api/#alff.data_generator.lib_initdata","title":"<code>lib_initdata</code>","text":""},{"location":"alff_api/#alff.data_generator.lib_initdata.make_outdir_name","title":"<code>make_outdir_name(pdict)</code>","text":""},{"location":"alff_api/#alff.data_generator.lib_initdata.build_conf","title":"<code>build_conf(pdict)</code>","text":"<p>Build atomic configuration</p>"},{"location":"alff_api/#alff.data_generator.lib_initdata.build_conf_from_poscar","title":"<code>build_conf_from_poscar(pdict)</code>","text":"<p>Build atomic configuration from POSCAR file</p>"},{"location":"alff_api/#alff.fineturn","title":"<code>fineturn</code>","text":""},{"location":"alff_api/#alff.lib","title":"<code>lib</code>","text":""},{"location":"alff_api/#alff.lib.arginfo","title":"<code>arginfo</code>","text":"<p><code>alff</code> accepts a configuration file in YAML/JSON/JSONC format.</p>"},{"location":"alff_api/#alff.lib.arginfo.param","title":"<code>param()</code>","text":"<p>ALFF parameters.</p>"},{"location":"alff_api/#alff.lib.arginfo.param--parameters","title":"Parameters","text":"<pre><code>mlp_engine: str\n    The engine to use for training the MLP model. Choices: 'sevenn', 'mace'\nnumb_models: int\n    Number of models to train.\ninit_data_paths: list[str]\n    List of paths to the initial data.\ndistributed: bool\n    Whether to use distributed training.\ndistributed_backend: str\n    The Pytorch backend to use for distributed training. Choices: 'nccl', 'mpi'\nsevenn_args: dict\n    SevenNet's parameters.\nmace_args: dict\n    Mace's parameters.\n</code></pre>"},{"location":"alff_api/#alff.lib.arginfo.not_use_param_seveen","title":"<code>not_use_param_seveen()</code>","text":"<p>SevenNet parameters that are not applicable.</p> <p>These parameters are either generated by the ALFF or are not required for running the ALFF.</p>"},{"location":"alff_api/#alff.lib.arginfo.not_use_param_seveen--parameters","title":"Parameters","text":"<pre><code>train.random_seed: int\n    Random seed for reproducibility.\ndata.load_dataset_path: list[str]\n    List of paths to the dataset.\n</code></pre>"},{"location":"alff_api/#alff.lib.arginfo.machine","title":"<code>machine()</code>","text":"<p>ALFF parameters for running on a clusters.</p>"},{"location":"alff_api/#alff.lib.arginfo_old","title":"<code>arginfo_old</code>","text":""},{"location":"alff_api/#alff.lib.arginfo_old.run_mdata_arginfo","title":"<code>run_mdata_arginfo() -&gt; Argument</code>","text":"<p>Generate arginfo for dpgen run mdata.</p>"},{"location":"alff_api/#alff.lib.arginfo_old.run_mdata_arginfo--returns","title":"Returns","text":"<p>Argument     arginfo</p>"},{"location":"alff_api/#alff.lib.arginfo_old.basic_args","title":"<code>basic_args() -&gt; list[Argument]</code>","text":""},{"location":"alff_api/#alff.lib.arginfo_old.data_args","title":"<code>data_args() -&gt; list[Argument]</code>","text":""},{"location":"alff_api/#alff.lib.arginfo_old.training_args_common","title":"<code>training_args_common() -&gt; list[Argument]</code>","text":""},{"location":"alff_api/#alff.lib.arginfo_old.training_args_dp","title":"<code>training_args_dp() -&gt; list[Argument]</code>","text":"<p>Traning arguments.</p>"},{"location":"alff_api/#alff.lib.arginfo_old.training_args_dp--returns","title":"Returns","text":"<p>list[dargs.Argument]     List of training arguments.</p>"},{"location":"alff_api/#alff.lib.arginfo_old.training_args","title":"<code>training_args() -&gt; Variant</code>","text":""},{"location":"alff_api/#alff.lib.arginfo_old.model_devi_jobs_template_args","title":"<code>model_devi_jobs_template_args() -&gt; Argument</code>","text":""},{"location":"alff_api/#alff.lib.arginfo_old.model_devi_jobs_rev_mat_args","title":"<code>model_devi_jobs_rev_mat_args() -&gt; Argument</code>","text":""},{"location":"alff_api/#alff.lib.arginfo_old.model_devi_jobs_args","title":"<code>model_devi_jobs_args() -&gt; list[Argument]</code>","text":""},{"location":"alff_api/#alff.lib.arginfo_old.model_devi_lmp_args","title":"<code>model_devi_lmp_args() -&gt; list[Argument]</code>","text":""},{"location":"alff_api/#alff.lib.arginfo_old.model_devi_amber_args","title":"<code>model_devi_amber_args() -&gt; list[Argument]</code>","text":"<p>Amber engine arguments.</p>"},{"location":"alff_api/#alff.lib.arginfo_old.model_devi_args","title":"<code>model_devi_args() -&gt; list[Variant]</code>","text":""},{"location":"alff_api/#alff.lib.arginfo_old.fp_style_vasp_args","title":"<code>fp_style_vasp_args() -&gt; list[Argument]</code>","text":""},{"location":"alff_api/#alff.lib.arginfo_old.fp_style_abacus_args","title":"<code>fp_style_abacus_args() -&gt; list[Argument]</code>","text":""},{"location":"alff_api/#alff.lib.arginfo_old.fp_style_gaussian_args","title":"<code>fp_style_gaussian_args() -&gt; list[Argument]</code>","text":"<p>Gaussian fp style arguments.</p>"},{"location":"alff_api/#alff.lib.arginfo_old.fp_style_gaussian_args--returns","title":"Returns","text":"<p>list[dargs.Argument]     list of Gaussian fp style arguments</p>"},{"location":"alff_api/#alff.lib.arginfo_old.fp_style_siesta_args","title":"<code>fp_style_siesta_args() -&gt; list[Argument]</code>","text":""},{"location":"alff_api/#alff.lib.arginfo_old.fp_style_cp2k_args","title":"<code>fp_style_cp2k_args() -&gt; list[Argument]</code>","text":""},{"location":"alff_api/#alff.lib.arginfo_old.fp_style_amber_diff_args","title":"<code>fp_style_amber_diff_args() -&gt; list[Argument]</code>","text":"<p>Arguments for FP style amber/diff.</p>"},{"location":"alff_api/#alff.lib.arginfo_old.fp_style_amber_diff_args--returns","title":"Returns","text":"<p>list[dargs.Argument]     list of amber/diff fp style arguments</p>"},{"location":"alff_api/#alff.lib.arginfo_old.fp_style_pwscf_args","title":"<code>fp_style_pwscf_args() -&gt; list[Argument]</code>","text":"<p>Arguments for FP style pwscf (Quantum Espresso).</p>"},{"location":"alff_api/#alff.lib.arginfo_old.fp_style_pwscf_args--returns","title":"Returns","text":"<p>list[dargs.Argument]     list of pwscf fp style arguments</p>"},{"location":"alff_api/#alff.lib.arginfo_old.fp_style_custom_args","title":"<code>fp_style_custom_args() -&gt; list[Argument]</code>","text":"<p>Arguments for FP style custom.</p>"},{"location":"alff_api/#alff.lib.arginfo_old.fp_style_custom_args--returns","title":"Returns","text":"<p>list[dargs.Argument]     list of custom fp style arguments</p>"},{"location":"alff_api/#alff.lib.arginfo_old.fp_style_variant_type_args","title":"<code>fp_style_variant_type_args() -&gt; Variant</code>","text":""},{"location":"alff_api/#alff.lib.arginfo_old.fp_args","title":"<code>fp_args() -&gt; list[Argument]</code>","text":""},{"location":"alff_api/#alff.lib.arginfo_old.run_jdata_arginfo","title":"<code>run_jdata_arginfo() -&gt; Argument</code>","text":"<p>Argument information for dpgen run mdata.</p>"},{"location":"alff_api/#alff.lib.arginfo_old.run_jdata_arginfo--returns","title":"Returns","text":"<p>Argument     argument information</p>"},{"location":"alff_api/#alff.lib.data_tool","title":"<code>data_tool</code>","text":""},{"location":"alff_api/#alff.lib.data_tool.select_extxyz_frames","title":"<code>select_extxyz_frames(extxyz_file: str, has_symbols: list = None, only_symbols: list = None, exact_symbols: list = None, has_properties: list = None, only_properties: list = None, has_columns: list = None, only_columns: list = None, output_file: str = 'selected_frames.extxyz') -&gt; list[ase.Atoms]</code>","text":"<p>Choose frames from a extxyz trajectory file, based on some criterion.</p> <p>Parameters:</p> <ul> <li> <code>extxyz_file</code>               (<code>str</code>)           \u2013            <p>Path to the extxyz file.</p> </li> <li> <code>has_symbols</code>               (<code>list</code>, default:                   <code>None</code> )           \u2013            <p>List of symbols that each frame must have at least one of them.</p> </li> <li> <code>only_symbols</code>               (<code>list</code>, default:                   <code>None</code> )           \u2013            <p>List of symbols that each frame must have only these symbols.</p> </li> <li> <code>exact_symbols</code>               (<code>list</code>, default:                   <code>None</code> )           \u2013            <p>List of symbols that each frame must have exactly these symbols.</p> </li> <li> <code>has_properties</code>               (<code>list</code>, default:                   <code>None</code> )           \u2013            <p>List of properties that each frame must have at least one of them.</p> </li> <li> <code>only_properties</code>               (<code>list</code>, default:                   <code>None</code> )           \u2013            <p>List of properties that each frame must have only these properties.</p> </li> <li> <code>has_columns</code>               (<code>list</code>, default:                   <code>None</code> )           \u2013            <p>List of columns that each frame must have at least one of them.</p> </li> <li> <code>only_columns</code>               (<code>list</code>, default:                   <code>None</code> )           \u2013            <p>List of columns that each frame must have only these columns.</p> </li> <li> <code>output_file</code>               (<code>str</code>, default:                   <code>'selected_frames.extxyz'</code> )           \u2013            <p>Path to the output file.</p> </li> </ul>"},{"location":"alff_api/#alff.lib.data_tool.read_log_MACE_train","title":"<code>read_log_MACE_train(log_file: str, output_file: str = None) -&gt; dict</code>","text":"<p>Read MACE log file, and extract learning curve.</p>"},{"location":"alff_api/#alff.lib.data_tool.get_all_mace_args_offline","title":"<code>get_all_mace_args_offline()</code>","text":"<p>Retrieve all MACE arguments from installed version.</p>"},{"location":"alff_api/#alff.lib.data_tool.get_all_mace_args_online","title":"<code>get_all_mace_args_online()</code>","text":"<p>Retrieve all MACE arguments from source codes.</p>"},{"location":"alff_api/#alff.lib.data_tool.revise_mace_cli_args","title":"<code>revise_mace_cli_args(input_args: dict)</code>","text":"<p>Check if the input arguments are valid for MACE CLI.</p>"},{"location":"alff_api/#alff.lib.data_tool.poscar2lmpdata","title":"<code>poscar2lmpdata(poscar_file: str, lmpdata_file: str, atom_style: str = 'atomic') -&gt; list</code>","text":"<p>Convert POSCAR file to LAMMPS data file.</p>"},{"location":"alff_api/#alff.lib.data_tool.extxyz2lmpdata","title":"<code>extxyz2lmpdata(extxyz_file: str, lmpdata_file: str, atom_style: str = 'atomic') -&gt; list</code>","text":"<p>Convert extxyz file to LAMMPS data file.</p>"},{"location":"alff_api/#alff.lib.dataset","title":"<code>dataset</code>","text":""},{"location":"alff_api/#alff.lib.dataset.convert_mpchgnet_to_xyz","title":"<code>convert_mpchgnet_to_xyz</code>","text":""},{"location":"alff_api/#alff.lib.dataset.convert_mpchgnet_to_xyz.parser","title":"<code>parser = argparse.ArgumentParser()</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.lib.dataset.convert_mpchgnet_to_xyz.args","title":"<code>args = parser.parse_args()</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.lib.dataset.convert_mpchgnet_to_xyz.filename","title":"<code>filename = args.mptrj</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.lib.dataset.convert_mpchgnet_to_xyz.info_keys","title":"<code>info_keys = ['uncorrected_total_energy', 'corrected_total_energy', 'energy_per_atom', 'ef_per_atom', 'e_per_atom_relaxed', 'ef_per_atom_relaxed', 'magmom', 'bandgap', 'mp_id']</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.lib.dataset.convert_mpchgnet_to_xyz.data","title":"<code>data = json.load(f)</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.lib.dataset.convert_mpchgnet_to_xyz.dataset","title":"<code>dataset = list(data.values())</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.lib.dataset.convert_mpchgnet_to_xyz.aseatoms_list","title":"<code>aseatoms_list = []</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.lib.dataset.convert_mpchgnet_to_xyz.new_filename","title":"<code>new_filename = filename.replace('.json', '.extxyz')</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.lib.dataset.convert_mpchgnet_to_xyz.chgnet_to_ase_atoms","title":"<code>chgnet_to_ase_atoms(datum: dict[str, dict[str, Any]]) -&gt; list[Atoms]</code>","text":""},{"location":"alff_api/#alff.lib.deepmdkit_model_devi","title":"<code>deepmdkit_model_devi</code>","text":""},{"location":"alff_api/#alff.lib.deepmdkit_model_devi.calc_model_devi_f","title":"<code>calc_model_devi_f(fs: np.ndarray, real_f: Optional[np.ndarray] = None, relative: Optional[float] = None, atomic: bool = False) -&gt; Tuple[np.ndarray, ...]</code>","text":"<p>Calculate model deviation of force.</p>"},{"location":"alff_api/#alff.lib.deepmdkit_model_devi.calc_model_devi_f--parameters","title":"Parameters","text":"<p>fs : numpy.ndarray     size of <code>n_models x n_frames x n_atoms x 3</code> real_f : numpy.ndarray or None     real force, size of <code>n_frames x n_atoms x 3</code>. If given,     the RMS real error is calculated instead. relative : float, default: None     If given, calculate the relative model deviation of force. The     value is the level parameter for computing the relative model     deviation of the force. atomic : bool, default: False     Whether return deviation of force in all atoms</p>"},{"location":"alff_api/#alff.lib.deepmdkit_model_devi.calc_model_devi_f--returns","title":"Returns","text":"<p>max_devi_f : numpy.ndarray     maximum deviation of force in all atoms min_devi_f : numpy.ndarray     minimum deviation of force in all atoms avg_devi_f : numpy.ndarray     average deviation of force in all atoms fs_devi : numpy.ndarray     deviation of force in all atoms, returned if atomic=True</p>"},{"location":"alff_api/#alff.lib.deepmdkit_model_devi.calc_model_devi_e","title":"<code>calc_model_devi_e(es: np.ndarray, real_e: Optional[np.ndarray] = None) -&gt; np.ndarray</code>","text":"<p>Calculate model deviation of total energy per atom.</p> <p>Here we don't use the atomic energy, as the decomposition of energy is arbitrary and not unique. There is no fitting target for atomic energy.</p>"},{"location":"alff_api/#alff.lib.deepmdkit_model_devi.calc_model_devi_e--parameters","title":"Parameters","text":"<p>es : numpy.ndarray     size of <code>n_models x n_frames x 1 real_e : numpy.ndarray     real energy, size of</code>n_frames x 1`. If given,     the RMS real error is calculated instead.</p>"},{"location":"alff_api/#alff.lib.deepmdkit_model_devi.calc_model_devi_e--returns","title":"Returns","text":"<p>max_devi_e : numpy.ndarray     maximum deviation of energy</p>"},{"location":"alff_api/#alff.lib.deepmdkit_model_devi.calc_model_devi_v","title":"<code>calc_model_devi_v(vs: np.ndarray, real_v: Optional[np.ndarray] = None, relative: Optional[float] = None) -&gt; Tuple[np.ndarray, np.ndarray, np.ndarray]</code>","text":"<p>Calculate model deviation of virial.</p>"},{"location":"alff_api/#alff.lib.deepmdkit_model_devi.calc_model_devi_v--parameters","title":"Parameters","text":"<p>vs : numpy.ndarray     size of <code>n_models x n_frames x 9</code> real_v : numpy.ndarray     real virial, size of <code>n_frames x 9</code>. If given,     the RMS real error is calculated instead. relative : float, default: None     If given, calculate the relative model deviation of virial. The     value is the level parameter for computing the relative model     deviation of the virial.</p>"},{"location":"alff_api/#alff.lib.deepmdkit_model_devi.calc_model_devi_v--returns","title":"Returns","text":"<p>max_devi_v : numpy.ndarray     maximum deviation of virial in 9 elements min_devi_v : numpy.ndarray     minimum deviation of virial in 9 elements avg_devi_v : numpy.ndarray     average deviation of virial in 9 elements</p>"},{"location":"alff_api/#alff.lib.deepmdkit_model_devi.write_model_devi_out","title":"<code>write_model_devi_out(devi: np.ndarray, fname: str, header: str = '', atomic: bool = False)</code>","text":"<p>Write output of model deviation.</p>"},{"location":"alff_api/#alff.lib.deepmdkit_model_devi.write_model_devi_out--parameters","title":"Parameters","text":"<p>devi : numpy.ndarray     the first column is the steps index fname : str     the file name to dump header : str, default=\"\"     the header to dump atomic : bool, default: False     whether atomic model deviation is printed</p>"},{"location":"alff_api/#alff.lib.deepmdkit_model_devi.calc_model_devi","title":"<code>calc_model_devi(coord, box, atype, models, fname=None, frequency=1, mixed_type=False, fparam: Optional[np.ndarray] = None, aparam: Optional[np.ndarray] = None, real_data: Optional[dict] = None, atomic: bool = False, relative: Optional[float] = None, relative_v: Optional[float] = None)</code>","text":"<p>Python interface to calculate model deviation.</p>"},{"location":"alff_api/#alff.lib.deepmdkit_model_devi.calc_model_devi--parameters","title":"Parameters","text":"<p>coord : numpy.ndarray, <code>n_frames x n_atoms x 3</code>     Coordinates of system to calculate box : numpy.ndarray or None, <code>n_frames x 3 x 3</code>     Box to specify periodic boundary condition. If None, no pbc will be used atype : numpy.ndarray, <code>n_atoms x 1</code>     Atom types models : list of DeepPot models     Models used to evaluate deviation fname : str or None     File to dump results, default None frequency : int     Steps between frames (if the system is given by molecular dynamics engine), default 1 mixed_type : bool     Whether the input atype is in mixed_type format or not fparam : numpy.ndarray     frame specific parameters aparam : numpy.ndarray     atomic specific parameters real_data : dict, optional     real data to calculate RMS real error atomic : bool, default: False     If True, calculate the force model deviation of each atom. relative : float, default: None     If given, calculate the relative model deviation of force. The     value is the level parameter for computing the relative model     deviation of the force. relative_v : float, default: None     If given, calculate the relative model deviation of virial. The     value is the level parameter for computing the relative model     deviation of the virial.</p>"},{"location":"alff_api/#alff.lib.deepmdkit_model_devi.calc_model_devi--returns","title":"Returns","text":"<p>model_devi : numpy.ndarray, <code>n_frames x 8</code>     Model deviation results. The first column is index of steps, the other 7 columns are     max_devi_v, min_devi_v, avg_devi_v, max_devi_f, min_devi_f, avg_devi_f, devi_e.</p>"},{"location":"alff_api/#alff.lib.deepmdkit_model_devi.calc_model_devi--examples","title":"Examples","text":"<p>from deepmd.infer import calc_model_devi from deepmd.infer import DeepPot as DP import numpy as np coord = np.array([[1,0,0], [0,0,1.5], [1,0,3]]).reshape([1, -1]) cell = np.diag(10 * np.ones(3)).reshape([1, -1]) atype = [1,0,1] graphs = [DP(\"graph.000.pb\"), DP(\"graph.001.pb\")] model_devi = calc_model_devi(coord, cell, atype, graphs)</p>"},{"location":"alff_api/#alff.lib.deepmdkit_model_devi.make_model_devi","title":"<code>make_model_devi(*, models: list, system: str, set_prefix: str, output: str, frequency: int, real_error: bool = False, atomic: bool = False, relative: Optional[float] = None, relative_v: Optional[float] = None, **kwargs)</code>","text":"<p>Make model deviation calculation.</p>"},{"location":"alff_api/#alff.lib.deepmdkit_model_devi.make_model_devi--parameters","title":"Parameters","text":"<p>models : list     A list of paths of models to use for making model deviation system : str     The path of system to make model deviation calculation set_prefix : str     The set prefix of the system output : str     The output file for model deviation results frequency : int     The number of steps that elapse between writing coordinates     in a trajectory by a MD engine (such as Gromacs / Lammps).     This paramter is used to determine the index in the output file. real_error : bool, default: False     If True, calculate the RMS real error instead of model deviation. atomic : bool, default: False     If True, calculate the force model deviation of each atom. relative : float, default: None     If given, calculate the relative model deviation of force. The     value is the level parameter for computing the relative model     deviation of the force. relative_v : float, default: None     If given, calculate the relative model deviation of virial. The     value is the level parameter for computing the relative model     deviation of the virial. **kwargs     Arbitrary keyword arguments.</p>"},{"location":"alff_api/#alff.lib.dpdispatcher","title":"<code>dpdispatcher</code>","text":""},{"location":"alff_api/#alff.lib.dpdispatcher.log_file","title":"<code>log_file = DIR_LOG / 'dpdispatcher.log'</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.lib.dpdispatcher.fh","title":"<code>fh = logging.FileHandler(log_file.resolve(), delay=True)</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.lib.dpdispatcher.make_submission","title":"<code>make_submission(mdict_machine, mdict_resources, command_list, work_path, task_paths, forward_files, backward_files, forward_common_files, outlog, errlog)</code>","text":""},{"location":"alff_api/#alff.lib.lib_gpaw","title":"<code>lib_gpaw</code>","text":""},{"location":"alff_api/#alff.lib.lib_gpaw.gpaw","title":"<code>gpaw</code>","text":"<p>Move all the GPAW related functions to here. - functions for <code>arginfo.py</code> - functions for <code>run.py</code>.</p>"},{"location":"alff_api/#alff.lib.lib_gpaw.gpaw.fp_name","title":"<code>fp_name = '02.fp'</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.lib.lib_gpaw.gpaw.GPAW_LIB_PATH","title":"<code>GPAW_LIB_PATH = Path(__file__).parent</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.lib.lib_gpaw.gpaw.fp_style_gpaw_args","title":"<code>fp_style_gpaw_args() -&gt; list[Argument]</code>","text":""},{"location":"alff_api/#alff.lib.lib_gpaw.gpaw.pre_fp_gpaw","title":"<code>pre_fp_gpaw(iter_index, jdata)</code>","text":"<p>Make input file for customized FP style.</p>"},{"location":"alff_api/#alff.lib.lib_gpaw.gpaw.pre_fp_gpaw--parameters","title":"Parameters","text":"<p>iter_index : int     iter index jdata : dict     Run parameters.</p>"},{"location":"alff_api/#alff.lib.lib_gpaw.gpaw.post_fp_gpaw","title":"<code>post_fp_gpaw(iter_index, jdata)</code>","text":"<p>Post fp for custom fp. Collect data from user-defined <code>output_fn</code>.</p>"},{"location":"alff_api/#alff.lib.lib_gpaw.gpaw.post_fp_gpaw--parameters","title":"Parameters","text":"<p>iter_index : int     The index of the current iteration. jdata : dict     The parameter data.</p>"},{"location":"alff_api/#alff.lib.lib_gpaw.internal_gpaw_aimd","title":"<code>internal_gpaw_aimd</code>","text":"<p>Some notes: - Run MD in ase following this tutorial: https://wiki.fysik.dtu.dk/ase/tutorials/md/md.html - Must set txt='calc.txt' in GPAW calculator for backward files.</p>"},{"location":"alff_api/#alff.lib.lib_gpaw.internal_gpaw_aimd.parallel_args","title":"<code>parallel_args = {'sl_auto': True, 'use_elpa': True}</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.lib.lib_gpaw.internal_gpaw_aimd.parser","title":"<code>parser = argparse.ArgumentParser(description='Optimize structure using GPAW')</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.lib.lib_gpaw.internal_gpaw_aimd.args","title":"<code>args = parser.parse_args()</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.lib.lib_gpaw.internal_gpaw_aimd.nsteps","title":"<code>nsteps = args.nsteps</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.lib.lib_gpaw.internal_gpaw_aimd.conf_freq","title":"<code>conf_freq = args.conf_freq</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.lib.lib_gpaw.internal_gpaw_aimd.fmax","title":"<code>fmax = args.fmax</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.lib.lib_gpaw.internal_gpaw_aimd.ecut","title":"<code>ecut = args.ecutoff</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.lib.lib_gpaw.internal_gpaw_aimd.kdensity","title":"<code>kdensity = args.kdensity</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.lib.lib_gpaw.internal_gpaw_aimd.pbc","title":"<code>pbc = [int(item) for item in args.pbc.split(' ')]</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.lib.lib_gpaw.internal_gpaw_aimd.relax_dim","title":"<code>relax_dim = [int(item) for item in args.relax_dim.split(' ')]</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.lib.lib_gpaw.internal_gpaw_aimd.atoms","title":"<code>atoms = read('POSCAR', format='vasp')</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.lib.lib_gpaw.internal_gpaw_aimd.calc","title":"<code>calc = GPAW(mode=PW(ecut), xc='PBE', occupations=FermiDirac(0.01), kpts={'density': kdensity, 'gamma': True}, txt='calc_aimd.txt', parallel=parallel_args)</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.lib.lib_gpaw.internal_gpaw_aimd.dyn","title":"<code>dyn = Langevin(atoms, timestep=0.5 * units.fs, temperature_K=300, friction=0.002)</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.lib.lib_gpaw.internal_gpaw_aimd.traj","title":"<code>traj = Trajectory('CONF.asetraj', 'w', atoms, properties=['energy', 'forces', 'stress'])</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.lib.lib_gpaw.internal_gpaw_aimd.tailor_properties","title":"<code>tailor_properties(a=atoms, filename='calc_properties.txt')</code>","text":"<p>Function to print the potential, kinetic and total energy.</p>"},{"location":"alff_api/#alff.lib.lib_gpaw.internal_gpaw_optimize","title":"<code>internal_gpaw_optimize</code>","text":"<p>Some notes - Must set txt='calc.txt' in GPAW calculator for backward files.</p>"},{"location":"alff_api/#alff.lib.lib_gpaw.internal_gpaw_optimize.parallel_args","title":"<code>parallel_args = {'sl_auto': True, 'use_elpa': True}</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.lib.lib_gpaw.internal_gpaw_optimize.parser","title":"<code>parser = argparse.ArgumentParser(description='Optimize structure using GPAW')</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.lib.lib_gpaw.internal_gpaw_optimize.args","title":"<code>args = parser.parse_args()</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.lib.lib_gpaw.internal_gpaw_optimize.fmax","title":"<code>fmax = args.fmax</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.lib.lib_gpaw.internal_gpaw_optimize.ecut","title":"<code>ecut = args.ecutoff</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.lib.lib_gpaw.internal_gpaw_optimize.kdensity","title":"<code>kdensity = args.kdensity</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.lib.lib_gpaw.internal_gpaw_optimize.pbc","title":"<code>pbc = [int(item) for item in args.pbc.split(' ')]</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.lib.lib_gpaw.internal_gpaw_optimize.relax_dim","title":"<code>relax_dim = [int(item) for item in args.relax_dim.split(' ')]</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.lib.lib_gpaw.internal_gpaw_optimize.atoms","title":"<code>atoms = read('POSCAR', format='vasp')</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.lib.lib_gpaw.internal_gpaw_optimize.calc","title":"<code>calc = GPAW(mode=PW(ecut), xc='PBE', occupations=FermiDirac(0.01), kpts={'density': kdensity, 'gamma': True}, txt='calc_optimize.txt', parallel=parallel_args)</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.lib.lib_gpaw.internal_gpaw_optimize.atoms_filter","title":"<code>atoms_filter = FrechetCellFilter(atoms, mask=relax_dim)</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.lib.lib_gpaw.internal_gpaw_optimize.opt","title":"<code>opt = BFGS(atoms_filter)</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.lib.lib_gpaw.internal_gpaw_singlepoint","title":"<code>internal_gpaw_singlepoint</code>","text":"<p>Some notes - Must set txt='calc.txt' in GPAW calculator for backward files.</p>"},{"location":"alff_api/#alff.lib.lib_gpaw.internal_gpaw_singlepoint.parallel_args","title":"<code>parallel_args = {'sl_auto': True, 'use_elpa': True}</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.lib.lib_gpaw.internal_gpaw_singlepoint.parser","title":"<code>parser = argparse.ArgumentParser(description='Optimize structure using GPAW')</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.lib.lib_gpaw.internal_gpaw_singlepoint.args","title":"<code>args = parser.parse_args()</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.lib.lib_gpaw.internal_gpaw_singlepoint.fmax","title":"<code>fmax = args.fmax</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.lib.lib_gpaw.internal_gpaw_singlepoint.ecut","title":"<code>ecut = args.ecutoff</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.lib.lib_gpaw.internal_gpaw_singlepoint.kdensity","title":"<code>kdensity = args.kdensity</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.lib.lib_gpaw.internal_gpaw_singlepoint.pbc","title":"<code>pbc = [int(item) for item in args.pbc.split(' ')]</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.lib.lib_gpaw.internal_gpaw_singlepoint.atoms","title":"<code>atoms = read('POSCAR', format='vasp')</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.lib.lib_gpaw.internal_gpaw_singlepoint.calc","title":"<code>calc = GPAW(mode=PW(ecut), xc='PBE', occupations=FermiDirac(0.01), kpts={'density': kdensity, 'gamma': True}, txt='calc_singlepoint.txt')</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.lib.mlp_dp","title":"<code>mlp_dp</code>","text":""},{"location":"alff_api/#alff.lib.mlp_dp.make_train_dp","title":"<code>make_train_dp(iter_idx, pdict, mdict)</code>","text":""},{"location":"alff_api/#alff.lib.mlp_dp.run_train_dp","title":"<code>run_train_dp(iter_idx, pdict, mdict)</code>","text":""},{"location":"alff_api/#alff.lib.mlp_dp.post_train_dp","title":"<code>post_train_dp(iter_idx, pdict, mdict)</code>","text":""},{"location":"alff_api/#alff.lib.mlp_dp.detect_batch_size","title":"<code>detect_batch_size(batch_size, system=None)</code>","text":""},{"location":"alff_api/#alff.lib.mlp_dp.get_nframes","title":"<code>get_nframes(system)</code>","text":""},{"location":"alff_api/#alff.lib.mlp_mace","title":"<code>mlp_mace</code>","text":""},{"location":"alff_api/#alff.lib.mlp_mace.pre_train_mace","title":"<code>pre_train_mace(iter_idx, pdict, mdict)</code>","text":""},{"location":"alff_api/#alff.lib.mlp_mace.run_train_mace","title":"<code>run_train_mace(iter_idx, pdict, mdict)</code>","text":""},{"location":"alff_api/#alff.lib.mlp_mace.post_train_mace","title":"<code>post_train_mace(iter_idx, pdict, mdict)</code>","text":""},{"location":"alff_api/#alff.lib.mlp_sevenn","title":"<code>mlp_sevenn</code>","text":""},{"location":"alff_api/#alff.lib.mlp_sevenn.pre_train_sevenn","title":"<code>pre_train_sevenn(iter_idx, pdict, mdict)</code>","text":""},{"location":"alff_api/#alff.lib.mlp_sevenn.run_train_sevenn","title":"<code>run_train_sevenn(iter_idx, pdict, mdict)</code>","text":""},{"location":"alff_api/#alff.lib.mlp_sevenn.post_train_sevenn","title":"<code>post_train_sevenn(iter_idx, pdict, mdict)</code>","text":""},{"location":"alff_api/#alff.lib.old_lib","title":"<code>old_lib</code>","text":""},{"location":"alff_api/#alff.lib.old_lib.abacus_scf","title":"<code>abacus_scf</code>","text":""},{"location":"alff_api/#alff.lib.old_lib.abacus_scf.bohr2ang","title":"<code>bohr2ang = 0.52917721067</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.lib.old_lib.abacus_scf.fp_params","title":"<code>fp_params = {'k_points': [1, 1, 1, 0, 0, 0]}</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.lib.old_lib.abacus_scf.ret","title":"<code>ret = make_abacus_scf_kpt(fp_params)</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.lib.old_lib.abacus_scf.make_abacus_scf_kpt","title":"<code>make_abacus_scf_kpt(fp_params)</code>","text":""},{"location":"alff_api/#alff.lib.old_lib.abacus_scf.make_abacus_scf_input","title":"<code>make_abacus_scf_input(fp_params, extra_file_path='')</code>","text":""},{"location":"alff_api/#alff.lib.old_lib.abacus_scf.make_abacus_scf_stru","title":"<code>make_abacus_scf_stru(sys_data, fp_pp_files, fp_orb_files=None, fp_dpks_descriptor=None, fp_params=None, type_map=None, pporb='')</code>","text":""},{"location":"alff_api/#alff.lib.old_lib.abacus_scf.get_abacus_input_parameters","title":"<code>get_abacus_input_parameters(INPUT)</code>","text":""},{"location":"alff_api/#alff.lib.old_lib.abacus_scf.get_mass_from_STRU","title":"<code>get_mass_from_STRU(geometry_inlines, atom_names)</code>","text":""},{"location":"alff_api/#alff.lib.old_lib.abacus_scf.get_natoms_from_stru","title":"<code>get_natoms_from_stru(geometry_inlines)</code>","text":""},{"location":"alff_api/#alff.lib.old_lib.abacus_scf.get_additional_from_STRU","title":"<code>get_additional_from_STRU(geometry_inlines, nele)</code>","text":""},{"location":"alff_api/#alff.lib.old_lib.abacus_scf.get_abacus_STRU","title":"<code>get_abacus_STRU(STRU, INPUT=None, n_ele=None)</code>","text":""},{"location":"alff_api/#alff.lib.old_lib.abacus_scf.make_supercell_abacus","title":"<code>make_supercell_abacus(from_struct, super_cell)</code>","text":""},{"location":"alff_api/#alff.lib.old_lib.abacus_scf.make_kspacing_kpoints_stru","title":"<code>make_kspacing_kpoints_stru(stru, kspacing)</code>","text":""},{"location":"alff_api/#alff.lib.old_lib.calypso_check_outcar","title":"<code>calypso_check_outcar</code>","text":""},{"location":"alff_api/#alff.lib.old_lib.calypso_check_outcar.cwd","title":"<code>cwd = os.getcwd()</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.lib.old_lib.calypso_check_outcar.Get_Element_Num","title":"<code>Get_Element_Num(elements)</code>","text":"<p>Using the Atoms.symples to Know Element&amp;Num.</p>"},{"location":"alff_api/#alff.lib.old_lib.calypso_check_outcar.Write_Contcar","title":"<code>Write_Contcar(element, ele, lat, pos)</code>","text":"<p>Write CONTCAR.</p>"},{"location":"alff_api/#alff.lib.old_lib.calypso_check_outcar.Write_Outcar","title":"<code>Write_Outcar(element, ele, volume, lat, pos, ene, force, stress, pstress)</code>","text":"<p>Write OUTCAR.</p>"},{"location":"alff_api/#alff.lib.old_lib.calypso_check_outcar.check","title":"<code>check()</code>","text":""},{"location":"alff_api/#alff.lib.old_lib.calypso_run_model_devi","title":"<code>calypso_run_model_devi</code>","text":""},{"location":"alff_api/#alff.lib.old_lib.calypso_run_model_devi.cwd","title":"<code>cwd = os.getcwd()</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.lib.old_lib.calypso_run_model_devi.model_path","title":"<code>model_path = os.path.join(os.path.abspath(os.path.join(cwd, os.pardir)), 'gen_stru_analy')</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.lib.old_lib.calypso_run_model_devi.parser","title":"<code>parser = argparse.ArgumentParser(description='calc model-devi by `all_models` and `type_map`')</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.lib.old_lib.calypso_run_model_devi.args","title":"<code>args = parser.parse_args()</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.lib.old_lib.calypso_run_model_devi.write_model_devi_out","title":"<code>write_model_devi_out(devi, fname)</code>","text":""},{"location":"alff_api/#alff.lib.old_lib.calypso_run_model_devi.Modd","title":"<code>Modd(all_models, type_map)</code>","text":""},{"location":"alff_api/#alff.lib.old_lib.calypso_run_opt","title":"<code>calypso_run_opt</code>","text":""},{"location":"alff_api/#alff.lib.old_lib.calypso_run_opt.Get_Element_Num","title":"<code>Get_Element_Num(elements)</code>","text":"<p>Using the Atoms.symples to Know Element&amp;Num.</p>"},{"location":"alff_api/#alff.lib.old_lib.calypso_run_opt.Write_Contcar","title":"<code>Write_Contcar(element, ele, lat, pos)</code>","text":"<p>Write CONTCAR.</p>"},{"location":"alff_api/#alff.lib.old_lib.calypso_run_opt.Write_Outcar","title":"<code>Write_Outcar(element, ele, volume, lat, pos, ene, force, stress, pstress)</code>","text":"<p>Write OUTCAR.</p>"},{"location":"alff_api/#alff.lib.old_lib.calypso_run_opt.read_stress_fmax","title":"<code>read_stress_fmax()</code>","text":""},{"location":"alff_api/#alff.lib.old_lib.calypso_run_opt.run_opt","title":"<code>run_opt(fmax, stress)</code>","text":"<p>Using the ASE&amp;DP to Optimize Configures.</p>"},{"location":"alff_api/#alff.lib.old_lib.calypso_run_opt.run","title":"<code>run()</code>","text":""},{"location":"alff_api/#alff.lib.old_lib.cp2k","title":"<code>cp2k</code>","text":""},{"location":"alff_api/#alff.lib.old_lib.cp2k.default_config","title":"<code>default_config = {'GLOBAL': {'PROJECT': 'DPGEN'}, 'FORCE_EVAL': {'METHOD': 'QS', 'STRESS_TENSOR': 'ANALYTICAL', 'DFT': {'BASIS_SET_FILE_NAME': './cp2k_basis_pp_file/BASIS_MOLOPT', 'POTENTIAL_FILE_NAME': './cp2k_basis_pp_file/GTH_POTENTIALS', 'CHARGE': 0, 'UKS': 'F', 'MULTIPLICITY': 1, 'MGRID': {'CUTOFF': 400, 'REL_CUTOFF': 50, 'NGRIDS': 4}, 'QS': {'EPS_DEFAULT': '1.0E-12'}, 'SCF': {'SCF_GUESS': 'ATOMIC', 'EPS_SCF': '1.0E-6', 'MAX_SCF': 50}, 'XC': {'XC_FUNCTIONAL': {'_': 'PBE'}}}, 'SUBSYS': {'CELL': {'A': '10 .0 .0', 'B': '.0 10 .0', 'C': '.0 .0 10'}, 'COORD': {'@include': 'coord.xyz'}, 'KIND': {'_': ['H', 'C', 'N'], 'POTENTIAL': ['GTH-PBE-q1', 'GTH-PBE-q4', 'GTH-PBE-q5'], 'BASIS_SET': ['DZVP-MOLOPT-GTH', 'DZVP-MOLOPT-GTH', 'DZVP-MOLOPT-GTH']}}, 'PRINT': {'FORCES': {'_': 'ON'}, 'STRESS_TENSOR': {'_': 'ON'}}}}</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.lib.old_lib.cp2k.update_dict","title":"<code>update_dict(old_d, update_d)</code>","text":"<p>A method to recursive update dict :old_d: old dictionary :update_d: some update value written in dictionary form.</p>"},{"location":"alff_api/#alff.lib.old_lib.cp2k.iterdict","title":"<code>iterdict(d, out_list, flag=None, indent=0)</code>","text":"<p>:doc: a recursive expansion of dictionary into cp2k input :k: current key  current value :d: current dictionary under expansion :flag: used to record dictionary state. if flag is None, it means we are in top level dict. flag is a string. :indent: intent for current section.</p>"},{"location":"alff_api/#alff.lib.old_lib.cp2k.make_cp2k_input","title":"<code>make_cp2k_input(sys_data, fp_params)</code>","text":""},{"location":"alff_api/#alff.lib.old_lib.cp2k.make_cp2k_xyz","title":"<code>make_cp2k_xyz(sys_data)</code>","text":""},{"location":"alff_api/#alff.lib.old_lib.cp2k.make_cp2k_input_from_external","title":"<code>make_cp2k_input_from_external(sys_data, exinput_path)</code>","text":""},{"location":"alff_api/#alff.lib.old_lib.ele_temp","title":"<code>ele_temp</code>","text":""},{"location":"alff_api/#alff.lib.old_lib.ele_temp.NBandsEsti","title":"<code>NBandsEsti(test_list)</code>","text":"<code>pref = float(fp.readline())</code> <code>instance-attribute</code> \u00b6 <code></code> <code>err = float(fp.readline())</code> <code>instance-attribute</code> \u00b6 <code></code> <code>save(fname)</code> \u00b6 <code></code> <code>predict(target_dir, tolerance=0.5)</code> \u00b6"},{"location":"alff_api/#alff.lib.old_lib.gaussian","title":"<code>gaussian</code>","text":""},{"location":"alff_api/#alff.lib.old_lib.gaussian.detect_multiplicity","title":"<code>detect_multiplicity(symbols)</code>","text":""},{"location":"alff_api/#alff.lib.old_lib.gaussian.make_gaussian_input","title":"<code>make_gaussian_input(sys_data, fp_params)</code>","text":""},{"location":"alff_api/#alff.lib.old_lib.gaussian.take_cluster","title":"<code>take_cluster(old_conf_name, type_map, idx, jdata)</code>","text":""},{"location":"alff_api/#alff.lib.old_lib.lammps","title":"<code>lammps</code>","text":""},{"location":"alff_api/#alff.lib.old_lib.lammps.ret","title":"<code>ret = get_dumped_forces('40.lammpstrj')</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.lib.old_lib.lammps.make_lammps_input","title":"<code>make_lammps_input(ensemble, conf_file, graphs, nsteps, dt, neidelay, trj_freq, mass_map, temp, jdata, tau_t=0.1, pres=None, tau_p=0.5, pka_e=None, ele_temp_f=None, ele_temp_a=None, max_seed=1000000, nopbc=False, deepmd_version='0.1', nbeads=None)</code>","text":""},{"location":"alff_api/#alff.lib.old_lib.lammps.get_dumped_forces","title":"<code>get_dumped_forces(file_name)</code>","text":""},{"location":"alff_api/#alff.lib.old_lib.lammps.get_all_dumped_forces","title":"<code>get_all_dumped_forces(file_name)</code>","text":""},{"location":"alff_api/#alff.lib.old_lib.make_calypso","title":"<code>make_calypso</code>","text":""},{"location":"alff_api/#alff.lib.old_lib.make_calypso.make_calypso_input","title":"<code>make_calypso_input(nameofatoms, numberofatoms, numberofformula, volume, distanceofion, psoratio, popsize, maxstep, icode, split, vsc, maxnumatom, ctrlrange, pstress, fmax)</code>","text":""},{"location":"alff_api/#alff.lib.old_lib.make_calypso.write_model_devi_out","title":"<code>write_model_devi_out(devi, fname)</code>","text":""},{"location":"alff_api/#alff.lib.old_lib.parse_calypso","title":"<code>parse_calypso</code>","text":""},{"location":"alff_api/#alff.lib.old_lib.pwmat","title":"<code>pwmat</code>","text":""},{"location":"alff_api/#alff.lib.old_lib.pwmat.make_pwmat_input_dict","title":"<code>make_pwmat_input_dict(node1, node2, atom_config, ecut, e_error, rho_error, icmix=None, smearing=None, sigma=None, kspacing=0.5, flag_symm=None)</code>","text":""},{"location":"alff_api/#alff.lib.old_lib.pwmat.write_input_dict","title":"<code>write_input_dict(input_dict)</code>","text":""},{"location":"alff_api/#alff.lib.old_lib.pwmat.make_pwmat_input_user_dict","title":"<code>make_pwmat_input_user_dict(fp_params)</code>","text":""},{"location":"alff_api/#alff.lib.old_lib.pwmat.input_upper","title":"<code>input_upper(dinput)</code>","text":""},{"location":"alff_api/#alff.lib.old_lib.pwscf","title":"<code>pwscf</code>","text":""},{"location":"alff_api/#alff.lib.old_lib.pwscf.ry2ev","title":"<code>ry2ev = 13.605693009</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.lib.old_lib.pwscf.bohr2ang","title":"<code>bohr2ang = 0.52917721067</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.lib.old_lib.pwscf.kbar2evperang3","title":"<code>kbar2evperang3 = 1</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.lib.old_lib.pwscf.make_pwscf_01_runctrl_dict","title":"<code>make_pwscf_01_runctrl_dict(sys_data, idict)</code>","text":""},{"location":"alff_api/#alff.lib.old_lib.pwscf.make_pwscf_input","title":"<code>make_pwscf_input(sys_data, fp_pp_files, fp_params, user_input=True)</code>","text":""},{"location":"alff_api/#alff.lib.old_lib.pwscf.get_block","title":"<code>get_block(lines, keyword, skip=0)</code>","text":""},{"location":"alff_api/#alff.lib.old_lib.pwscf.get_types","title":"<code>get_types(lines)</code>","text":""},{"location":"alff_api/#alff.lib.old_lib.pwscf.get_cell","title":"<code>get_cell(lines)</code>","text":""},{"location":"alff_api/#alff.lib.old_lib.pwscf.get_coords","title":"<code>get_coords(lines)</code>","text":""},{"location":"alff_api/#alff.lib.old_lib.pwscf.get_natoms","title":"<code>get_natoms(lines)</code>","text":""},{"location":"alff_api/#alff.lib.old_lib.pwscf.get_atom_types","title":"<code>get_atom_types(lines)</code>","text":""},{"location":"alff_api/#alff.lib.old_lib.pwscf.get_energy","title":"<code>get_energy(lines)</code>","text":""},{"location":"alff_api/#alff.lib.old_lib.pwscf.get_force","title":"<code>get_force(lines)</code>","text":""},{"location":"alff_api/#alff.lib.old_lib.pwscf.get_stress","title":"<code>get_stress(lines, cells)</code>","text":""},{"location":"alff_api/#alff.lib.old_lib.pwscf.cvt_1frame","title":"<code>cvt_1frame(fin, fout)</code>","text":""},{"location":"alff_api/#alff.lib.old_lib.run_calypso","title":"<code>run_calypso</code>","text":"<p>calypso as model devi engine: 1. gen_structures 2. analysis 3. model devi.</p>"},{"location":"alff_api/#alff.lib.old_lib.run_calypso.train_name","title":"<code>train_name = '00.train'</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.lib.old_lib.run_calypso.model_devi_name","title":"<code>model_devi_name = '01.model_devi'</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.lib.old_lib.run_calypso.fp_name","title":"<code>fp_name = '02.fp'</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.lib.old_lib.run_calypso.calypso_run_opt_name","title":"<code>calypso_run_opt_name = 'gen_stru_analy'</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.lib.old_lib.run_calypso.calypso_model_devi_name","title":"<code>calypso_model_devi_name = 'model_devi_results'</code>  <code>module-attribute</code>","text":""},{"location":"alff_api/#alff.lib.old_lib.run_calypso.gen_structures","title":"<code>gen_structures(iter_index, jdata, mdata, caly_run_path, current_idx, length_of_caly_runopt_list)</code>","text":""},{"location":"alff_api/#alff.lib.old_lib.run_calypso.gen_main","title":"<code>gen_main(iter_index, jdata, mdata, caly_run_opt_list, gen_idx)</code>","text":""},{"location":"alff_api/#alff.lib.old_lib.run_calypso.analysis","title":"<code>analysis(iter_index, jdata, calypso_model_devi_path)</code>","text":""},{"location":"alff_api/#alff.lib.old_lib.run_calypso.run_calypso_model_devi","title":"<code>run_calypso_model_devi(iter_index, jdata, mdata)</code>","text":""},{"location":"alff_api/#alff.lib.old_lib.siesta","title":"<code>siesta</code>","text":""},{"location":"alff_api/#alff.lib.old_lib.siesta.make_siesta_input","title":"<code>make_siesta_input(sys_data, fp_pp_files, fp_params)</code>","text":""},{"location":"alff_api/#alff.lib.util","title":"<code>util</code>","text":"<p>some common utilities for generator, auto_test and data</p>"},{"location":"alff_api/#alff.lib.util.print_pkg_info","title":"<code>print_pkg_info(dep_modules=['sevenn', 'ase', 'numpy', 'scipy', 'dpdispatcher', 'thutil'])</code>","text":""},{"location":"alff_api/#alff.lib.util.logo_text","title":"<code>logo_text()</code>","text":""},{"location":"alff_api/#alff.lib.util.record_iter","title":"<code>record_iter(filename, iter_idx, stage_idx)</code>","text":""},{"location":"alff_api/#alff.lib.util.center_text","title":"<code>center_text(input_text='example', fill='-', max_length=60)</code>","text":"<p>Create a line with centered text.</p>"},{"location":"alff_api/#alff.lib.util.box_text","title":"<code>box_text(input_text='', fill=' ', sp='|', max_length=60)</code>","text":"<p>Put the string at the center of |  |.</p>"},{"location":"alff_api/#alff.lib.util.make_iter_name","title":"<code>make_iter_name(iter_idx: int) -&gt; str</code>","text":""},{"location":"alff_api/#alff.lib.util.create_path","title":"<code>create_path(path)</code>","text":""},{"location":"alff_api/#alff.lib.util.symlink_user_forward_files","title":"<code>symlink_user_forward_files(mdata, task_type, work_path, fmt_task=None)</code>","text":"<p>Symlink user-defined forward_common_files Current path should be work_path, such as 00.train.</p>"},{"location":"alff_api/#alff.lib.util.symlink_user_forward_files--parameters","title":"Parameters","text":"<p>mdata : dict     machine parameters task_type : str     task_type, such as \"train\" work_path : str     work_path, such as \"iter.000001/00.train\" fmt_task : dict     formats of tasks</p>"},{"location":"alff_api/#alff.lib.util.symlink_user_forward_files--returns","title":"Returns","text":"<p>None</p>"},{"location":"alff_api/#alff.lib.util.replace","title":"<code>replace(file_name, pattern, subst)</code>","text":""},{"location":"alff_api/#alff.lib.util.copy_file_list","title":"<code>copy_file_list(file_list, from_path, to_path)</code>","text":""},{"location":"alff_api/#alff.lib.util.cmd_append_log","title":"<code>cmd_append_log(cmd, log_file)</code>","text":""},{"location":"alff_api/#alff.lib.util.repeat_to_length","title":"<code>repeat_to_length(input_str: str, length) -&gt; str</code>","text":""},{"location":"alff_api/#alff.lib.util.expand_sys_str","title":"<code>expand_sys_str(root_dir: Union[str, Path]) -&gt; list[str]</code>","text":"<p>Recursively iterate over directories taking those that contain <code>type.raw</code> file.</p> <p>If root_dir is a file but not a directory, it will be assumed as an HDF5 file.</p>"},{"location":"alff_api/#alff.lib.util.expand_sys_str--parameters","title":"Parameters","text":"<p>root_dir : Union[str, Path]     starting directory</p>"},{"location":"alff_api/#alff.lib.util.expand_sys_str--returns","title":"Returns","text":"<p>List[str]     list of string pointing to system directories</p>"},{"location":"alff_api/#alff.lib.util.expand_sys_str--raises","title":"Raises","text":"<p>RuntimeError     No system was found in the directory</p>"},{"location":"alff_api/#alff.lib.util.expand_idx","title":"<code>expand_idx(in_list: list[int, str]) -&gt; list[int]</code>","text":"<p>Expand the input list of indices to a list of integers. Eg: in_list = [1, 2, \"3-5:2\", \"6-10\"]</p>"},{"location":"alff_api/#alff.lib.util.normalize","title":"<code>normalize(arginfo: Argument, data: dict, strict_check: bool = True) -&gt; dict</code>","text":"<p>Normalize and check input data.</p>"},{"location":"alff_api/#alff.lib.util.normalize--parameters","title":"Parameters","text":"<p>arginfo : dargs.Argument     argument information data : dict     input data strict_check : bool, default=True     strict check data or not</p>"},{"location":"alff_api/#alff.lib.util.normalize--returns","title":"Returns","text":"<p>dict     normalized data</p>"},{"location":"alff_api/#alff.lib.util.convert_training_data_to_hdf5","title":"<code>convert_training_data_to_hdf5(input_files: list[str], h5_file: str)</code>","text":"<p>Convert training data to HDF5 format and update the input files.</p>"},{"location":"alff_api/#alff.lib.util.convert_training_data_to_hdf5--parameters","title":"Parameters","text":"<p>input_files : list of str     DeePMD-kit input file names h5_file : str     HDF5 file name</p>"},{"location":"alff_api/#alff.lib.util.set_directory","title":"<code>set_directory(path: Path)</code>","text":"<p>Sets the current working path within the context.</p>"},{"location":"alff_api/#alff.lib.util.set_directory--parameters","title":"Parameters","text":"<p>path : Path     The path to the cwd</p>"},{"location":"alff_api/#alff.lib.util.set_directory--yields","title":"Yields","text":"<p>None</p>"},{"location":"alff_api/#alff.lib.util.set_directory--examples","title":"Examples","text":"<p>with set_directory(\"some_path\"): ...    do_something()</p>"},{"location":"alff_api/#alff.lib.util.setup_ele_temp","title":"<code>setup_ele_temp(atomic: bool)</code>","text":"<p>Set electronic temperature as required input data.</p>"},{"location":"alff_api/#alff.lib.util.setup_ele_temp--parameters","title":"Parameters","text":"<p>atomic : bool     Whether to use atomic temperature or frame temperature</p>"},{"location":"alff_api/#alff.lib.util.get_atomic_masses","title":"<code>get_atomic_masses(atom)</code>","text":""},{"location":"alff_api/#alff.run","title":"<code>run</code>","text":"iter <p>0_train 1_model_devi 2_fp 3_data</p>"},{"location":"alff_api/#alff.run.get_job_names","title":"<code>get_job_names(pdict)</code>","text":""},{"location":"alff_api/#alff.run.pre_fp_task_name","title":"<code>pre_fp_task_name(struct_idx, counter)</code>","text":""},{"location":"alff_api/#alff.run.get_sys_index","title":"<code>get_sys_index(task)</code>","text":""},{"location":"alff_api/#alff.run.copy_model","title":"<code>copy_model(numb_model, prv_iter_idx, cur_iter_idx, suffix='.pb')</code>","text":""},{"location":"alff_api/#alff.run.poscar_natoms","title":"<code>poscar_natoms(lines)</code>","text":""},{"location":"alff_api/#alff.run.pre_train","title":"<code>pre_train(iter_idx, pdict, mdict)</code>","text":""},{"location":"alff_api/#alff.run.run_train","title":"<code>run_train(iter_idx, pdict, mdict)</code>","text":""},{"location":"alff_api/#alff.run.post_train","title":"<code>post_train(iter_idx, pdict, mdict)</code>","text":""},{"location":"alff_api/#alff.run.expand_matrix_values","title":"<code>expand_matrix_values(target_list, cur_idx=0)</code>","text":""},{"location":"alff_api/#alff.run.pre_md","title":"<code>pre_md(iter_idx, pdict, mdict)</code>","text":""},{"location":"alff_api/#alff.run.pre_md_lammps_7net","title":"<code>pre_md_lammps_7net(iter_idx, pdict, mdict)</code>","text":""},{"location":"alff_api/#alff.run.run_md","title":"<code>run_md(iter_idx, pdict, mdict)</code>","text":""},{"location":"alff_api/#alff.run.run_md_lammps_7net","title":"<code>run_md_lammps_7net(iter_idx, pdict, mdict)</code>","text":""},{"location":"alff_api/#alff.run.run_md_model_devi","title":"<code>run_md_model_devi(iter_idx, pdict, mdict)</code>","text":""},{"location":"alff_api/#alff.run.post_md","title":"<code>post_md(iter_idx, pdict, mdict)</code>","text":""},{"location":"alff_api/#alff.run.check_cluster","title":"<code>check_cluster(conf_name, fp_cluster_vacuum, fmt='lammps/dump')</code>","text":""},{"location":"alff_api/#alff.run.check_bad_box","title":"<code>check_bad_box(conf_name, criteria, fmt='lammps/dump')</code>","text":""},{"location":"alff_api/#alff.run.pre_fp_vasp","title":"<code>pre_fp_vasp(iter_idx, pdict)</code>","text":""},{"location":"alff_api/#alff.run.pre_fp_amber_diff","title":"<code>pre_fp_amber_diff(iter_idx: int, pdict: dict)</code>","text":"<p>Run amber twice to calculate high-level and low-level potential, and then generate difference between them.</p> <p>Besides AMBER, one needs to install <code>dpamber</code> package, which is avaiable at https://github.com/njzjz/dpamber</p> <p>Currently, it should be used with the AMBER model_devi driver.</p>"},{"location":"alff_api/#alff.run.pre_fp_amber_diff--parameters","title":"Parameters","text":"<p>iter_idx : int     iter index pdict : dict     Run parameters. The following parameters are used in this method:         mdin_prefix : str             The path prefix to AMBER mdin files         qm_region : list[str]             AMBER mask of the QM region. Each mask maps to a system.         qm_charge : list[int]             Charge of the QM region. Each charge maps to a system.         high_level : str             high level method         low_level : str             low level method         fp_param : dict             This parameters includes:                 high_level_mdin : str                     High-level AMBER mdin file. %qm_theory%, %qm_region%,                     and %qm_charge% will be replace.                 low_level_mdin : str                     Low-level AMBER mdin file. %qm_theory%, %qm_region%,                     and %qm_charge% will be replace.         parm7_prefix : str             The path prefix to AMBER PARM7 files         parm7 : list[str]             List of paths to AMBER PARM7 files. Each file maps to a system.</p>"},{"location":"alff_api/#alff.run.pre_fp_amber_diff--references","title":"References","text":"<p>.. [1] Development of Range-Corrected Deep Learning Potentials for Fast, Accurate Quantum    Mechanical/Molecular Mechanical Simulations of Chemical Reactions in Solution,    Jinzhe Zeng, Timothy J. Giese, \u015e\u00f6len Ekesan, and Darrin M. York, Journal of Chemical    Theory and Computation 2021 17 (11), 6993-7009</p>"},{"location":"alff_api/#alff.run.pre_fp_custom","title":"<code>pre_fp_custom(iter_idx, pdict)</code>","text":"<p>Make input file for customized FP style.</p> <p>Convert the POSCAR file to custom format.</p>"},{"location":"alff_api/#alff.run.pre_fp_custom--parameters","title":"Parameters","text":"<p>iter_idx : int     iter index pdict : dict     Run parameters.</p>"},{"location":"alff_api/#alff.run.pre_fp","title":"<code>pre_fp(iter_idx, pdict, mdict)</code>","text":"<p>Select the candidate strutures and make the input file of FP calculation.</p>"},{"location":"alff_api/#alff.run.pre_fp--parameters","title":"Parameters","text":"<p>iter_idx : int     iter index pdict : dict     Run parameters. mdict : dict     Machine parameters.</p>"},{"location":"alff_api/#alff.run.pre_fp_calculation","title":"<code>pre_fp_calculation(iter_idx, pdict, mdict)</code>","text":"<p>Make the input file of FP calculation.</p>"},{"location":"alff_api/#alff.run.pre_fp_calculation--parameters","title":"Parameters","text":"<p>iter_idx : int     iter index pdict : dict     Run parameters. mdict : dict     Machine parameters.</p>"},{"location":"alff_api/#alff.run.run_fp_inner","title":"<code>run_fp_inner(iter_idx, pdict, mdict, forward_files, backward_files, check_fin, log_file='fp.log', forward_common_files=[])</code>","text":""},{"location":"alff_api/#alff.run.run_fp","title":"<code>run_fp(iter_idx, pdict, mdict)</code>","text":""},{"location":"alff_api/#alff.run.post_fp_check_fail","title":"<code>post_fp_check_fail(iter_idx, pdict, rfailed=None)</code>","text":""},{"location":"alff_api/#alff.run.post_fp_vasp","title":"<code>post_fp_vasp(iter_idx, pdict, rfailed=None)</code>","text":""},{"location":"alff_api/#alff.run.post_fp_pwscf","title":"<code>post_fp_pwscf(iter_idx, pdict)</code>","text":""},{"location":"alff_api/#alff.run.post_fp_abacus_scf","title":"<code>post_fp_abacus_scf(iter_idx, pdict)</code>","text":""},{"location":"alff_api/#alff.run.post_fp_siesta","title":"<code>post_fp_siesta(iter_idx, pdict)</code>","text":""},{"location":"alff_api/#alff.run.post_fp_amber_diff","title":"<code>post_fp_amber_diff(iter_idx, pdict)</code>","text":""},{"location":"alff_api/#alff.run.post_fp_custom","title":"<code>post_fp_custom(iter_idx, pdict)</code>","text":"<p>Post fp for custom fp. Collect data from user-defined <code>output_fn</code>.</p>"},{"location":"alff_api/#alff.run.post_fp_custom--parameters","title":"Parameters","text":"<p>iter_idx : int     The index of the current iteration. pdict : dict     The parameter data.</p>"},{"location":"alff_api/#alff.run.post_fp","title":"<code>post_fp(iter_idx, pdict)</code>","text":""},{"location":"alff_api/#alff.run.run_iter","title":"<code>run_iter(configfile_param, configfile_machine)</code>","text":"<p>Run main loop of active learning.</p>"},{"location":"alff_cli/","title":"CLI","text":"<p>ALLF provides command-line interface (CLI) to run the ALFF processes:</p> <ul> <li>Active learning process</li> <li>generate data for training ML forcefields</li> <li>convert MPtrj files to XYZ datasets.</li> <li>etc.</li> </ul>"},{"location":"alff_cli/#alff","title":"alff","text":"<p>Run the main ALFF active learning process.</p> <pre><code>alff PARAM.yaml MACHINE.yaml\n</code></pre> <ul> <li><code>PARAM.yaml</code>: The parameters of the generator.</li> <li><code>MACHINE.yaml</code>: The settings of the machines running the generator.</li> </ul>"},{"location":"alff_cli/#data-generator","title":"Data generator","text":"<p>Generate data for training ML forcefields.</p> <pre><code>alff_gen_bulk PARAM.yaml MACHINE.yaml\n</code></pre> <ul> <li><code>PARAM.yaml</code>: The parameters of the generator.</li> <li><code>MACHINE.yaml</code>: The settings of the machines running the generator.</li> </ul>"},{"location":"alff_cli/#dataset-tools","title":"Dataset tools","text":"<p>Convert MPtrj to XYZ</p> <pre><code>chgnet_to_xyz MPtrj.json\n</code></pre> <ul> <li><code>MPtrj.json</code>: The MPtrj file to be converted to XYZ dataset.</li> </ul>"},{"location":"alff_info/","title":"alff parameters","text":""},{"location":"alff_info/#alff.lib.arginfo","title":"<code>alff.lib.arginfo</code>","text":"<p><code>alff</code> accepts a configuration file in YAML/JSON/JSONC format.</p>"},{"location":"alff_info/#alff.lib.arginfo.param","title":"<code>param()</code>","text":"<p>ALFF parameters.</p>"},{"location":"alff_info/#alff.lib.arginfo.param--parameters","title":"Parameters","text":"<pre><code>mlp_engine: str\n    The engine to use for training the MLP model. Choices: 'sevenn', 'mace'\nnumb_models: int\n    Number of models to train.\ninit_data_paths: list[str]\n    List of paths to the initial data.\ndistributed: bool\n    Whether to use distributed training.\ndistributed_backend: str\n    The Pytorch backend to use for distributed training. Choices: 'nccl', 'mpi'\nsevenn_args: dict\n    SevenNet's parameters.\nmace_args: dict\n    Mace's parameters.\n</code></pre>"},{"location":"alff_info/#alff.lib.arginfo.not_use_param_seveen","title":"<code>not_use_param_seveen()</code>","text":"<p>SevenNet parameters that are not applicable.</p> <p>These parameters are either generated by the ALFF or are not required for running the ALFF.</p>"},{"location":"alff_info/#alff.lib.arginfo.not_use_param_seveen--parameters","title":"Parameters","text":"<pre><code>train.random_seed: int\n    Random seed for reproducibility.\ndata.load_dataset_path: list[str]\n    List of paths to the dataset.\n</code></pre>"},{"location":"alff_info/#alff.lib.arginfo.machine","title":"<code>machine()</code>","text":"<p>ALFF parameters for running on a clusters.</p>"},{"location":"mace_train_param/","title":"MACE train","text":""},{"location":"mace_train_param/#mace-parameters-for-training","title":"MACE parameters for training","text":"<p>See more development parameters here.</p>"},{"location":"mace_train_param/#name-and-seed","title":"Name and seed","text":"<pre><code>    parser.add_argument(\"--name\", help=\"experiment name\", required=True)\n    parser.add_argument(\"--seed\", help=\"random seed\", type=int, default=123)\n</code></pre>"},{"location":"mace_train_param/#directories","title":"Directories","text":"<pre><code>    parser.add_argument(\n        \"--work_dir\",\n        help=\"set directory for all files and folders\",\n        type=str,\n        default=\".\",\n    )\n    parser.add_argument(\n        \"--log_dir\", help=\"directory for log files\", type=str, default=None\n    )\n    parser.add_argument(\n        \"--model_dir\", help=\"directory for final model\", type=str, default=None\n    )\n    parser.add_argument(\n        \"--checkpoints_dir\",\n        help=\"directory for checkpoint files\",\n        type=str,\n        default=None,\n    )\n    parser.add_argument(\n        \"--results_dir\", help=\"directory for results\", type=str, default=None\n    )\n    parser.add_argument(\n        \"--downloads_dir\", help=\"directory for downloads\", type=str, default=None\n    )\n\n    ## Device and logging\n    parser.add_argument(\n        \"--device\",\n        help=\"select device\",\n        type=str,\n        choices=[\"cpu\", \"cuda\", \"mps\", \"xpu\"],\n        default=\"cpu\",\n    )\n    parser.add_argument(\n        \"--default_dtype\",\n        help=\"set default dtype\",\n        type=str,\n        choices=[\"float32\", \"float64\"],\n        default=\"float64\",\n    )\n    parser.add_argument(\n        \"--distributed\",\n        help=\"train in multi-GPU data parallel mode\",\n        action=\"store_true\",\n        default=False,\n    )\n    parser.add_argument(\"--log_level\", help=\"log level\", type=str, default=\"INFO\")\n\n    parser.add_argument(\n        \"--error_table\",\n        help=\"Type of error table produced at the end of the training\",\n        type=str,\n        choices=[\n            \"PerAtomRMSE\",\n            \"TotalRMSE\",\n            \"PerAtomRMSEstressvirials\",\n            \"PerAtomMAEstressvirials\",\n            \"PerAtomMAE\",\n            \"TotalMAE\",\n            \"DipoleRMSE\",\n            \"DipoleMAE\",\n            \"EnergyDipoleRMSE\",\n        ],\n        default=\"PerAtomRMSE\",\n    )\n</code></pre>"},{"location":"mace_train_param/#model","title":"Model","text":"<pre><code>    parser.add_argument(\n        \"--model\",\n        help=\"model type\",\n        default=\"MACE\",\n        choices=[\n            \"BOTNet\",\n            \"MACE\",\n            \"ScaleShiftMACE\",\n            \"ScaleShiftBOTNet\",\n            \"AtomicDipolesMACE\",\n            \"EnergyDipolesMACE\",\n        ],\n    )\n    parser.add_argument(\n        \"--r_max\", help=\"distance cutoff (in Ang)\", type=float, default=5.0\n    )\n    parser.add_argument(\n        \"--radial_type\",\n        help=\"type of radial basis functions\",\n        type=str,\n        default=\"bessel\",\n        choices=[\"bessel\", \"gaussian\", \"chebyshev\"],\n    )\n    parser.add_argument(\n        \"--num_radial_basis\",\n        help=\"number of radial basis functions\",\n        type=int,\n        default=8,\n    )\n    parser.add_argument(\n        \"--num_cutoff_basis\",\n        help=\"number of basis functions for smooth cutoff\",\n        type=int,\n        default=5,\n    )\n    parser.add_argument(\n        \"--pair_repulsion\",\n        help=\"use pair repulsion term with ZBL potential\",\n        action=\"store_true\",\n        default=False,\n    )\n    parser.add_argument(\n        \"--distance_transform\",\n        help=\"use distance transform for radial basis functions\",\n        default=\"None\",\n        choices=[\"None\", \"Agnesi\", \"Soft\"],\n    )\n    parser.add_argument(\n        \"--interaction\",\n        help=\"name of interaction block\",\n        type=str,\n        default=\"RealAgnosticResidualInteractionBlock\",\n        choices=[\n            \"RealAgnosticResidualInteractionBlock\",\n            \"RealAgnosticAttResidualInteractionBlock\",\n            \"RealAgnosticInteractionBlock\",\n        ],\n    )\n    parser.add_argument(\n        \"--interaction_first\",\n        help=\"name of interaction block\",\n        type=str,\n        default=\"RealAgnosticResidualInteractionBlock\",\n        choices=[\n            \"RealAgnosticResidualInteractionBlock\",\n            \"RealAgnosticInteractionBlock\",\n        ],\n    )\n    parser.add_argument(\n        \"--max_ell\", help=r\"highest \\ell of spherical harmonics\", type=int, default=3\n    )\n    parser.add_argument(\n        \"--correlation\", help=\"correlation order at each layer\", type=int, default=3\n    )\n    parser.add_argument(\n        \"--num_interactions\", help=\"number of interactions\", type=int, default=2\n    )\n    parser.add_argument(\n        \"--MLP_irreps\",\n        help=\"hidden irreps of the MLP in last readout\",\n        type=str,\n        default=\"16x0e\",\n    )\n    parser.add_argument(\n        \"--radial_MLP\",\n        help=\"width of the radial MLP\",\n        type=str,\n        default=\"[64, 64, 64]\",\n    )\n    parser.add_argument(\n        \"--hidden_irreps\",\n        help=\"irreps for hidden node states\",\n        type=str,\n        default=None,\n    )\n    ## add option to specify irreps by channel number and max L\n    parser.add_argument(\n        \"--num_channels\",\n        help=\"number of embedding channels\",\n        type=int,\n        default=None,\n    )\n    parser.add_argument(\n        \"--max_L\",\n        help=\"max L equivariance of the message\",\n        type=int,\n        default=None,\n    )\n    parser.add_argument(\n        \"--gate\",\n        help=\"non linearity for last readout\",\n        type=str,\n        default=\"silu\",\n        choices=[\"silu\", \"tanh\", \"abs\", \"None\"],\n    )\n    parser.add_argument(\n        \"--scaling\",\n        help=\"type of scaling to the output\",\n        type=str,\n        default=\"rms_forces_scaling\",\n        choices=[\"std_scaling\", \"rms_forces_scaling\", \"no_scaling\"],\n    )\n    parser.add_argument(\n        \"--avg_num_neighbors\",\n        help=\"normalization factor for the message\",\n        type=float,\n        default=1,\n    )\n    parser.add_argument(\n        \"--compute_avg_num_neighbors\",\n        help=\"normalization factor for the message\",\n        type=str2bool,\n        default=True,\n    )\n    parser.add_argument(\n        \"--compute_stress\",\n        help=\"Select True to compute stress\",\n        type=str2bool,\n        default=False,\n    )\n    parser.add_argument(\n        \"--compute_forces\",\n        help=\"Select True to compute forces\",\n        type=str2bool,\n        default=True,\n    )\n</code></pre>"},{"location":"mace_train_param/#dataset","title":"Dataset","text":"<pre><code>    parser.add_argument(\n        \"--train_file\",\n        help=\"Training set file, format is .xyz or .h5\",\n        type=str,\n        required=False,\n    )\n    parser.add_argument(\n        \"--valid_file\",\n        help=\"Validation set .xyz or .h5 file\",\n        default=None,\n        type=str,\n        required=False,\n    )\n    parser.add_argument(\n        \"--valid_fraction\",\n        help=\"Fraction of training set used for validation\",\n        type=float,\n        default=0.1,\n        required=False,\n    )\n    parser.add_argument(\n        \"--test_file\",\n        help=\"Test set .xyz pt .h5 file\",\n        type=str,\n    )\n    parser.add_argument(\n        \"--test_dir\",\n        help=\"Path to directory with test files named as test_*.h5\",\n        type=str,\n        default=None,\n        required=False,\n    )\n    parser.add_argument(\n        \"--multi_processed_test\",\n        help=\"Boolean value for whether the test data was multiprocessed\",\n        type=str2bool,\n        default=False,\n        required=False,\n    )\n    parser.add_argument(\n        \"--num_workers\",\n        help=\"Number of workers for data loading\",\n        type=int,\n        default=0,\n    )\n    parser.add_argument(\n        \"--pin_memory\",\n        help=\"Pin memory for data loading\",\n        default=True,\n        type=str2bool,\n    )\n    parser.add_argument(\n        \"--atomic_numbers\",\n        help=\"List of atomic numbers\",\n        type=str,\n        default=None,\n        required=False,\n    )\n    parser.add_argument(\n        \"--mean\",\n        help=\"Mean energy per atom of training set\",\n        type=float,\n        default=None,\n        required=False,\n    )\n    parser.add_argument(\n        \"--std\",\n        help=\"Standard deviation of force components in the training set\",\n        type=float,\n        default=None,\n        required=False,\n    )\n    parser.add_argument(\n        \"--statistics_file\",\n        help=\"json file containing statistics of training set\",\n        type=str,\n        default=None,\n        required=False,\n    )\n    parser.add_argument(\n        \"--E0s\",\n        help=\"Dictionary of isolated atom energies\",\n        type=str,\n        default=None,\n        required=False,\n    )\n\n\n\n    ## Keys\n    parser.add_argument(\n        \"--energy_key\",\n        help=\"Key of reference energies in training xyz\",\n        type=str,\n        default=\"REF_energy\",\n    )\n    parser.add_argument(\n        \"--forces_key\",\n        help=\"Key of reference forces in training xyz\",\n        type=str,\n        default=\"REF_forces\",\n    )\n    parser.add_argument(\n        \"--virials_key\",\n        help=\"Key of reference virials in training xyz\",\n        type=str,\n        default=\"REF_virials\",\n    )\n    parser.add_argument(\n        \"--stress_key\",\n        help=\"Key of reference stress in training xyz\",\n        type=str,\n        default=\"REF_stress\",\n    )\n    parser.add_argument(\n        \"--dipole_key\",\n        help=\"Key of reference dipoles in training xyz\",\n        type=str,\n        default=\"REF_dipole\",\n    )\n    parser.add_argument(\n        \"--charges_key\",\n        help=\"Key of atomic charges in training xyz\",\n        type=str,\n        default=\"REF_charges\",\n    )\n</code></pre>"},{"location":"mace_train_param/#fine-tuning","title":"Fine-tuning","text":"<pre><code>    parser.add_argument(\n        \"--foundation_filter_elements\",\n        help=\"Filter element during fine-tuning\",\n        type=str2bool,\n        default=True,\n        required=False,\n    )\n    parser.add_argument(\n        \"--heads\",\n        help=\"Dict of heads: containing individual files and E0s\",\n        type=str,\n        default=None,\n        required=False,\n    )\n    parser.add_argument(\n        \"--multiheads_finetuning\",\n        help=\"Boolean value for whether the model is multiheaded\",\n        type=str2bool,\n        default=True,\n    )\n    parser.add_argument(\n        \"--weight_pt_head\",\n        help=\"Weight of the pretrained head in the loss function\",\n        type=float,\n        default=1.0,\n    )\n    parser.add_argument(\n        \"--num_samples_pt\",\n        help=\"Number of samples in the pretrained head\",\n        type=int,\n        default=1000,\n    )\n    parser.add_argument(\n        \"--subselect_pt\",\n        help=\"Method to subselect the configurations of the pretraining set\",\n        choices=[\"fps\", \"random\"],\n        default=\"random\",\n    )\n    parser.add_argument(\n        \"--pt_train_file\",\n        help=\"Training set file for the pretrained head\",\n        type=str,\n        default=None,\n    )\n    parser.add_argument(\n        \"--pt_valid_file\",\n        help=\"Validation set file for the pretrained head\",\n        type=str,\n        default=None,\n    )\n    parser.add_argument(\n        \"--keep_isolated_atoms\",\n        help=\"Keep isolated atoms in the dataset, useful for transfer learning\",\n        type=str2bool,\n        default=False,\n    )\n</code></pre>"},{"location":"mace_train_param/#loss-and-optimization","title":"Loss and optimization","text":"<pre><code>    parser.add_argument(\n        \"--loss\",\n        help=\"type of loss\",\n        default=\"weighted\",\n        choices=[\n            \"ef\",\n            \"weighted\",\n            \"forces_only\",\n            \"virials\",\n            \"stress\",\n            \"dipole\",\n            \"huber\",\n            \"universal\",\n            \"energy_forces_dipole\",\n        ],\n    )\n    parser.add_argument(\n        \"--forces_weight\", help=\"weight of forces loss\", type=float, default=100.0\n    )\n    parser.add_argument(\n        \"--swa_forces_weight\",\n        \"--stage_two_forces_weight\",\n        help=\"weight of forces loss after starting Stage Two (previously called swa)\",\n        type=float,\n        default=100.0,\n        dest=\"swa_forces_weight\",\n    )\n    parser.add_argument(\n        \"--energy_weight\", help=\"weight of energy loss\", type=float, default=1.0\n    )\n    parser.add_argument(\n        \"--swa_energy_weight\",\n        \"--stage_two_energy_weight\",\n        help=\"weight of energy loss after starting Stage Two (previously called swa)\",\n        type=float,\n        default=1000.0,\n        dest=\"swa_energy_weight\",\n    )\n    parser.add_argument(\n        \"--virials_weight\", help=\"weight of virials loss\", type=float, default=1.0\n    )\n    parser.add_argument(\n        \"--swa_virials_weight\",\n        \"--stage_two_virials_weight\",\n        help=\"weight of virials loss after starting Stage Two (previously called swa)\",\n        type=float,\n        default=10.0,\n        dest=\"swa_virials_weight\",\n    )\n    parser.add_argument(\n        \"--stress_weight\", help=\"weight of virials loss\", type=float, default=1.0\n    )\n    parser.add_argument(\n        \"--swa_stress_weight\",\n        \"--stage_two_stress_weight\",\n        help=\"weight of stress loss after starting Stage Two (previously called swa)\",\n        type=float,\n        default=10.0,\n        dest=\"swa_stress_weight\",\n    )\n    parser.add_argument(\n        \"--dipole_weight\", help=\"weight of dipoles loss\", type=float, default=1.0\n    )\n    parser.add_argument(\n        \"--swa_dipole_weight\",\n        \"--stage_two_dipole_weight\",\n        help=\"weight of dipoles after starting Stage Two (previously called swa)\",\n        type=float,\n        default=1.0,\n        dest=\"swa_dipole_weight\",\n    )\n    parser.add_argument(\n        \"--config_type_weights\",\n        help=\"String of dictionary containing the weights for each config type\",\n        type=str,\n        default='{\"Default\":1.0}',\n    )\n    parser.add_argument(\n        \"--huber_delta\",\n        help=\"delta parameter for huber loss\",\n        type=float,\n        default=0.01,\n    )\n    parser.add_argument(\n        \"--optimizer\",\n        help=\"Optimizer for parameter optimization\",\n        type=str,\n        default=\"adam\",\n        choices=[\"adam\", \"adamw\", \"schedulefree\"],\n    )\n    parser.add_argument(\n        \"--beta\",\n        help=\"Beta parameter for the optimizer\",\n        type=float,\n        default=0.9,\n    )\n    parser.add_argument(\"--batch_size\", help=\"batch size\", type=int, default=10)\n    parser.add_argument(\n        \"--valid_batch_size\", help=\"Validation batch size\", type=int, default=10\n    )\n    parser.add_argument(\n        \"--lr\", help=\"Learning rate of optimizer\", type=float, default=0.01\n    )\n    parser.add_argument(\n        \"--swa_lr\",\n        \"--stage_two_lr\",\n        help=\"Learning rate of optimizer in Stage Two (previously called swa)\",\n        type=float,\n        default=1e-3,\n        dest=\"swa_lr\",\n    )\n    parser.add_argument(\n        \"--weight_decay\", help=\"weight decay (L2 penalty)\", type=float, default=5e-7\n    )\n    parser.add_argument(\n        \"--amsgrad\",\n        help=\"use amsgrad variant of optimizer\",\n        action=\"store_true\",\n        default=True,\n    )\n    parser.add_argument(\n        \"--scheduler\", help=\"Type of scheduler\", type=str, default=\"ReduceLROnPlateau\"\n    )\n    parser.add_argument(\n        \"--lr_factor\", help=\"Learning rate factor\", type=float, default=0.8\n    )\n    parser.add_argument(\n        \"--scheduler_patience\", help=\"Learning rate factor\", type=int, default=50\n    )\n    parser.add_argument(\n        \"--lr_scheduler_gamma\",\n        help=\"Gamma of learning rate scheduler\",\n        type=float,\n        default=0.9993,\n    )\n    parser.add_argument(\n        \"--swa\",\n        \"--stage_two\",\n        help=\"use Stage Two loss weight, which decreases the learning rate and increases the energy weight at the end of the training to help converge them\",\n        action=\"store_true\",\n        default=False,\n        dest=\"swa\",\n    )\n    parser.add_argument(\n        \"--start_swa\",\n        \"--start_stage_two\",\n        help=\"Number of epochs before changing to Stage Two loss weights\",\n        type=int,\n        default=None,\n        dest=\"start_swa\",\n    )\n    parser.add_argument(\n        \"--ema\",\n        help=\"use Exponential Moving Average\",\n        action=\"store_true\",\n        default=False,\n    )\n    parser.add_argument(\n        \"--ema_decay\",\n        help=\"Exponential Moving Average decay\",\n        type=float,\n        default=0.99,\n    )\n    parser.add_argument(\n        \"--max_num_epochs\", help=\"Maximum number of epochs\", type=int, default=2048\n    )\n    parser.add_argument(\n        \"--patience\",\n        help=\"Maximum number of consecutive epochs of increasing loss\",\n        type=int,\n        default=2048,\n    )\n    parser.add_argument(\n        \"--foundation_model\",\n        help=\"Path to the foundation model for transfer learning\",\n        type=str,\n        default=None,\n    )\n    parser.add_argument(\n        \"--foundation_model_readout\",\n        help=\"Use readout of foundation model for transfer learning\",\n        action=\"store_false\",\n        default=True,\n    )\n    parser.add_argument(\n        \"--eval_interval\", help=\"evaluate model every &lt;n&gt; epochs\", type=int, default=1\n    )\n    parser.add_argument(\n        \"--keep_checkpoints\",\n        help=\"keep all checkpoints\",\n        action=\"store_true\",\n        default=False,\n    )\n    parser.add_argument(\n        \"--save_all_checkpoints\",\n        help=\"save all checkpoints\",\n        action=\"store_true\",\n        default=False,\n    )\n    parser.add_argument(\n        \"--restart_latest\",\n        help=\"restart optimizer from latest checkpoint\",\n        action=\"store_true\",\n        default=False,\n    )\n    parser.add_argument(\n        \"--save_cpu\",\n        help=\"Save a model to be loaded on cpu\",\n        action=\"store_true\",\n        default=False,\n    )\n    parser.add_argument(\n        \"--clip_grad\",\n        help=\"Gradient Clipping Value\",\n        type=check_float_or_none,\n        default=10.0,\n    )\n    ## options for using Weights and Biases for experiment tracking\n    ## to install see https://wandb.ai\n    parser.add_argument(\n        \"--wandb\",\n        help=\"Use Weights and Biases for experiment tracking\",\n        action=\"store_true\",\n        default=False,\n    )\n    parser.add_argument(\n        \"--wandb_dir\",\n        help=\"An absolute path to a directory where Weights and Biases metadata will be stored\",\n        type=str,\n        default=None,\n    )\n    parser.add_argument(\n        \"--wandb_project\",\n        help=\"Weights and Biases project name\",\n        type=str,\n        default=\"\",\n    )\n    parser.add_argument(\n        \"--wandb_entity\",\n        help=\"Weights and Biases entity name\",\n        type=str,\n        default=\"\",\n    )\n    parser.add_argument(\n        \"--wandb_name\",\n        help=\"Weights and Biases experiment name\",\n        type=str,\n        default=\"\",\n    )\n    parser.add_argument(\n        \"--wandb_log_hypers\",\n        help=\"The hyperparameters to log in Weights and Biases\",\n        type=list,\n        default=[\n            \"num_channels\",\n            \"max_L\",\n            \"correlation\",\n            \"lr\",\n            \"swa_lr\",\n            \"weight_decay\",\n            \"batch_size\",\n            \"max_num_epochs\",\n            \"start_swa\",\n            \"energy_weight\",\n            \"forces_weight\",\n        ],\n    )\n    return parser\n</code></pre>"},{"location":"sevenn_train_param/","title":"SevenNet parameters for training model","text":"<p>There are preset parameters:</p> <ul> <li>base</li> <li>fine_tune</li> <li>sevennet-0</li> </ul> <p>See full full development parameters here.</p> <p>To access energy, force, and stress, in <code>extxyz</code> dataset, the following keys are used: <pre><code>data:\n    data_format_args:\n        energy_key: 'TotEnergy'\n        force_key: 'force'\n        stress_key: 'stress'\n</code></pre></p>"},{"location":"sevenn_train_param/#base","title":"base","text":"<pre><code># Example input.yaml for training SevenNet.\n# '*' signifies default. You can check log.sevenn for defaults.\n\nmodel:\n    chemical_species: 'Auto'                      # Chemical elements present in the dataset, guess them from load_dataset data if 'auto'\n    cutoff: 5.0                                   # Cutoff radius in Angstroms. If two atoms are within the cutoff, they are connected.\n    channel: 32                                   # The multiplicity(channel) of node features.\n    lmax: 2                                       # Maximum order of irreducible representations (rotation order).\n    num_convolution_layer: 3                      # The number of message passing layers.\n\n    #irreps_manual:                               # Manually set irreps of the model in each layer\n        #- \"128x0e\"\n        #- \"128x0e+64x1e+32x2e\"\n        #- \"128x0e+64x1e+32x2e\"\n        #- \"128x0e+64x1e+32x2e\"\n        #- \"128x0e+64x1e+32x2e\"\n        #- \"128x0e\"\n\n    weight_nn_hidden_neurons: [64, 64]            # Hidden neurons in convolution weight neural network\n    radial_basis:                                 # Function and its parameters to encode radial distance\n        radial_basis_name: 'bessel'               # Only 'bessel' is currently supported\n        bessel_basis_num: 8\n    cutoff_function:                              # Envelop function, multiplied to radial_basis functions to init edge featrues\n        cutoff_function_name: 'poly_cut'          # {'poly_cut' and 'poly_cut_p_value'} or {'XPLOR' and 'cutoff_on'}\n        poly_cut_p_value: 6\n\n    act_gate: {'e': 'silu', 'o': 'tanh'}          # Equivalent to 'nonlinearity_gates' in nequip\n    act_scalar: {'e': 'silu', 'o': 'tanh'}        # Equivalent to 'nonlinearity_scalars' in nequip\n\n    is_parity: False                              # Pairy True (E(3) group) or False (to SE(3) group)\n\n    self_connection_type: 'nequip'                # Default is 'nequip'. 'linear' is used for SevenNet-0.\n\n    conv_denominator: \"avg_num_neigh\"             # Valid options are \"avg_num_neigh*\", \"sqrt_avg_num_neigh\", or float\n    train_denominator: False                      # Enable training for denominator in convolution layer\n    train_shift_scale: False                      # Enable training for shift &amp; scale in output layer\n\ntrain:\n    random_seed: 1\n    is_train_stress: True                         # Includes stress in the loss function\n    epoch: 200                                    # Ends training after this number of epochs\n\n    #loss: 'Huber'                                # Default is 'mse' (mean squared error)\n    #loss_param:\n        #delta: 0.01\n\n    # Each optimizer and scheduler have different available parameters.\n    # You can refer to sevenn/train/optim.py for supporting optimizer &amp; schedulers\n    optimizer: 'adam'                             # Options available are 'sgd', 'adagrad', 'adam', 'adamw', 'radam'\n    optim_param:\n        lr: 0.005\n    scheduler: 'exponentiallr'                    # 'steplr', 'multisteplr', 'exponentiallr', 'cosineannealinglr', 'reducelronplateau', 'linearlr'\n    scheduler_param:\n        gamma: 0.99\n\n    force_loss_weight: 0.1                        # Coefficient for force loss\n    stress_loss_weight: 1e-06                     # Coefficient for stress loss (to kbar unit)\n\n    per_epoch: 10                                 # Generate checkpoints every this epoch\n\n    # ['target y', 'metric']\n    # Target y: TotalEnergy, Energy, Force, Stress, Stress_GPa, TotalLoss\n    # Metric  : RMSE, MAE, or Loss\n    error_record:\n        - ['Energy', 'RMSE']\n        - ['Force', 'RMSE']\n        - ['Stress', 'RMSE']\n        - ['TotalLoss', 'None']\n\n    # Continue training model from given checkpoint, or pre-trained model checkpoint for fine-tuning\n    #continue:\n        #checkpoint: 'checkpoint_best.pth'         # Checkpoint of pre-trained model or a model want to continue training.\n        #reset_optimizer: False                    # Set True for fine-tuning\n        #reset_scheduler: False                    # Set True for fine-tuning\n        #use_statistic_values_of_checkpoint: False # Set True to use shift, scale, and avg_num_neigh from checkpoint or not\n\ndata:\n    batch_size: 4                                 # Per GPU batch size.\n    data_divide_ratio: 0.1                        # Split dataset into training and validation sets by this ratio\n\n    shift: 'per_atom_energy_mean'                 # One of 'per_atom_energy_mean*', 'elemwise_reference_energies', float\n    scale: 'force_rms'                            # One of 'force_rms*', 'per_atom_energy_std', 'elemwise_force_rms', float\n\n    # ase.io.read readable data files or structure_list or .sevenn_data files can be used as dataset.\n    # .sevenn_data is preprocessed data set has edges connected (can be obtained by using sevenn_graph_build or by save_** options below)\n    data_format: 'ase'                            # One of 'ase', 'structure_list' (.sevenn_data is always readable)\n    data_format_args:                             # if `data_format` is `ase`, args will be passed to `ase.io.read`\n        index: ':'                                # see `https://wiki.fysik.dtu.dk/ase/ase/io/io.html` for more valid arguments\n\n    # If only load_dataset_path is provided, train/valid set is automatically decided by splitting dataset by divide ratio\n    # If both load_dataset_path &amp; load_validset_path is provided, use load_dataset_path as training set.\n    load_dataset_path: ['../data/train.extxyz']   # Example of using ase as data_format, support multiple datasets and expansion(*)\n    #load_validset_path: ['./valid.sevenn_data']\n\n    #save_dataset_path: './total'                 # Save the preprocessed (in load_dataset_path) dataset\n    #save_by_train_valid: True                    # Save the preprocessed train.sevenn_data, valid.sevenn_data\n</code></pre>"},{"location":"sevenn_train_param/#fine_tune","title":"fine_tune","text":"<pre><code># Example input.yaml for fine-tuning sevennet-0\n# '*' signifies default. You can check log.sevenn for defaults.\n\nmodel:  # model keys should be consistent except for train_* keys\n    chemical_species: 'Auto'\n    cutoff: 5.0\n    channel: 128\n    is_parity: False\n    lmax: 2\n    num_convolution_layer: 5\n    irreps_manual:\n        - \"128x0e\"\n        - \"128x0e+64x1e+32x2e\"\n        - \"128x0e+64x1e+32x2e\"\n        - \"128x0e+64x1e+32x2e\"\n        - \"128x0e+64x1e+32x2e\"\n        - \"128x0e\"\n\n    weight_nn_hidden_neurons: [64, 64]\n    radial_basis:\n        radial_basis_name: 'bessel'\n        bessel_basis_num: 8\n    cutoff_function:\n        cutoff_function_name: 'XPLOR'\n        cutoff_on: 4.5\n    self_connection_type: 'linear'\n\n    train_shift_scale: False   # customizable (True | False)\n    train_denominator: False   # customizable (True | False)\n\ntrain:  # Customizable\n    random_seed: 1\n    is_train_stress: True\n    epoch: 100\n\n    optimizer: 'adam'\n    optim_param:\n        lr: 0.004\n    scheduler: 'exponentiallr'\n    scheduler_param:\n        gamma: 0.99\n\n    force_loss_weight: 0.1\n    stress_loss_weight: 1e-06\n\n    per_epoch: 10  # Generate checkpoints every this epoch\n\n    # ['target y', 'metric']\n    # Target y: TotalEnergy, Energy, Force, Stress, Stress_GPa, TotalLoss\n    # Metric  : RMSE, MAE, or Loss\n    error_record:\n        - ['Energy', 'RMSE']\n        - ['Force', 'RMSE']\n        - ['Stress', 'RMSE']\n        - ['TotalLoss', 'None']\n\n    continue:\n        reset_optimizer: True\n        reset_scheduler: True\n        reset_epoch: True\n        checkpoint: 'SevenNet-0_11July2024'\n        # Set True to use shift, scale, and avg_num_neigh from checkpoint (highly recommended)\n        use_statistic_values_of_checkpoint: True\n\ndata:  # Customizable\n    batch_size: 4\n    data_divide_ratio: 0.1\n\n    # ase.io.read readable data files or structure_list or .sevenn_data files can be used as dataset.\n    # .sevenn_data is preprocessed data set has edges connected (can be obtained by using sevenn_graph_build or by save_** options below)\n    data_format: 'ase'                            # One of 'ase', 'structure_list' (.sevenn_data is always readable)\n    data_format_args:                             # if `data_format` is `ase`, args will be passed to `ase.io.read`\n        index: ':'                                # see `https://wiki.fysik.dtu.dk/ase/ase/io/io.html` for more valid arguments\n\n    # If only load_dataset_path is provided, train/valid set is automatically decided by splitting dataset by divide ratio\n    # If both load_dataset_path &amp; load_validset_path is provided, use load_dataset_path as training set.\n    load_dataset_path: ['fine_tune.extxyz']       # Support multiple files and expansion(*)\n    #load_validset_path: ['./valid.sevenn_data']\n\n    #save_dataset_path: './total'                 # Save the preprocessed (in load_dataset_path) dataset\n    #save_by_train_valid: True                    # Save the preprocessed train.sevenn_data, valid.sevenn_data\n</code></pre>"},{"location":"sevenn_train_param/#sevennet-0","title":"sevennet-0","text":"<pre><code># SevenNet-0\nmodel:\n    chemical_species: 'auto'\n    cutoff: 5.0\n    channel: 128\n    is_parity: False\n    lmax: 2\n    num_convolution_layer: 5\n    irreps_manual:\n        - \"128x0e\"\n        - \"128x0e+64x1e+32x2e\"\n        - \"128x0e+64x1e+32x2e\"\n        - \"128x0e+64x1e+32x2e\"\n        - \"128x0e+64x1e+32x2e\"\n        - \"128x0e\"\n\n    weight_nn_hidden_neurons: [64, 64]\n    radial_basis:\n        radial_basis_name: 'bessel'\n        bessel_basis_num: 8\n    cutoff_function:\n        cutoff_function_name: 'XPLOR'\n        cutoff_on: 4.5\n\n    act_gate: {'e': 'silu', 'o': 'tanh'}\n    act_scalar: {'e': 'silu', 'o': 'tanh'}\n\n    conv_denominator: 'avg_num_neigh'\n    train_shift_scale: False\n    train_denominator: False\n    self_connection_type: 'linear'\ntrain:\n    train_shuffle: False\n    random_seed: 1\n    is_train_stress : True\n    epoch: 600\n\n    loss: 'Huber'\n    loss_param:\n        delta: 0.01\n\n    optimizer: 'adam'\n    optim_param:\n        lr: 0.01\n    scheduler: 'linearlr'\n    scheduler_param:\n        start_factor: 1.0\n        total_iters: 600\n        end_factor: 0.0001\n\n    force_loss_weight : 1.00\n    stress_loss_weight: 0.01\n\n    error_record:\n        - ['Energy', 'RMSE']\n        - ['Force', 'RMSE']\n        - ['Stress', 'RMSE']\n        - ['Energy', 'MAE']\n        - ['Force', 'MAE']\n        - ['Stress', 'MAE']\n        - ['Energy', 'Loss']\n        - ['Force', 'Loss']\n        - ['Stress', 'Loss']\n        - ['TotalLoss', 'None']\n\n    per_epoch: 10\n    # continue:\n    #    checkpoint: './checkpoint_last.pth'\n    #    reset_optimizer: False\n    #    reset_scheduler: False\ndata:\n    data_shuffle: False\n    batch_size: 128  # per GPU batch size, as the model trained with 32 GPUs, the effective batch size equals 4096.\n    scale: 'per_atom_energy_std'\n    shift: 'elemwise_reference_energies'\n\n    data_format: 'ase'\n    save_by_train_valid: False\n    load_dataset_path: [\"path_to_MPtrj_total.sevenn_data\"]\n    load_validset_path: [\"validaset.sevenn_data\"]\n</code></pre>"},{"location":"sevenn_train_param/#full-parameters","title":"Full parameters","text":"<pre><code># Example input.yaml for training SevenNet.\n# The underlying model is nequip (https://github.com/mir-group/nequip), but the names of hyperparameters might different.\n# Defaults model parameter that works well of channel, lmax, and num_convolution_layer are 32, 1, 3 respectively.\n# '*' signifies default. You can check log.sevenn.\n\nmodel:\n    chemical_species: 'Auto'                      # Chemical elements present in the dataset, guess them from load_dataset data if 'auto'\n    cutoff: 5.0                                   # Cutoff radius in Angstroms. If two atoms are within the cutoff, they are connected.\n    channel: 4                                    # The multiplicity(channel) of node features.\n    lmax: 1                                       # Maximum order of irreducible representations (rotation order).\n    num_convolution_layer: 4                      # The number of message passing layers.\n\n    #irreps_manual:                               # Manually set irreps of the model in each layer\n        #- \"128x0e\"\n        #- \"128x0e+64x1e+32x2e\"\n        #- \"128x0e+64x1e+32x2e\"\n        #- \"128x0e+64x1e+32x2e\"\n        #- \"128x0e+64x1e+32x2e\"\n        #- \"128x0e\"\n\n    weight_nn_hidden_neurons: [64, 64]            # Hidden neurons in convolution weight neural network\n    radial_basis:                                 # Function and its parameters to encode radial distance\n        radial_basis_name: 'bessel'               # Only 'bessel' is currently supported\n        bessel_basis_num: 8\n    cutoff_function:                              # Envelop function, multiplied to radial_basis functions to init edge featrues\n        cutoff_function_name: 'poly_cut'          # {'poly_cut' and 'poly_cut_p_value'} or {'XPLOR' and 'cutoff_on'}\n        poly_cut_p_value: 6\n\n    act_gate: {'e': 'silu', 'o': 'tanh'}          # Equivalent to 'nonlinearity_gates' in nequip\n    act_scalar: {'e': 'silu', 'o': 'tanh'}        # Equivalent to 'nonlinearity_scalars' in nequip\n\n    is_parity: False                              # Pairy True (E(3) group) or False (to SE(3) group)\n\n    self_connection_type: 'nequip'                # Default is 'nequip'. 'linear' is used for SevenNet-0.\n\n    conv_denominator: \"avg_num_neigh\"             # Valid options are \"avg_num_neigh*\", \"sqrt_avg_num_neigh\", or float\n    train_shift_scale: False                      # Enable training for shift &amp; scale in output layer\n    train_denominator: False                      # Enable training for denominator in convolution layer\n\ntrain:\n    random_seed: 1\n    is_train_stress: True                         # Includes stress in the loss function\n    epoch: 10                                     # Ends training after this number of epochs\n\n    #loss: 'Huber'                                # Default is 'mse' (mean squared error)\n    #loss_param:\n        #delta: 0.01\n\n    # Each optimizer and scheduler have different available parameters.\n    # You can refer to sevenn/train/optim.py for supporting optimizer &amp; schedulers\n    optimizer: 'adam'                             # Options available are 'sgd', 'adagrad', 'adam', 'adamw', 'radam'\n    optim_param:\n        lr: 0.005\n    scheduler: 'exponentiallr'                    # One of 'steplr', 'multisteplr', 'exponentiallr', 'cosineannealinglr', 'reducelronplateau', 'linearlr'\n    scheduler_param:\n        gamma: 0.99\n\n    force_loss_weight: 0.1                        # Coefficient for force loss\n    stress_loss_weight: 1e-06                     # Coefficient for stress loss (to kbar unit)\n\n    per_epoch:  5                                # Generate checkpoints every this epoch\n\n    # TotalEnergy, Energy, Force, Stress, Stress_GPa, TotalLoss\n    # RMSE, MAE, or Loss\n    error_record:\n        - ['Energy', 'RMSE']\n        - ['Force', 'RMSE']\n        - ['Stress', 'RMSE']\n        - ['TotalLoss', 'None']\n\n    # Continue training model from given checkpoint, or pre-trained model checkpoint for fine-tuning\n    #continue:\n        #reset_optimizer: False                    # Set True for fine-tuning\n        #reset_scheduler: False                    # Set True for fine-tuning\n        #checkpoint: 'checkpoint_best.pth'         # Checkpoint of pre-trained model or a model want to continue training.\n        #use_statistic_values_of_checkpoint: False # Set True to use shift, scale, and avg_num_neigh from checkpoint or not\n\n    # If the dataset changed (for fine-tuning),\n    # setting 'use_statistic_value_of_checkpoint' to True roughly changes model's accuracy in the beginning of training.\n    # We recommand to use it as False, and turn train_shift_scale and train_avg_num_neigh to True.\n\ndata:\n    batch_size: 2                                 # Per GPU batch size.\n    data_divide_ratio: 0.1                        # Split dataset into training and validation sets by this ratio\n\n    #shift: 'per_atom_energy_mean'                # One of 'per_atom_energy_mean*', 'elemwise_reference_energies', float\n    #scale: 'force_rms'                           # One of 'force_rms*', 'per_atom_energy_std', 'elemwise_force_rms', float\n\n    # ase.io.read readable data files or structure_list or .sevenn_data files can be used as dataset.\n    # .sevenn_data is preprocessed data set has edges connected (can be obtained by using sevenn_graph_build or by save_** options below)\n    data_format: 'ase'                   # Default is 'ase'. Choices are 'ase', 'structure_list', '.sevenn_data'\n    data_format_args:                            # Paramaters, will be passed to ase.io.read\n        energy_key: 'TotEnergy'                  # Key for energy in extxyz file\n        force_key: 'force'                       # Key for force in extxyz file\n\n    # ASE tries to infer its type by extension, in this case, extxyz file is loaded by ase.\n    #load_dataset_path: ['../data/test.extxyz']   # Example of using ase as data_format\n\n    # If only load_dataset_path is provided, train/valid set is automatically decided by splitting dataset by divide ratio\n    # If both load_dataset_path &amp; load_validset_path is provided, use load_dataset_path as training set.\n    load_dataset_path: ['./1_process_data/dataset_1593.xyz']\n    #load_validset_path: ['./valid.sevenn_data']\n\n    #save_dataset_path: 'total'                   # Save the preprocessed (in load_dataset_path) dataset\n    #save_by_train_valid: True                    # Save the preprocessed train.sevenn_data, valid.sevenn_data\n    #save_by_label: False                         # Save the dataset by labels specified in the structure_list\n</code></pre>"}]}